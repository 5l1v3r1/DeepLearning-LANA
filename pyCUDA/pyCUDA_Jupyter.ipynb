{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyCUDA-Jupyter.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning_LANA/blob/master/pyCUDA/pyCUDA_Jupyter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "uxb1Kq5YAwKZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# PyCUDA - Nvidia CUDA em GPUs com python"
      ]
    },
    {
      "metadata": {
        "id": "KV7eWPUeq1OQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "17c751d8-dd9b-4dd2-f360-cf7ddfaa3c93"
      },
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/58/33/cced4891eddd1a3ac561ff99081019fddc7838a07cace272c941e3c2f915/pycuda-2018.1.1.tar.gz (1.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.6MB 16.2MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2 (from pycuda)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/6a/7b706e4730db0ee5724c677cceafcac1bc9710c61612442a689e7b0aa5c4/pytools-2018.5.2.tar.gz (58kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytest>=2 in /usr/local/lib/python3.6/dist-packages (from pycuda) (3.10.1)\n",
            "Requirement already satisfied: decorator>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from pycuda) (4.3.0)\n",
            "Collecting appdirs>=1.4.0 (from pycuda)\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Collecting mako (from pycuda)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/f3/67579bb486517c0d49547f9697e36582cd19dafb5df9e687ed8e22de57fa/Mako-1.0.7.tar.gz (564kB)\n",
            "\u001b[K    100% |████████████████████████████████| 573kB 27.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pytools>=2011.2->pycuda) (1.14.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (40.6.3)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (5.0.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (1.7.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (1.2.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (18.2.0)\n",
            "Requirement already satisfied: pluggy>=0.7 in /usr/local/lib/python3.6/dist-packages (from pytest>=2->pycuda) (0.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from mako->pycuda) (1.1.0)\n",
            "Building wheels for collected packages: pycuda, pytools, mako\n",
            "  Running setup.py bdist_wheel for pycuda ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\n",
            "\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a5/17/ac/99922221c732eeece43529d3e0f9d441f7301c75990b2cdbff\n",
            "  Running setup.py bdist_wheel for pytools ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/cd/36/2f/b42ca5d846f492555de78add756be727b9d0f6258b31ea84d0\n",
            "  Running setup.py bdist_wheel for mako ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/15/35/25/dbcb848832ccb1a4b4ad23f529badfd3bce9bf88017f7ca510\n",
            "Successfully built pycuda pytools mako\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.3 mako-1.0.7 pycuda-2018.1.1 pytools-2018.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rwsuiFpiAwKa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Status da GPU"
      ]
    },
    {
      "metadata": {
        "id": "gFx8c-fYAwKb",
        "colab_type": "code",
        "outputId": "2fccbb2a-0c00-4dc7-8dff-ed1a8515e5ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jan 14 23:25:49 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hNvWrpipAzJL",
        "colab_type": "code",
        "outputId": "4b1e19af-c085-47f5-a83f-29f5f4d2dc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cuda_files.zip   exemplo3.cu\t exemplo4_out   exemplo6.cu\t   exemplo7.cu\n",
            " exemplo1.cu\t  exemplo3_out\t exemplo5.cu    exemplo6_out\t   exemplo7_out\n",
            " exemplo2.cu\t  exemplo4.cu\t exemplo5_out  'exemplo7 (1).cu'   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nkRzZB8kBFBU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Para importar arquivos"
      ]
    },
    {
      "metadata": {
        "id": "NnVnEKqjBESe",
        "colab_type": "code",
        "outputId": "dd5af112-3fb3-49c5-de8b-667a81f4a3f2",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-af4251c0-f798-447c-bca9-5f5a12c2bf06\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-af4251c0-f798-447c-bca9-5f5a12c2bf06\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 01-check-env.py to 01-check-env.py\n",
            "Saving 02-PyCudaWorkflow.py to 02-PyCudaWorkflow.py\n",
            "Saving 03-PyCudaMatrixManipulation.py to 03-PyCudaMatrixManipulation.py\n",
            "Saving 04-PyCudaGPUArray.py to 04-PyCudaGPUArray.py\n",
            "Saving 05-PyCudaElementWise.py to 05-PyCudaElementWise.py\n",
            "Saving 06-PyCudaReductionKernel.py to 06-PyCudaReductionKernel.py\n",
            "Saving Duvida-Pycuda-01.txt to Duvida-Pycuda-01.txt\n",
            "Saving t2est-02-PyCudaWorkflow-test.py to t2est-02-PyCudaWorkflow-test.py\n",
            "Saving test-02-PyCudaWorkflow-test.py to test-02-PyCudaWorkflow-test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SDyM3glRuuPQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Checando o ambiente GPU"
      ]
    },
    {
      "metadata": {
        "id": "n4aPdwtFus1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9cbe3334-b929-4042-a010-f5b59cf3aa91"
      },
      "cell_type": "code",
      "source": [
        "# Informações da GPU\n",
        "import pycuda.driver as drv \n",
        "\n",
        "drv.init() \n",
        "\n",
        "print (\"%d Dispositivo(s) encontrados.\" % drv.Device.count())\n",
        "\n",
        "for ordinal in range(drv.Device.count()): \n",
        "       dev = drv.Device(ordinal) \n",
        "       print (\"Dispositivo #%d: %s\" % (ordinal, dev.name())) \n",
        "       print (\" Compute Capability: %d.%d\" % dev.compute_capability())     \n",
        "       print (\" Total Memory: %s KB\" % (dev.total_memory()//(1024))) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Dispositivo(s) encontrados.\n",
            "Dispositivo #0: Tesla K80\n",
            " Compute Capability: 3.7\n",
            " Total Memory: 11715776 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p33mZNU8u-CU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "caca9ea8-46bb-4aea-e893-dc83d9228cd1"
      },
      "cell_type": "code",
      "source": [
        "!ls *.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01-check-env.py\t\t\t05-PyCudaElementWise.py\n",
            "02-PyCudaWorkflow.py\t\t06-PyCudaReductionKernel.py\n",
            "03-PyCudaMatrixManipulation.py\tt2est-02-PyCudaWorkflow-test.py\n",
            "04-PyCudaGPUArray.py\t\ttest-02-PyCudaWorkflow-test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aJsmDvUpv8L0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "ShC24ACzv6FR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "12fbc403-a478-42d1-f167-a65776476a89"
      },
      "cell_type": "code",
      "source": [
        "# Multiplicação de Matrizes Usando a GPU\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "a = numpy.random.randn(5,5)\n",
        "a = a.astype(numpy.float32)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "  __global__ void doubles_matrix(float *a)\n",
        "  {\n",
        "    int idx = threadIdx.x + threadIdx.y*4;\n",
        "    a[idx] *= 2;\n",
        "  }\n",
        "  \"\"\")\n",
        "\n",
        "func = mod.get_function(\"doubles_matrix\")\n",
        "\n",
        "func(a_gpu, block=(5,5,1))\n",
        "\n",
        "a_doubled = numpy.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "\n",
        "print (\"Matriz Original\")\n",
        "print (a)\n",
        "print (\"Matriz Multiplicada Por 2 Usando PyCUDA\")\n",
        "print (a_doubled)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Original\n",
            "[[-0.91079015 -0.8891651  -1.0901822  -1.1925074  -0.11522503]\n",
            " [-0.24382235 -0.83982086 -0.6174249  -0.82852226 -1.3399014 ]\n",
            " [-0.13524824 -2.486508    0.5964713   1.7961265  -0.1433859 ]\n",
            " [ 0.84577096  0.17217064  0.26081115 -1.7617484  -0.3193688 ]\n",
            " [-0.10955688  0.33049542  0.08368162  0.5058635   1.8535402 ]]\n",
            "Matriz Multiplicada Por 2 Usando PyCUDA\n",
            "[[-1.8215803  -1.7783302  -2.1803644  -2.3850148  -0.23045006]\n",
            " [-0.4876447  -1.6796417  -1.2348498  -1.6570445  -2.679803  ]\n",
            " [-0.2704965  -4.973016    1.1929426   3.592253   -0.2867718 ]\n",
            " [ 1.6915419   0.34434128  0.5216223  -3.5234969  -0.6387376 ]\n",
            " [-0.21911375  0.33049542  0.08368162  0.5058635   1.8535402 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pbMg8ZiFv6ID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "9b3ecac7-8dd9-4084-af6f-aeebcacc5330"
      },
      "cell_type": "code",
      "source": [
        "# Gerenciamento de Memória na GPU através da muliplicação de 2 matrizes\n",
        "\n",
        "# Pacotes\n",
        "import numpy as np\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "\n",
        "# Inicializando o device\n",
        "import pycuda.autoinit\n",
        "\n",
        "# Kernel\n",
        "kernel_code_template = \"\"\"\n",
        "__global__ void MatrixMulKernel(float *a, float *b, float *c)\n",
        "{\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    float Pvalue = 0;\n",
        "    for (int k = 0; k < %(MATRIX_SIZE)s; ++k) {\n",
        "        float Aelement = a[ty * %(MATRIX_SIZE)s + k];\n",
        "        float Belement = b[k * %(MATRIX_SIZE)s + tx];\n",
        "        Pvalue += Aelement * Belement;\n",
        "    }\n",
        "\n",
        "    c[ty * %(MATRIX_SIZE)s + tx] = Pvalue;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "# Define o tamanho da Matriz\n",
        "MATRIX_SIZE = 5\n",
        "\n",
        "# Variáveis para armazenar as matrizes na memória do host\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "\n",
        "# Variáveis para armazenar as matrizes na memória do device\n",
        "a_gpu = gpuarray.to_gpu(a_cpu) \n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "# Define o kernel\n",
        "kernel_code = kernel_code_template % {\n",
        "    'MATRIX_SIZE': MATRIX_SIZE \n",
        "    }\n",
        "\n",
        "# Compila o kernel\n",
        "mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "# Obtém o kernel\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "# Executa o kernel\n",
        "matrixmul(\n",
        "    a_gpu, b_gpu, \n",
        "    c_gpu, \n",
        "    block = (MATRIX_SIZE, MATRIX_SIZE, 1),\n",
        "    )\n",
        "\n",
        "# Imprime os resultados\n",
        "print (\"-\" * 80)\n",
        "print (\"Matriz A (GPU):\")\n",
        "print (a_gpu.get())\n",
        "\n",
        "print (\"-\" * 80)\n",
        "print (\"Matriz B (GPU):\")\n",
        "print (b_gpu.get())\n",
        "\n",
        "print (\"-\" * 80)\n",
        "print (\"Matriz C (GPU):\")\n",
        "print (c_gpu.get())\n",
        "\n",
        "print (\"-\" * 80)\n",
        "print (\"Diferença CPU-GPU:\")\n",
        "print (c_cpu - c_gpu.get())\n",
        "\n",
        "np.allclose(c_cpu, c_gpu.get())\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Matriz A (GPU):\n",
            "[[ 0.3604919   1.1128123  -0.9120744  -0.2843168  -0.55064857]\n",
            " [ 1.6783663   0.06910207  0.30600306  0.35123047  0.5714042 ]\n",
            " [-1.8354139  -0.13443327 -0.11898965  1.3090595   0.5153561 ]\n",
            " [-2.0327392  -0.47590256  0.06097374 -2.3049285  -1.6842628 ]\n",
            " [ 1.3557538  -1.0107814   0.36772087  1.38075    -0.15153128]]\n",
            "--------------------------------------------------------------------------------\n",
            "Matriz B (GPU):\n",
            "[[ 0.18019308 -0.23353235 -0.6655699   0.2204949   0.79046947]\n",
            " [ 0.9329438  -1.0420737   0.8548512  -0.62169874  0.68219674]\n",
            " [ 0.15263858 -0.625713   -1.7614852  -0.834755    1.8488528 ]\n",
            " [-0.31875882 -1.4452021  -0.8125798  -0.778752    0.34576753]\n",
            " [ 0.18867064 -0.58592045 -0.2399493   1.092761    0.67266935]]\n",
            "--------------------------------------------------------------------------------\n",
            "Matriz C (GPU):\n",
            "[[ 0.9506691   0.06040929  2.6811197  -0.23130372 -1.1108884 ]\n",
            " [ 0.4094556  -1.4978288  -2.0195286   0.42255977  2.4454033 ]\n",
            " [-0.79435164 -1.550642    0.12889963 -0.6780669  -0.96324843]\n",
            " [-0.38402358  5.250416    3.1157758  -0.24876767 -3.7486675 ]\n",
            " [-1.1112921  -1.4000688  -3.4997613  -0.62046784  1.43748   ]]\n",
            "--------------------------------------------------------------------------------\n",
            "Diferença CPU-GPU:\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "5IPa4TiCv6P-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5550d777-5b4d-41fc-dba2-3c5c9d08ce89"
      },
      "cell_type": "code",
      "source": [
        "# GPU Array\n",
        "# Funciona de forma similar ao np.ndarray do Numpy\n",
        "# GPU Array suporta diversas operações aritméticas e pode ser usado em conjunto com pycuda.cumath e pycuda.curandom\n",
        "\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "\n",
        "# Definindo a matriz em tempo de execução - gpuarray -> operações na GPU\n",
        "a_gpu = gpuarray.to_gpu(numpy.random.randn(5,5).astype(numpy.float32))\n",
        "\n",
        "# Multiplicando a matriz na GPU\n",
        "a_doubled = (2 * a_gpu).get()\n",
        "\n",
        "# Imprimindo so resultados\n",
        "print (\"Matriz Original\")\n",
        "print (a_gpu.get())\n",
        "print (\"Matriz multiplicada por 2 após a execução com GPUARRAY\")\n",
        "print (a_doubled)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz Original\n",
            "[[-0.68389815 -0.9540187   0.62444663  2.2092094   0.6055998 ]\n",
            " [ 2.1918674  -2.0914237  -1.5909268   1.1299127  -0.14859967]\n",
            " [-0.18609966  0.793407    0.90570015 -0.4340446   1.9414983 ]\n",
            " [-1.7000875   1.1402414   0.8981155   1.5661582  -1.6731738 ]\n",
            " [-0.98103285 -0.86361957 -1.1050426  -0.82644194  1.7413609 ]]\n",
            "Matriz multiplicada por 2 após a execução com GPUARRAY\n",
            "[[-1.3677963  -1.9080374   1.2488933   4.418419    1.2111996 ]\n",
            " [ 4.3837347  -4.1828475  -3.1818535   2.2598255  -0.29719934]\n",
            " [-0.37219933  1.586814    1.8114003  -0.8680892   3.8829966 ]\n",
            " [-3.400175    2.2804828   1.796231    3.1323164  -3.3463476 ]\n",
            " [-1.9620657  -1.7272391  -2.2100852  -1.6528839   3.4827218 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oD1KQE_Pv6LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "083d2051-803d-46dd-9fd2-eb97053f628b"
      },
      "cell_type": "code",
      "source": [
        "# Avaliando Expressões Element-wise\n",
        "# Avaliando a combinação linear entre 2 vetores\n",
        "\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "from pycuda.curandom import rand as curand\n",
        "from pycuda.elementwise import ElementwiseKernel\n",
        "import numpy.linalg as la\n",
        "\n",
        "# Matrizes\n",
        "input_vector_a = curand((50,))\n",
        "input_vector_b = curand((50,))\n",
        "\n",
        "# Coeficientes\n",
        "mult_coefficient_a = 2\n",
        "mult_coefficient_b = 5\n",
        "\n",
        "# Kernel\n",
        "# Combinação Linear = 2a + 5b\n",
        "linear_combination = ElementwiseKernel(\n",
        "        \"float a, float *x, float b, float *y, float *c\",\n",
        "        \"c[i] = a*x[i] + b*y[i]\",\n",
        "        \"linear_combination\")\n",
        "\n",
        "# Variável para receber o resultado da operação\n",
        "linear_combination_result = gpuarray.empty_like(input_vector_a)\n",
        "\n",
        "# Execução do kernel\n",
        "linear_combination(mult_coefficient_a, input_vector_a, mult_coefficient_b, input_vector_b, linear_combination_result)\n",
        "\n",
        "# Imprime os resultados\n",
        "print (\"Vetor A =\")\n",
        "print (input_vector_a)\n",
        "\n",
        "print (\"Vetor B = \")\n",
        "print (input_vector_b)\n",
        "\n",
        "print (\"Vetor Resultante C = \")\n",
        "print (linear_combination_result)\n",
        "\n",
        "print (\"Verificando o resultado, checando a diferença entre o vetor C e a combinação linear de A e B\")\n",
        "print (\"C - (%sA + %sB) = \"%(mult_coefficient_a,mult_coefficient_b))\n",
        "print (linear_combination_result - (mult_coefficient_a*input_vector_a + mult_coefficient_b*input_vector_b))\n",
        "assert la.norm((linear_combination_result - (mult_coefficient_a*input_vector_a + mult_coefficient_b*input_vector_b)).get()) < 1e-5"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vetor A =\n",
            "[0.9299976  0.57159555 0.6747105  0.35152113 0.42484605 0.2478653\n",
            " 0.28940392 0.5270712  0.41606745 0.48860577 0.32973623 0.60531074\n",
            " 0.37160522 0.49076557 0.2574233  0.75812644 0.14752856 0.85217303\n",
            " 0.81258714 0.03948139 0.8952462  0.98310745 0.37579942 0.04873587\n",
            " 0.37918943 0.84297776 0.86008066 0.17635828 0.54952157 0.8074612\n",
            " 0.8917616  0.01910386 0.32837296 0.0960414  0.23743396 0.94870305\n",
            " 0.5522556  0.5548405  0.33031994 0.83856946 0.09172963 0.7755765\n",
            " 0.0759598  0.7508158  0.12523359 0.2862492  0.0158942  0.83963037\n",
            " 0.0863947  0.25151792]\n",
            "Vetor B = \n",
            "[0.96609336 0.48443323 0.71880895 0.28619775 0.5227978  0.82229006\n",
            " 0.97751075 0.5487958  0.4755591  0.9365577  0.29246634 0.3210364\n",
            " 0.95645505 0.19344777 0.9341336  0.03502631 0.6869635  0.3317518\n",
            " 0.18612684 0.13323092 0.8401832  0.31316194 0.90463746 0.25292233\n",
            " 0.58972275 0.32619864 0.9309445  0.9536835  0.3777082  0.36830986\n",
            " 0.24655311 0.97965175 0.72053516 0.4027994  0.36097062 0.7576021\n",
            " 0.45439163 0.26408187 0.53147167 0.5948454  0.03152365 0.50839806\n",
            " 0.8838597  0.36709437 0.12045027 0.9455113  0.03388422 0.21912126\n",
            " 0.68500036 0.8653983 ]\n",
            "Vetor Resultante C = \n",
            "[6.690462   3.5653572  4.9434657  2.134031   3.4636812  4.6071806\n",
            " 5.4663615  3.7981215  3.2099304  5.66       2.1218042  2.8158035\n",
            " 5.5254855  1.94877    5.185515   1.6913844  3.7298746  3.363105\n",
            " 2.5558085  0.7451174  5.9914083  3.5320246  5.274786   1.3620833\n",
            " 3.7069926  3.3169487  6.374884   5.121134   2.987584   3.4564717\n",
            " 3.0162888  4.936466   4.259422   2.20608    2.279721   5.6854167\n",
            " 3.3764691  2.4300904  3.3179984  4.6513658  0.3410775  4.0931435\n",
            " 4.5712185  3.3371034  0.85271853 5.3000546  0.20120952 2.774867\n",
            " 3.5977912  4.8300276 ]\n",
            "Verificando o resultado, checando a diferença entre o vetor C e a combinação linear de A e B\n",
            "C - (2A + 5B) = \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qyGetp-x9emg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "220fa178-9a2c-4089-dda2-6b551294e756"
      },
      "cell_type": "code",
      "source": [
        "# Operações de MapReduce em Paralelo na GPU\n",
        "\n",
        "# Pacotes\n",
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "from pycuda.reduction import ReductionKernel\n",
        "\n",
        "# Comprimento do vetor\n",
        "vector_length = 400\n",
        "\n",
        "# Vetores A e B\n",
        "input_vector_a = gpuarray.arange(vector_length, dtype = numpy.int)\n",
        "input_vector_b = gpuarray.arange(vector_length, dtype = numpy.int)\n",
        "\n",
        "# Operação de redução em paralelo\n",
        "dot_product = ReductionKernel(numpy.int,\n",
        "                       arguments = \"int *x, int *y\",\n",
        "                       map_expr = \"x[i]*y[i]\",\n",
        "                       reduce_expr = \"a+b\", \n",
        "                       neutral = \"0\")\n",
        "\n",
        "# Execução do kernel\n",
        "dot_product = dot_product(input_vector_a, input_vector_b).get()\n",
        "\n",
        "# Imprime os resultados\n",
        "print(\"Matriz A\")\n",
        "print(input_vector_a)\n",
        "\n",
        "print(\"Matriz B\")\n",
        "print(input_vector_b)\n",
        "\n",
        "print(\"Resultado do Produto A * B\")\n",
        "print(dot_product)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matriz A\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399]\n",
            "Matriz B\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399]\n",
            "Resultado do Produto A * B\n",
            "2646700\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WtO4EBYx9yzt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b3fadf22-ec52-4068-ed72-67bad73cbe0c"
      },
      "cell_type": "code",
      "source": [
        "!ls *.py"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01-check-env.py\t\t\t05-PyCudaElementWise.py\n",
            "02-PyCudaWorkflow.py\t\t06-PyCudaReductionKernel.py\n",
            "03-PyCudaMatrixManipulation.py\tt2est-02-PyCudaWorkflow-test.py\n",
            "04-PyCudaGPUArray.py\t\ttest-02-PyCudaWorkflow-test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2fe3gwncAwL1",
        "colab_type": "code",
        "outputId": "017de9da-5676-457a-9a72-f5cf0ef589c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "rm -f pycuda_files.zip\n",
        "zip -r pycuda_files.zip . -i *.py"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: t2est-02-PyCudaWorkflow-test.py (deflated 52%)\n",
            "  adding: 04-PyCudaGPUArray.py (deflated 44%)\n",
            "  adding: 02-PyCudaWorkflow.py (deflated 44%)\n",
            "  adding: 01-check-env.py (deflated 43%)\n",
            "  adding: test-02-PyCudaWorkflow-test.py (deflated 44%)\n",
            "  adding: 05-PyCudaElementWise.py (deflated 63%)\n",
            "  adding: 03-PyCudaMatrixManipulation.py (deflated 60%)\n",
            "  adding: 06-PyCudaReductionKernel.py (deflated 57%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dkm0WZogUttd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Download a file"
      ]
    },
    {
      "metadata": {
        "id": "x4ds4AfvUnLf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('pycuda_files.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q5l1qxflTsJB",
        "colab_type": "code",
        "outputId": "5d6b4ee1-bf9f-460b-95d3-f37b2ae33e67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 01-check-env.py\t\t  exemplo4_out\n",
            " 02-PyCudaWorkflow.py\t\t  exemplo5.cu\n",
            " 03-PyCudaMatrixManipulation.py   exemplo5_out\n",
            " 04-PyCudaGPUArray.py\t\t  exemplo6.cu\n",
            " 05-PyCudaElementWise.py\t  exemplo6_out\n",
            " 06-PyCudaReductionKernel.py\t 'exemplo7 (1).cu'\n",
            " cuda_files.zip\t\t\t  exemplo7.cu\n",
            " Duvida-Pycuda-01.txt\t\t  exemplo7_out\n",
            " exemplo1.cu\t\t\t  pycuda_files.zip\n",
            " exemplo2.cu\t\t\t  sample_data\n",
            " exemplo3.cu\t\t\t  t2est-02-PyCudaWorkflow-test.py\n",
            " exemplo3_out\t\t\t  test-02-PyCudaWorkflow-test.py\n",
            " exemplo4.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0aNp6dOyAwL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Depois de ** executar a célula acima, você pode baixar o arquivo zip [here](cuda_files.zip)"
      ]
    }
  ]
}