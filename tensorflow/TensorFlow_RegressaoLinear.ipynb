{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow-RegressaoLinear.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/tensorflow/TensorFlow_RegressaoLinear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KNeAhMKAxsCT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# TensorFlow - Regressão Linear"
      ]
    },
    {
      "metadata": {
        "id": "_Sp_BnKtx8St",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Carregando arquivo .csv"
      ]
    },
    {
      "metadata": {
        "id": "rjlRqK3-x7iX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget vendas\n",
        "!mkdir datasets\n",
        "!mv *.csv datasets\n",
        "!ls -ilah datasets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IFFmr5EFxqjD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Versão 1 do Modelo\n",
        "\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Nível de log\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
        "\n",
        "# ------------------------- Seção 1 - Carregando e Normalizando os Dados -------------------------\n",
        "\n",
        "# Carrega dados de treino\n",
        "dados_treino = pd.read_csv(\"datasets/vendas_data_training.csv\", dtype = float)\n",
        "\n",
        "# Define X e Y de treino\n",
        "X_treino = dados_treino.drop(\"total_vendas\", axis= 1).values\n",
        "Y_treino = dados_treino[['total_vendas']].values\n",
        "\n",
        "# Carrega dados de teste\n",
        "dados_teste = pd.read_csv(\"datasets/vendas_data_test.csv\", dtype = float)\n",
        "\n",
        "# Define X e Y de teste\n",
        "X_teste = dados_teste.drop(\"total_vendas\", axis = 1).values\n",
        "Y_teste = dados_teste[['total_vendas']].values\n",
        "\n",
        "# Criando operadores de escala\n",
        "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Aplicando escala aos dados de treino\n",
        "X_scaled_treino = X_scaler.fit_transform(X_treino)\n",
        "Y_scaled_treino = Y_scaler.fit_transform(Y_treino)\n",
        "\n",
        "# Aplicando escala aos dados de teste\n",
        "X_scaled_teste = X_scaler.transform(X_teste)\n",
        "Y_scaled_teste = Y_scaler.transform(Y_teste)\n",
        "\n",
        "# ------------------------- Seção 2 - Estrutura do Modelo -------------------------\n",
        "\n",
        "# Hiperparâmetros\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "display_step = 5\n",
        "\n",
        "# Definindo inputs e outputs\n",
        "num_inputs = 9\n",
        "num_outputs = 1\n",
        "\n",
        "# Camadas\n",
        "layer_1_nodes = 50\n",
        "layer_2_nodes = 100\n",
        "layer_3_nodes = 50\n",
        "\n",
        "# ------------------------- Seção 3 - Construindo Camadas da Rede Neural -------------------------\n",
        "\n",
        "# Camada de Input\n",
        "with tf.variable_scope('input'):\n",
        "    X = tf.placeholder(tf.float32, shape=(None, num_inputs))\n",
        "\n",
        "# Camada 1\n",
        "with tf.variable_scope('layer1'):\n",
        "    weights = tf.get_variable(name = 'weights1', shape=[num_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases1', shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
        "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
        "\n",
        "# Camada 2\n",
        "with tf.variable_scope('layer2'):\n",
        "    weights = tf.get_variable(name = 'weights2', shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases2', shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
        "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
        "\n",
        "# Camada 3\n",
        "with tf.variable_scope('layer3'):\n",
        "    weights = tf.get_variable(name = 'weights3', shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases3', shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
        "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
        "\n",
        "# Camada de Output\n",
        "with tf.variable_scope('output'):\n",
        "    weights = tf.get_variable(name = 'weights4', shape=[layer_3_nodes, num_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases4', shape=[num_outputs], initializer=tf.zeros_initializer())\n",
        "    prediction = tf.matmul(layer_3_output, weights) + biases\n",
        "\n",
        "# ------------------------- Seção 4 - Custo e Otimização -------------------------\n",
        "\n",
        "# Custo\n",
        "with tf.variable_scope('cost'):\n",
        "    Y = tf.placeholder(tf.float32, shape=(None, num_outputs))\n",
        "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))\n",
        "\n",
        "# Otimizador\n",
        "with tf.variable_scope('train'):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "# ------------------------- Seção 5 - Sessão TensorFlow -------------------------\n",
        "\n",
        "# Abrindo Sessão TensorFlow\n",
        "with tf.Session() as session:\n",
        "\n",
        "    # Inicialização das Variáveis\n",
        "    session.run(tf.global_variables_initializer())\n",
        "\n",
        "    # Loop for pelas epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Treinamento\n",
        "        session.run(optimizer, feed_dict={X:X_scaled_treino, Y:Y_scaled_treino})\n",
        "\n",
        "        # Progresso do Treinamento\n",
        "        if epoch % display_step == 0:\n",
        "            training_cost = session.run(cost, feed_dict={X:X_scaled_treino, Y:Y_scaled_treino})\n",
        "            test_cost = session.run(cost, feed_dict={X: X_scaled_teste, Y: Y_scaled_teste})\n",
        "            print(\"\\nCusto  em Treinamento: {}\".format(training_cost))\n",
        "            print(\"Custo  em Teste: {}\".format(test_cost))\n",
        "\n",
        "    # Print\n",
        "    print(\"\\nTreinamento Concluído\")\n",
        "\n",
        "    final_training_cost = session.run(cost, feed_dict={X: X_scaled_treino, Y: Y_scaled_treino})\n",
        "    final_test_cost = session.run(cost, feed_dict={X: X_scaled_teste, Y: Y_scaled_teste})\n",
        "\n",
        "    print(\"\\nCusto Final em Treinamento: {}\".format(final_training_cost))\n",
        "    print(\"Custo Final em Teste: {}\".format(final_test_cost))\n",
        "\n",
        "    # Variável com valores previstos normalizados\n",
        "    Y_predicted_scaled = session.run(prediction, feed_dict={X:X_scaled_teste})\n",
        "\n",
        "    # Remove a escala\n",
        "    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n",
        "\n",
        "    # Coleta os dados reais e os valores previstos\n",
        "    total_vendas_real = dados_teste['total_vendas'].values[1]\n",
        "    total_vendas_previsto = Y_predicted[1][0]\n",
        "\n",
        "    # Print do resultado\n",
        "    print(\"\\nTotal Vendas Real de 1 Seguro: {}\".format(total_vendas_real))\n",
        "    print(\"Total Vendas Previsto de 1 Seguro: {}\".format(total_vendas_previsto))\n",
        "    print(\"Erro = : {}\".format(total_vendas_real - total_vendas_previsto))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}