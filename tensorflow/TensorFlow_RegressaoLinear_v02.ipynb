{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow-RegressaoLinear-v02.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/tensorflow/TensorFlow_RegressaoLinear_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "ye2Pvh2oj-Yz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regressão Linear com TensorFlow - versão 2"
      ]
    },
    {
      "metadata": {
        "id": "84vqFYylkHOR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Carregando o modelo"
      ]
    },
    {
      "metadata": {
        "id": "lLHIiLTskoHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "d15866fd-f0ac-4a38-c04b-b67230d3b23c"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/tensorflow/data/vendas_data_training.csv\n",
        "!wget https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/tensorflow/data/vendas_data_test.csv\n",
        "!mkdir datasets\n",
        "!mv *.csv datasets\n",
        "!ls -ilah datasets"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-25 15:15:40--  https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/tensorflow/data/vendas_data_training.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30718 (30K) [text/plain]\n",
            "Saving to: ‘vendas_data_training.csv’\n",
            "\n",
            "\rvendas_data_trainin   0%[                    ]       0  --.-KB/s               \rvendas_data_trainin 100%[===================>]  30.00K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2019-01-25 15:15:40 (4.24 MB/s) - ‘vendas_data_training.csv’ saved [30718/30718]\n",
            "\n",
            "--2019-01-25 15:15:42--  https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/tensorflow/data/vendas_data_test.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12401 (12K) [text/plain]\n",
            "Saving to: ‘vendas_data_test.csv’\n",
            "\n",
            "vendas_data_test.cs 100%[===================>]  12.11K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-01-25 15:15:42 (95.9 MB/s) - ‘vendas_data_test.csv’ saved [12401/12401]\n",
            "\n",
            "total 64K\n",
            "19399414 drwxr-xr-x 2 root root 4.0K Jan 25 15:15 .\n",
            " 1048583 drwxr-xr-x 1 root root 4.0K Jan 25 15:15 ..\n",
            "19399413 -rw-r--r-- 1 root root  13K Jan 25 15:15 vendas_data_test.csv\n",
            "19399411 -rw-r--r-- 1 root root  30K Jan 25 15:15 vendas_data_training.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MWRv3tH1jyH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b98d0442-000f-49fa-83a7-491bd0206b52"
      },
      "cell_type": "code",
      "source": [
        "# Versão 2 do Modelo\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Nível de log\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '2'\n",
        "\n",
        "# ------------------------- Seção 1 - Carregando e Normalizando os Dados -------------------------\n",
        "\n",
        "# Carrega dados de treino\n",
        "dados_treino = pd.read_csv(\"datasets/vendas_data_training.csv\", dtype = float)\n",
        "\n",
        "# Define X e Y de treino\n",
        "X_treino = dados_treino.drop(\"total_vendas\", axis= 1).values\n",
        "Y_treino = dados_treino[['total_vendas']].values\n",
        "\n",
        "# Carrega dados de teste\n",
        "dados_teste = pd.read_csv(\"datasets/vendas_data_test.csv\", dtype = float)\n",
        "\n",
        "# Define X e Y de teste\n",
        "X_teste = dados_teste.drop(\"total_vendas\", axis = 1).values\n",
        "Y_teste = dados_teste[['total_vendas']].values\n",
        "\n",
        "# Criando operadores de escala\n",
        "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "Y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Aplicando escala aos dados de treino\n",
        "X_scaled_treino = X_scaler.fit_transform(X_treino)\n",
        "Y_scaled_treino = Y_scaler.fit_transform(Y_treino)\n",
        "\n",
        "# Aplicando escala aos dados de teste\n",
        "X_scaled_teste = X_scaler.transform(X_teste)\n",
        "Y_scaled_teste = Y_scaler.transform(Y_teste)\n",
        "\n",
        "# ------------------------- Seção 2 - Estrutura do Modelo -------------------------\n",
        "\n",
        "# Hiperparâmetros\n",
        "learning_rate = 0.001\n",
        "num_epochs = 100\n",
        "display_step = 5\n",
        "\n",
        "# Definindo inputs e outputs\n",
        "num_inputs = 9\n",
        "num_outputs = 1\n",
        "\n",
        "# Camadas\n",
        "layer_1_nodes = 50\n",
        "layer_2_nodes = 100\n",
        "layer_3_nodes = 50\n",
        "\n",
        "# Run Tensorboard\n",
        "RUN_NAME = \"Histograma\"\n",
        "\n",
        "# ------------------------- Seção 3 - Construindo Camadas da Rede Neural -------------------------\n",
        "\n",
        "# Camada de Input\n",
        "with tf.variable_scope('input'):\n",
        "    X = tf.placeholder(tf.float32, shape=(None, num_inputs))\n",
        "\n",
        "# Camada 1\n",
        "with tf.variable_scope('layer1'):\n",
        "    weights = tf.get_variable(name = 'weights1', shape=[num_inputs, layer_1_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases1', shape=[layer_1_nodes], initializer=tf.zeros_initializer())\n",
        "    layer_1_output = tf.nn.relu(tf.matmul(X, weights) + biases)\n",
        "\n",
        "# Camada 2\n",
        "with tf.variable_scope('layer2'):\n",
        "    weights = tf.get_variable(name = 'weights2', shape=[layer_1_nodes, layer_2_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases2', shape=[layer_2_nodes], initializer=tf.zeros_initializer())\n",
        "    layer_2_output = tf.nn.relu(tf.matmul(layer_1_output, weights) + biases)\n",
        "\n",
        "# Camada 3\n",
        "with tf.variable_scope('layer3'):\n",
        "    weights = tf.get_variable(name = 'weights3', shape=[layer_2_nodes, layer_3_nodes], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases3', shape=[layer_3_nodes], initializer=tf.zeros_initializer())\n",
        "    layer_3_output = tf.nn.relu(tf.matmul(layer_2_output, weights) + biases)\n",
        "\n",
        "# Camada de Output\n",
        "with tf.variable_scope('output'):\n",
        "    weights = tf.get_variable(name = 'weights4', shape=[layer_3_nodes, num_outputs], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    biases = tf.get_variable(name = 'biases4', shape=[num_outputs], initializer=tf.zeros_initializer())\n",
        "    prediction = tf.matmul(layer_3_output, weights) + biases\n",
        "\n",
        "# ------------------------- Seção 4 - Custo e Otimização -------------------------\n",
        "\n",
        "# Custo\n",
        "with tf.variable_scope('cost'):\n",
        "    Y = tf.placeholder(tf.float32, shape=(None, num_outputs))\n",
        "    cost = tf.reduce_mean(tf.squared_difference(prediction, Y))\n",
        "\n",
        "# Otimizador\n",
        "with tf.variable_scope('train'):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
        "\n",
        "# ------------------------- Seção 5 - Summary TensorBoard -------------------------\n",
        "\n",
        "# Summary\n",
        "with tf.variable_scope('logging'):\n",
        "    tf.summary.scalar('current_cost', cost)\n",
        "    tf.summary.histogram('predicted_value', prediction)\n",
        "    summary = tf.summary.merge_all()\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "# ------------------------- Seção 6 - Sessão TensorFlow -------------------------\n",
        "\n",
        "# Abrindo Sessão TensorFlow\n",
        "with tf.Session() as session:\n",
        "\n",
        "    # Inicialização das Variáveis\n",
        "    session.run(tf.global_variables_initializer())\n",
        "\n",
        "    # File writer para tracking do progresso\n",
        "    training_writer = tf.summary.FileWriter(\"./logs/{}/training\".format(RUN_NAME), session.graph)\n",
        "    testing_writer = tf.summary.FileWriter(\"./logs/{}/testing\".format(RUN_NAME), session.graph)\n",
        "\n",
        "    # Loop for pelas epochs\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Treinamento\n",
        "        session.run(optimizer, feed_dict={X:X_scaled_treino, Y:Y_scaled_treino})\n",
        "\n",
        "        # Progresso do Treinamento\n",
        "        if epoch % display_step == 0:\n",
        "            training_cost, training_summary = session.run([cost, summary], feed_dict={X:X_scaled_treino, Y:Y_scaled_treino})\n",
        "            test_cost, test_summary = session.run([cost, summary], feed_dict={X: X_scaled_teste, Y: Y_scaled_teste})\n",
        "\n",
        "            # Adicionando Sumário\n",
        "            training_writer.add_summary(training_summary, epoch)\n",
        "            testing_writer.add_summary(test_summary, epoch)\n",
        "\n",
        "    # Print\n",
        "    print(\"\\nTreinamento Concluído\")\n",
        "\n",
        "    final_training_cost = session.run(cost, feed_dict={X: X_scaled_treino, Y: Y_scaled_treino})\n",
        "    final_test_cost = session.run(cost, feed_dict={X: X_scaled_teste, Y: Y_scaled_teste})\n",
        "\n",
        "    print(\"\\nCusto Final em Treinamento: {}\".format(final_training_cost))\n",
        "    print(\"Custo Final em Teste: {}\".format(final_test_cost))\n",
        "\n",
        "    # Variável com valores previstos normalizados\n",
        "    Y_predicted_scaled = session.run(prediction, feed_dict={X:X_scaled_teste})\n",
        "\n",
        "    # Remove a escala\n",
        "    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n",
        "\n",
        "    # Coleta os dados reais e os valores previstos\n",
        "    total_vendas_real = dados_teste['total_vendas'].values[0]\n",
        "    total_vendas_previsto = Y_predicted[0][0]\n",
        "\n",
        "    # Print do resultado\n",
        "    print(\"\\nTotal Vendas Real de 1 Seguro: {}\".format(total_vendas_real))\n",
        "    print(\"Total Vendas Previsto de 1 Seguro: {}\".format(total_vendas_previsto))\n",
        "\n",
        "    # Salvando o modelo\n",
        "    save_path = saver.save(session, \"modelos/modelo_treinado_v2.ckpt\") # checkpoint\n",
        "    print(\"\\nModelo salvo: {}\".format(save_path))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Treinamento Concluído\n",
            "\n",
            "Custo Final em Treinamento: 0.00017210739315487444\n",
            "Custo Final em Teste: 0.00026958619127981365\n",
            "\n",
            "Total Vendas Real de 1 Seguro: 247537.0\n",
            "Total Vendas Previsto de 1 Seguro: 251262.796875\n",
            "\n",
            "Modelo salvo: modelos/modelo_treinado_v2.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9pGMpiDtkfM_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Carregando o modelo a partir do checkpoint"
      ]
    },
    {
      "metadata": {
        "id": "s1KOG19BkdBb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9900ab7f-a25a-4756-f55a-7d49d052d876"
      },
      "cell_type": "code",
      "source": [
        "# Abrindo Sessão TensorFlow\n",
        "with tf.Session() as session:\n",
        "\n",
        "    # Restaurando o modelo\n",
        "    saver.restore(session, \"modelos/modelo_treinado_v2.ckpt\")\n",
        "    print(\"\\nModelo Restaurado\")\n",
        "\n",
        "    # File writer para tracking do progresso\n",
        "    training_writer = tf.summary.FileWriter(\"./logs/{}/training\".format(RUN_NAME), session.graph)\n",
        "    testing_writer = tf.summary.FileWriter(\"./logs/{}/testing\".format(RUN_NAME), session.graph)\n",
        "\n",
        "\n",
        "    final_training_cost = session.run(cost, feed_dict={X: X_scaled_treino, Y: Y_scaled_treino})\n",
        "    final_test_cost = session.run(cost, feed_dict={X: X_scaled_teste, Y: Y_scaled_teste})\n",
        "\n",
        "    print(\"\\nCusto Final em Treinamento: {}\".format(final_training_cost))\n",
        "    print(\"Custo Final em Teste: {}\".format(final_test_cost))\n",
        "\n",
        "    # Variável com valores previstos normalizados\n",
        "    Y_predicted_scaled = session.run(prediction, feed_dict={X:X_scaled_teste})\n",
        "\n",
        "    # Remove a escala\n",
        "    Y_predicted = Y_scaler.inverse_transform(Y_predicted_scaled)\n",
        "\n",
        "    # Coleta os dados reais e os valores previstos\n",
        "    total_vendas_real = dados_teste['total_vendas'].values[0]\n",
        "    total_vendas_previsto = Y_predicted[0][0]\n",
        "\n",
        "    # Print do resultado\n",
        "    print(\"\\nTotal Vendas Real de 1 Seguro: {}\".format(total_vendas_real))\n",
        "    print(\"Total Vendas Previsto de 1 Seguro: {}\".format(total_vendas_previsto))\n",
        "\n",
        "    # Salvando o modelo\n",
        "    # save_path = saver.save(session, \"modelos/modelo_treinado_v2.ckpt\")\n",
        "    # print(\"\\nModelo salvo: {}\".format(save_path))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from modelos/modelo_treinado_v2.ckpt\n",
            "\n",
            "Modelo Restaurado\n",
            "\n",
            "Custo Final em Treinamento: 0.00017210739315487444\n",
            "Custo Final em Teste: 0.00026958619127981365\n",
            "\n",
            "Total Vendas Real de 1 Seguro: 247537.0\n",
            "Total Vendas Previsto de 1 Seguro: 251262.796875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}