{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Data-Preparation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/LSTM/LSTM_Data_Preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "_MNJGZyzc48d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Como Preparar os Dados Para LSTMs?"
      ]
    },
    {
      "metadata": {
        "id": "BWAiwEPTc48f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Os dados para as previsões de sequências, muito provavelmente terão que ser padronizados antes do treinamento da rede. Isso vale para todos os modelos de redes neurais artificiais. Quando um modelo é treinado em dados com escalas diferentes, com um diferente range de valores, isso pode tornar o treinamento mais lento e alguns casos impedir a convergência da rede. Existem basicamente duas formas de ajustar a escala dos seus dados: Normalização e Padronização. Em ambos os casos podemos usar o Scikit-learn."
      ]
    },
    {
      "metadata": {
        "id": "Y0-CvXRlc48h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Preparação de Dados Numéricos"
      ]
    },
    {
      "metadata": {
        "id": "4mvZSXzsc48i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalização"
      ]
    },
    {
      "metadata": {
        "id": "0VpnC0Qcc48j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A normalização é um redimensionamento dos dados do intervalo original para que todos os valores fiquem dentro do\n",
        "intervalo de 0 e 1. A normalização exige que você conheça ou seja capaz de estimar com precisão valores observáveis mínimos e máximos. Você pode estimar esses valores a partir dos dados. Se a sua série estiver tendendo para cima ou para baixo, estimar esses valores esperados pode ser difícil e a normalização pode não ser o melhor método para usar em seu problema.\n",
        "\n",
        "Se um valor a ser escalado estiver fora dos limites dos valores mínimo e máximo, o valor resultante não estará no intervalo de 0 e 1. Você pode verificar essas observações antes e removê-los do conjunto de dados ou limitá-los ao valores máximos ou mínimos pré-definido. Você pode normalizar seu conjunto de dados usando funções do scikit-learn MinMaxScaler."
      ]
    },
    {
      "metadata": {
        "id": "aBPz7411c48k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "4f19ea47-b5a4-4740-c20d-ff2cdfb0819f"
      },
      "cell_type": "code",
      "source": [
        "from pandas import Series\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Definindo uma série\n",
        "data = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
        "series = Series(data)\n",
        "print(series)\n",
        "\n",
        "# Preparando os dados para normalização\n",
        "values = series.values\n",
        "values = values.reshape((len(values), 1))\n",
        "print('values reshaped')\n",
        "print(values)\n",
        "\n",
        "\n",
        "# Treinando os dados normalizados. \n",
        "# Para a normalização, usamos a função MinMaxScaler()\n",
        "# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler = scaler.fit(values)\n",
        "print('Min: %f, Max: %f' % (scaler.data_min_, scaler.data_max_))\n",
        "\n",
        "# Normaliza o dataset e imprime\n",
        "normalized = scaler.transform(values)\n",
        "print('normalized values')\n",
        "print(normalized)\n",
        "\n",
        "# Inverte a transformação e imprime\n",
        "inversed = scaler.inverse_transform(normalized)\n",
        "print('inversed_tranformed values')\n",
        "print(inversed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     10.0\n",
            "1     20.0\n",
            "2     30.0\n",
            "3     40.0\n",
            "4     50.0\n",
            "5     60.0\n",
            "6     70.0\n",
            "7     80.0\n",
            "8     90.0\n",
            "9    100.0\n",
            "dtype: float64\n",
            "values reshaped\n",
            "[[ 10.]\n",
            " [ 20.]\n",
            " [ 30.]\n",
            " [ 40.]\n",
            " [ 50.]\n",
            " [ 60.]\n",
            " [ 70.]\n",
            " [ 80.]\n",
            " [ 90.]\n",
            " [100.]]\n",
            "Min: 10.000000, Max: 100.000000\n",
            "normalized values\n",
            "[[0.        ]\n",
            " [0.11111111]\n",
            " [0.22222222]\n",
            " [0.33333333]\n",
            " [0.44444444]\n",
            " [0.55555556]\n",
            " [0.66666667]\n",
            " [0.77777778]\n",
            " [0.88888889]\n",
            " [1.        ]]\n",
            "inversed_tranformed values\n",
            "[[ 10.]\n",
            " [ 20.]\n",
            " [ 30.]\n",
            " [ 40.]\n",
            " [ 50.]\n",
            " [ 60.]\n",
            " [ 70.]\n",
            " [ 80.]\n",
            " [ 90.]\n",
            " [100.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "WVFcka5Cc48q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Padronização"
      ]
    },
    {
      "metadata": {
        "id": "KaBi2Nc0c48r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A padronização de um conjunto de dados envolve a reavaliação da distribuição de valores, de modo que a média de observação dos valores seja 0 e o desvio padrão seja 1. Como a normalização, a padronização pode ser útil, e até mesmo necessária em aprendizado e máquina quando seus dados têm valores de entrada com diferentes escalas. Padronização assume que suas observações são uma distribuição gaussiana (curva do sino). Se os dados não estiverem com uma distribuição normal, você ainda pode tentar a Padronização, mas o resultado pode não ser confiável."
      ]
    },
    {
      "metadata": {
        "id": "qiuONSr9c48s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "906ee2e2-654b-466e-9a65-3f9c911ffc1a"
      },
      "cell_type": "code",
      "source": [
        "from pandas import Series\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from math import sqrt\n",
        "\n",
        "# Definindo uma série\n",
        "data = [1.0, 5.5, 9.0, 2.6, 8.8, 3.0, 4.1, 7.9, 6.3]\n",
        "series = Series(data)\n",
        "print(series)\n",
        "\n",
        "# Preparando os dados para normalização\n",
        "values = series.values\n",
        "values = values.reshape((len(values), 1))\n",
        "\n",
        "# Treinando os dados normalizados. \n",
        "# Para a normalização, usamos a função StandardScaler()\n",
        "# http://scikit-learn.org/stable/modules/preprocessing.html\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(values)\n",
        "print('Média: %f, Desvio Padrão: %f' % (scaler.mean_, sqrt(scaler.var_)))\n",
        "\n",
        "# Normaliza o dataset e imprime\n",
        "standardized = scaler.transform(values)\n",
        "print(standardized)\n",
        "\n",
        "# Inverte a transformação e imprime\n",
        "inversed = scaler.inverse_transform(standardized)\n",
        "print(inversed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1.0\n",
            "1    5.5\n",
            "2    9.0\n",
            "3    2.6\n",
            "4    8.8\n",
            "5    3.0\n",
            "6    4.1\n",
            "7    7.9\n",
            "8    6.3\n",
            "dtype: float64\n",
            "Média: 5.355556, Desvio Padrão: 2.712568\n",
            "[[-1.60569456]\n",
            " [ 0.05325007]\n",
            " [ 1.34354035]\n",
            " [-1.01584758]\n",
            " [ 1.26980948]\n",
            " [-0.86838584]\n",
            " [-0.46286604]\n",
            " [ 0.93802055]\n",
            " [ 0.34817357]]\n",
            "[[1. ]\n",
            " [5.5]\n",
            " [9. ]\n",
            " [2.6]\n",
            " [8.8]\n",
            " [3. ]\n",
            " [4.1]\n",
            " [7.9]\n",
            " [6.3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kdrOwWwlc48x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Preparação de Dados Categóricos"
      ]
    },
    {
      "metadata": {
        "id": "hHEh_feec48y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Os dados categóricos são variáveis que contêm valores de labels em vez de valores numéricos. O número dos valores possíveis geralmente é limitado a um conjunto fixo. As variáveis categóricas geralmente são chamadas de nominais."
      ]
    },
    {
      "metadata": {
        "id": "ahnvzVhZc48y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As palavras em um texto podem ser consideradas dados categóricos, onde cada palavra é considerada uma categoria diferente. Além disso, cada letra em dados de texto pode ser considerada uma categoria. Problemas de previsão de sequência com entrada ou saída de texto podem ser considerados dados categóricos. Algumas categorias podem ter uma relação natural entre si, como uma ordem natural. Os dados categóricos devem ser convertidos em números quando\n",
        "trabalhando com LSTMs."
      ]
    },
    {
      "metadata": {
        "id": "y2rSeryGc48z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Integer Encoding"
      ]
    },
    {
      "metadata": {
        "id": "GTYFS2jcc481",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Como um primeiro passo, cada valor de categoria exclusivo é atribuído a um valor inteiro. Por exemplo, o vermelho é\n",
        "1, verde é 2 e azul é 3. Isso é chamado de codificação de rótulo ou uma codificação de número inteiro e é facilmente\n",
        "reversível. Para algumas variáveis, isso pode ser suficiente.\n",
        "\n",
        "Os valores inteiros têm uma relação natural ordenada entre si e os algoritmos de aprendizagem de máquina podem ser capazes de compreender e aproveitar esse relacionamento. "
      ]
    },
    {
      "metadata": {
        "id": "xdG1aO8Wc481",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One-Hot Encoding"
      ]
    },
    {
      "metadata": {
        "id": "5xhkCnzJc483",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para variáveis categóricas onde não existe relação ordinal, o Integer Encoding não é suficiente. Na verdade, usando essa codificação e permitindo que o modelo assuma uma ordenação natural entre categorias pode resultar em desempenho fraco ou resultados inesperados (previsões erradas entre categorias). Neste caso, One-Hot Encoding pode ser aplicada na representação de inteiros. Aqui é onde a variável codificada inteira é removida e uma nova variável binária é adicionada para cada valor inteiro. No exemplo de variável de cores, existem 3 categorias e, portanto, 3 binários\n",
        "são necessárias. Por exemplo, as cores citadas acima, seriam codificadas usando one-Hot da seguinte forma:\n",
        "\n",
        "* Vermelho - [1, 0 , 0]\n",
        "* Azul     - [0, 1, 0]\n",
        "* Verde    - [0, 0, 1]"
      ]
    },
    {
      "metadata": {
        "id": "puuub_Pqc484",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "07a50cf8-feda-44f0-c937-d27de391bf4d"
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Define os dados\n",
        "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
        "values = array(data)\n",
        "print(values)\n",
        "\n",
        "# Integer Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "print(\"Integer Encoding\")\n",
        "print(integer_encoded)\n",
        "print(\"\\n\")\n",
        "\n",
        "# One-Hot Encoding\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(\"One-Hot Encoding\")\n",
        "print(onehot_encoded)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Inverte o primeito exemplo\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm' 'hot']\n",
            "Integer Encoding\n",
            "[0 0 2 0 1 1 2 0 2 1]\n",
            "\n",
            "\n",
            "One-Hot Encoding\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n",
            "\n",
            "\n",
            "['cold']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "fCyqnpe-c48-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ao executar o exemplo, primeiro imprime a sequência de labels. Isto é seguido pela codificação em inteiros de cada label.\n",
        "\n",
        "Por padrão, a classe OneHotEncoder retornará uma codificação esparsa mais eficiente. Isso pode não ser adequado para algumas aplicações, como o uso com a biblioteca de aprendizado profundo do Keras. Nesse caso, desativamos o tipo de retorno esparso configurando o argumento sparse = false. Se recebermos uma previsão nesta codificação a quente de 3 valores, podemos facilmente inverter a transformação para o rótulo original.\n",
        "\n",
        "Podemos ainda usar a função NumPy argmax() para localizar o índice da coluna com o maior valor. Isso pode ser enviado ao LabelEncoder para calcular uma transformação inversa de volta para um rótulo de texto. Isto é demonstrado no final do exemplo com a transformação inversa do primeiro exemplo codificado a quente voltou ao valor do rótulo frio. Mais uma vez, note que a entrada foi formatado para legibilidade.\n"
      ]
    },
    {
      "metadata": {
        "id": "vD9S5Q7xc49A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preparação de Sequências Com Comprimentos Variados"
      ]
    },
    {
      "metadata": {
        "id": "Vb2hBUsWc49B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Padding"
      ]
    },
    {
      "metadata": {
        "id": "tM6RMNDec49C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1fbe5b27-d974-4467-b3fe-8f4e81fb636a"
      },
      "cell_type": "code",
      "source": [
        "# Pre-Sequence Padding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sequências\n",
        "sequences = [\n",
        "    [1, 2, 3, 4],\n",
        "       [1, 2, 3],\n",
        "             [1]\n",
        "    ]\n",
        "\n",
        "# Pad sequence\n",
        "padded = pad_sequences(sequences)\n",
        "print(padded)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3 4]\n",
            " [0 1 2 3]\n",
            " [0 0 0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nJurXfjsc49F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "bc9b2e81-9811-45a4-bbf8-eb297a66fcfd"
      },
      "cell_type": "code",
      "source": [
        "# Post-Sequence Padding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sequências\n",
        "sequences = [\n",
        "    [1, 2, 3, 4],\n",
        "       [1, 2, 3],\n",
        "             [1]\n",
        "    ]\n",
        "\n",
        "# Pad sequence\n",
        "padded = pad_sequences(sequences, padding='post')\n",
        "print(padded)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3 4]\n",
            " [1 2 3 0]\n",
            " [1 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BhwFUpB1c49L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Truncando Sequências"
      ]
    },
    {
      "metadata": {
        "id": "ewPzoFbDc49L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5ba3c471-5231-4b5a-a340-f59ce4963734"
      },
      "cell_type": "code",
      "source": [
        "# Pre-Sequence Truncate\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sequências\n",
        "sequences = [\n",
        "    [1, 2, 3, 4],\n",
        "       [1, 2, 3],\n",
        "             [1]\n",
        "    ]\n",
        "\n",
        "# Truncando sequências\n",
        "truncated= pad_sequences(sequences, maxlen=2)\n",
        "print(truncated)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3 4]\n",
            " [2 3]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W-pxcColc49R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cb331fe3-1b53-4dad-95e0-22fddb219cb2"
      },
      "cell_type": "code",
      "source": [
        "# Post-Sequence Truncate\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Sequências\n",
        "sequences = [\n",
        "    [1, 2, 3, 4],\n",
        "       [1, 2, 3],\n",
        "             [1]\n",
        "    ]\n",
        "\n",
        "# Truncando sequências\n",
        "truncated= pad_sequences(sequences, maxlen=2, truncating='post')\n",
        "print(truncated)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [1 2]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "erx8uPZ5c49Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Definindo Sequências - Shift"
      ]
    },
    {
      "metadata": {
        "id": "7PHTaAB-c49a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f8cd0fc0-74d2-4e46-a945-594a5b26a17a"
      },
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "# Define a sequência\n",
        "df = DataFrame()\n",
        "df['t'] = [x for x in range(10)]\n",
        "print(df)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   t\n",
            "0  0\n",
            "1  1\n",
            "2  2\n",
            "3  3\n",
            "4  4\n",
            "5  5\n",
            "6  6\n",
            "7  7\n",
            "8  8\n",
            "9  9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2fdly1DHc49f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "052a7961-9071-46bc-c773-4f5fc60d4544"
      },
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "# Define a sequência\n",
        "df = DataFrame()\n",
        "df['t'] = [x for x in range(10)]\n",
        "\n",
        "# Shift forward\n",
        "df['t-1'] = df['t'].shift(1)\n",
        "print(df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   t  t-1\n",
            "0  0  NaN\n",
            "1  1  0.0\n",
            "2  2  1.0\n",
            "3  3  2.0\n",
            "4  4  3.0\n",
            "5  5  4.0\n",
            "6  6  5.0\n",
            "7  7  6.0\n",
            "8  8  7.0\n",
            "9  9  8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dbWX4PGRc49i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4f8aea8d-b884-4878-fed5-b47ca5473a82"
      },
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "# Define a sequência\n",
        "df = DataFrame()\n",
        "df['t'] = [x for x in range(10)]\n",
        "\n",
        "# Shift backward\n",
        "df['t+1'] = df['t'].shift(-1)\n",
        "print(df)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   t  t+1\n",
            "0  0  1.0\n",
            "1  1  2.0\n",
            "2  2  3.0\n",
            "3  3  4.0\n",
            "4  4  5.0\n",
            "5  5  6.0\n",
            "6  6  7.0\n",
            "7  7  8.0\n",
            "8  8  9.0\n",
            "9  9  NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-T9RlQX5c49o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}