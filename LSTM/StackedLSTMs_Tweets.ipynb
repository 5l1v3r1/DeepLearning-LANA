{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackedLSTMs-Tweets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/LSTM/StackedLSTMs_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7a_1z1f0Xdyb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gerando Tweets com Stacked LSTMs \n",
        "\n",
        "Usaremos Tweets do Presidente dos EUA, Donald Trump, para treinar um modelo LSTM de 2 camadas e então ensinar o modelo a gerar tweets automaticamente.\n",
        "\n",
        "O conjunto de dados está disponível no site de compretições em Data Science <a href=\"https://www.kaggle.com/kingburrito666/better-donald-trump-tweets\">Kaggle</a> e foi extraído do Twitter de Donald Trump: https://twitter.com/realDonaldTrump"
      ]
    },
    {
      "metadata": {
        "id": "tYzTD4lcXdye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Feature Engineering\n",
        "\n",
        "Os dados de texto bruto não podem ser fornecidos diretamente no modelo LSTM. Nós devemos fazer engenharia dos atributos primeiro antes de podermos seguir para a etapa de modelagem."
      ]
    },
    {
      "metadata": {
        "id": "N0KV-RU7Xdyf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfLVE93SXdyk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0dfd1748-755c-4f97-aeaa-603af955ece0"
      },
      "cell_type": "code",
      "source": [
        "# Carregando o dataset\n",
        "!wget https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/LSTM/data/tweets.csv\n",
        "data = pd.read_csv('tweets.csv')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-23 01:44:03--  https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/LSTM/data/tweets.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1703362 (1.6M) [text/plain]\n",
            "Saving to: ‘tweets.csv’\n",
            "\n",
            "\rtweets.csv            0%[                    ]       0  --.-KB/s               \rtweets.csv          100%[===================>]   1.62M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-01-23 01:44:03 (47.7 MB/s) - ‘tweets.csv’ saved [1703362/1703362]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zp4FUxeRXdyo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "eb78a8a4-3f84-4e86-aaff-3cdb1fd93a91"
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Tweet_Text</th>\n",
              "      <th>Type</th>\n",
              "      <th>Media_Type</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>Tweet_Id</th>\n",
              "      <th>Tweet_Url</th>\n",
              "      <th>twt_favourites_IS_THIS_LIKE_QUESTION_MARK</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>15:26:37</td>\n",
              "      <td>Today we express our deepest gratitude to all ...</td>\n",
              "      <td>text</td>\n",
              "      <td>photo</td>\n",
              "      <td>ThankAVet</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>127213</td>\n",
              "      <td>41112</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>13:33:35</td>\n",
              "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>141527</td>\n",
              "      <td>28654</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>11:14:20</td>\n",
              "      <td>Love the fact that the small groups of protest...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>183729</td>\n",
              "      <td>50039</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>2:19:44</td>\n",
              "      <td>Just had a very open and successful presidenti...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
              "      <td>214001</td>\n",
              "      <td>67010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>2:10:46</td>\n",
              "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
              "      <td>178499</td>\n",
              "      <td>36688</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date      Time                                         Tweet_Text  \\\n",
              "0  16-11-11  15:26:37  Today we express our deepest gratitude to all ...   \n",
              "1  16-11-11  13:33:35  Busy day planned in New York. Will soon be mak...   \n",
              "2  16-11-11  11:14:20  Love the fact that the small groups of protest...   \n",
              "3  16-11-11   2:19:44  Just had a very open and successful presidenti...   \n",
              "4  16-11-11   2:10:46  A fantastic day in D.C. Met with President Oba...   \n",
              "\n",
              "   Type Media_Type   Hashtags      Tweet_Id  \\\n",
              "0  text      photo  ThankAVet  7.970000e+17   \n",
              "1  text        NaN        NaN  7.970000e+17   \n",
              "2  text        NaN        NaN  7.970000e+17   \n",
              "3  text        NaN        NaN  7.970000e+17   \n",
              "4  text        NaN        NaN  7.970000e+17   \n",
              "\n",
              "                                           Tweet_Url  \\\n",
              "0  https://twitter.com/realDonaldTrump/status/797...   \n",
              "1  https://twitter.com/realDonaldTrump/status/797...   \n",
              "2  https://twitter.com/realDonaldTrump/status/797...   \n",
              "3  https://twitter.com/realDonaldTrump/status/796...   \n",
              "4  https://twitter.com/realDonaldTrump/status/796...   \n",
              "\n",
              "   twt_favourites_IS_THIS_LIKE_QUESTION_MARK  Retweets  Unnamed: 10  \\\n",
              "0                                     127213     41112          NaN   \n",
              "1                                     141527     28654          NaN   \n",
              "2                                     183729     50039          NaN   \n",
              "3                                     214001     67010          NaN   \n",
              "4                                     178499     36688          NaN   \n",
              "\n",
              "   Unnamed: 11  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "2          NaN  \n",
              "3          NaN  \n",
              "4          NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "PAISsu82Xdyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tudo o que precisamos é o campo ** Tweet_Text **. Vamos combinar todas as linhas para criar um corpus de texto, concatenando tweets, mas separando-os com duas novas linhas:"
      ]
    },
    {
      "metadata": {
        "id": "3T_lga7IXdyv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e401d029-6857-4779-8090-7b0d3f91bd46"
      },
      "cell_type": "code",
      "source": [
        "text = '\\n\\n'.join(data['Tweet_Text'].values)\n",
        "print(text[:400])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today we express our deepest gratitude to all those who have served in our armed forces. #ThankAVet https://t.co/wPk7QWpK8Z\n",
            "\n",
            "Busy day planned in New York. Will soon be making some very important decisions on the people who will be running our government!\n",
            "\n",
            "Love the fact that the small groups of protesters last night have passion for our great country. We will all come together and be proud!\n",
            "\n",
            "Just h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eZetk8a8Xdy0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para reduzir o tamanho do nosso espaço de recursos e o tempo de treinamento, removemos caracteres raros:"
      ]
    },
    {
      "metadata": {
        "id": "TEVyMKETXdy2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hDM3j5RLXdy4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cntr = Counter(text)\n",
        "rare = list(np.asarray(list(cntr.keys()))[np.asarray(list(cntr.values())) < 300])\n",
        "for c in rare:\n",
        "    text = re.sub('[' + c + ']', '', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-B4De7VqXdy6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui está como o início do corpus se parece:"
      ]
    },
    {
      "metadata": {
        "id": "B_EIa7hzXdy8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "766fc48f-2a93-47b2-c17e-36163e72e75f"
      },
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today we express our deepest gratitude to all those who have served in our armed forces. #ThankAVet https://t.co/wPk7QWpK8Z\n",
            "\n",
            "Busy day planned in New York. Will soon be making some very important decisions on the people who will be running our government!\n",
            "\n",
            "Love the fact that the small groups of protesters last night have passion for our great country. We will all come together and be proud!\n",
            "\n",
            "Just had a very open and successful presidential election. Now professional protesters, incited by the media, are protesting. Very unfair!\n",
            "\n",
            "A fantastic day in D.C. Met with President Obama for first time. Really good meeting, great chemistry. Melania liked Mrs. O a lot!\n",
            "\n",
            "Happy 241st birthday to the U.S. Marine Corps! Thank you for your service!! https://t.co/Lz2dhrXzo4\n",
            "\n",
            "Such a beautiful and important evening! The forgotten man and woman will never be forgotten again. We will all come together as never before\n",
            "\n",
            "Watching the returns at 9:45pm.\n",
            "#ElectionNight #MAGA__ https://t.co/HfuJeRZbod\n",
            "\n",
            "RT @IvankaT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sGl6pahAXdzA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O corpus tem 857177 caracteres e há 78 caracteres únicos dentro dele:"
      ]
    },
    {
      "metadata": {
        "id": "7iToAcr0XdzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa129218-cec9-4b42-df3d-9dfcfe10f8a6"
      },
      "cell_type": "code",
      "source": [
        "print('Total de Caracteres no Corpus: {:,d}'.format(len(text)))\n",
        "chars = sorted(list(set(text)))\n",
        "print('Total de Caracteres Únicos:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de Caracteres no Corpus: 857,177\n",
            "Total de Caracteres Únicos: 78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SIMW0kcBXdzF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora, vamos cortar o texto em sequências semi-redundantes de caracteres * maxlen * para que ele possa ser alimentado em um modelo LSTM:"
      ]
    },
    {
      "metadata": {
        "id": "qdPJts2UXdzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9924f311-3bb6-4f5e-cf18-bd3ec91542d0"
      },
      "cell_type": "code",
      "source": [
        "maxlen = 50\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Número de Sequências: {:,d}'.format(len(sentences)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de Sequências: 285,709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lXME3bcKXdzJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Então, vamos vetorizar as frases:"
      ]
    },
    {
      "metadata": {
        "id": "WupC7Tp7XdzK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YcynuedVXdzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "06931404-246b-4224-b447-4e71714cb91a"
      },
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "nj-ePwteXdzP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Modelo Generativo"
      ]
    },
    {
      "metadata": {
        "id": "A6m4RsD_XdzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1369bbfd-5249-41ac-e5f9-599d17e3b079"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BoYuMtY2XdzX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos criar algumas funções reutilizáveis que podem que podem gerar texto para nosso modelo generativo."
      ]
    },
    {
      "metadata": {
        "id": "0KYXEnKmXdzY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cntr = Counter(text)\n",
        "cntr_sum = sum(cntr.values())\n",
        "char_probs = list(map(lambda c: cntr[c] / cntr_sum, chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6ZjLO4qXdzf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = preds / np.sum(preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BMb34_lsXdzi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate(model, length, seed=''):\n",
        "    \n",
        "    if len(seed) != 0:\n",
        "        sys.stdout.write(seed)\n",
        "    \n",
        "    generated = seed\n",
        "    sentence = seed\n",
        "    \n",
        "    for i in range(length):\n",
        "        x = np.zeros((1, maxlen, len(chars)))\n",
        "\n",
        "        padding = maxlen - len(sentence)\n",
        "        \n",
        "        for i in range(padding):\n",
        "            x[0, i] = char_probs # pad usando os anteriores\n",
        "            \n",
        "        for t, char in enumerate(sentence):\n",
        "            x[0, padding + t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        sentence = sentence[1:] + next_char\n",
        "        generated += next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "        \n",
        "    return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w-Avv-3gXdzm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora, vamos construir o grafo da nossa rede neural. Depois, vamos treinar nosso modelo e exibir algumas amostras em todas as épocas. No final do treinamento, salvamos o modelo para que possamos reutilizá-lo rapidamente no futuro."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "IcymuMQWXdzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "dbb00200-c0d3-4723-e6a6-e7e6a2b1e900"
      },
      "cell_type": "code",
      "source": [
        "from os.path import isfile\n",
        "from keras.models import load_model\n",
        "\n",
        "!rm stacked-lstm-2-layers-128-hidden.h5\n",
        "!wget https://github.com/vladimiralencar/DeepLearning-LANA/raw/master/LSTM/data/stacked-lstm-2-layers-128-hidden.h5\n",
        "\n",
        "MODEL_PATH = 'stacked-lstm-2-layers-128-hidden.h5'\n",
        "\n",
        "if isfile(MODEL_PATH):\n",
        "    model = load_model(MODEL_PATH)\n",
        "else:\n",
        "    N_HIDDEN = 128\n",
        "\n",
        "    # Modelo\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(N_HIDDEN, dropout = 0.1, input_shape = (maxlen, len(chars)), return_sequences = True))\n",
        "    model.add(LSTM(N_HIDDEN, dropout = 0.1))\n",
        "    model.add(Dense(len(chars), activation = 'softmax'))\n",
        "\n",
        "    # Otimizador\n",
        "    optimizer = RMSprop(lr = 0.01)\n",
        "    \n",
        "    # Compilação\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n",
        "\n",
        "    # Imprime amostras a cada época\n",
        "    for iteration in range(1, 40):\n",
        "        print('\\n')\n",
        "        print('-' * 50)\n",
        "        print('\\nIteração', iteration)\n",
        "        model.fit(X, y, batch_size=3000, epochs=1)\n",
        "\n",
        "        print('\\n-------------------- Tweet Gerado Pelo Modelo Nesta Iteração ---------------------\\n')\n",
        "\n",
        "        rand = np.random.randint(len(text) - maxlen)\n",
        "        seed = text[rand:rand + maxlen]\n",
        "        generate(model, 400, seed)\n",
        "\n",
        "    model.save(MODEL_PATH)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-01-23 01:48:09--  https://github.com/vladimiralencar/DeepLearning-LANA/raw/master/LSTM/data/stacked-lstm-2-layers-128-hidden.h5\n",
            "Resolving github.com (github.com)... 140.82.118.3, 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/LSTM/data/stacked-lstm-2-layers-128-hidden.h5 [following]\n",
            "--2019-01-23 01:48:09--  https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/LSTM/data/stacked-lstm-2-layers-128-hidden.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2004136 (1.9M) [application/octet-stream]\n",
            "Saving to: ‘stacked-lstm-2-layers-128-hidden.h5’\n",
            "\n",
            "\r          stacked-l   0%[                    ]       0  --.-KB/s               \rstacked-lstm-2-laye 100%[===================>]   1.91M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-01-23 01:48:09 (50.4 MB/s) - ‘stacked-lstm-2-layers-128-hidden.h5’ saved [2004136/2004136]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
            "  warnings.warn('Error in loading the saved optimizer '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YW5Ix_mhXdzp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora vamos experimentar o modelo!\n",
        "\n",
        "Usando a primeira frase deste <a href='https://twitter.com/realDonaldTrump/status/890764622852173826'>tweet</a> como semente, vamos tentar continuar a frase de Trump e ver quais coisas interessantes o nosso modelo pode dizer:"
      ]
    },
    {
      "metadata": {
        "id": "_lPQ9dFdXdzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "06ef7e94-a699-4d4e-a937-3a82f8c76fc6"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'Go Republican Senators, Go!'\n",
        "_ = generate(model, 200, sample_tweet_start)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go Republican Senators, Go! Polling - theyWith, and insteacing\n",
            "\n",
            "\n",
            "\n",
            "Can do what you cant wait will disguard their #Ispairwitb, in her, Clinton is beuting be, you are great. We then edwatcyl mevided be thoughts!\n",
            "\n",
            "RT @TheNastan25 @"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "68Oe2d0QXdzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1465
        },
        "outputId": "ffb270ec-d93e-4f28-b2ad-bd7d98e0e4fc"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'immigration'\n",
        "for i in range(10):\n",
        "    _ = generate(model, 200, sample_tweet_start)\n",
        "    print('\\n=========================================\\n')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "immigration I watched #Mogey #MakeAmericaGurhts #MakeAmericaGU. #CrookedHillary seon you, we are not to see that Issue? @SaralPrump: .@StateForTMrisy #FIPrece Prayers - anyone it we can down ower started! Genera\n",
            "=========================================\n",
            "\n",
            "immigration #ThankABir #Bruz they she will her watching they hope register @annennahoe #ICNND!\n",
            "\n",
            "Lating Ohioss #1 @realDonaldTrump #Trump2016\n",
            "\n",
            "Thank you! #Trump2016 @jick_bal3: CNN has in the U.S.\n",
            "\n",
            "RT @ChrisCulid\n",
            "=========================================\n",
            "\n",
            "immigration Trump on increase Crooked Hillary Clintons. Great Hillary, this news Donald. You are almosticianCore: We cannot ewnel https://t.coHaPresann @tedcruz:\n",
            "TRUMP:\n",
            "https://t.coSeSher atherfully #2016\n",
            "\n",
            "Thank\n",
            "=========================================\n",
            "\n",
            "immigrationa_ strick #_HallaryColumh\n",
            "\n",
            "RT @ABC @UnionLeam 40 Paris: https://t.coL2Ami in 1002- @RealHelkop RANS a funness amazing crowd! This the werss. Way a deal. CampPertrop_\n",
            "Watched 1 #WNN newspead! #VoteTrum\n",
            "=========================================\n",
            "\n",
            "immigrationaus opening needs are Tited, Mexico. Helitics what just needs TEA!!!! Thank you\n",
            "Lets Dend Great subbost been anwuldy they would be in 2016.\n",
            "WOMEN #Scope\n",
            "\n",
            "\"@thurgChrody\n",
            "\n",
            "CLUNTON MORE NEES DARISY\n",
            "https:\n",
            "=========================================\n",
            "\n",
            "immigration: @realDonaldTrump I ahead who has never be a MOW!\n",
            "\n",
            "I have higher out of me in Iowa Last campaign, Get if I imporemence862 Trump is the newseat crefengenks standing a joe_\n",
            "\n",
            "\"\"MoStipers2016\"  Makes gre\n",
            "=========================================\n",
            "\n",
            "immigration\n",
            "\n",
            "\"@Billork: #NYPrimarysFLand, whele we ted #GOP.!\"\n",
            "\n",
            "\"@htiltmcoogation #MakeAmericaGreat #10pmertical @Reperres #CNNOW!!\n",
            "https://t.cohCPINGE\n",
            "https://t.coSty10 @last_Crevest Medicarence: Dessiancess1 C\n",
            "=========================================\n",
            "\n",
            "immigration: https://t.co/PKetthine would totally Rubio Priemer\n",
            "\n",
            "\"@BirdeeMather Americans http://t.co/WMSM\n",
            "\n",
            "I have attacked your USA..\n",
            "\n",
            "\"@MattuelDen #MakeAmericaGurhthe #DrainTheSwamp  @LandonDebate 2016!!!\"\n",
            "\n",
            "\"@\n",
            "=========================================\n",
            "\n",
            "immigration\n",
            "\"LyinOLE: Very compens unfiewtland excited Dralnars. Should sen our needs\n",
            "\n",
            "RT @LSneZBSH\n",
            "TRUTHIUSS!#mTPC\n",
            "https://t.cohXoT: https://t.co/ls516\n",
            "\n",
            "Thank you for the United #MAGA\n",
            "\n",
            "New HAJDERS #RATU:_\n",
            "https\n",
            "=========================================\n",
            "\n",
            "immigration on off.\n",
            "\n",
            "\"@sconlingfor\n",
            "\n",
            "\"@tedcmaliess say the respected them we need you very since Jeb Bush, it, as way! #Trump2016\n",
            "\n",
            "RT @DenSboushers : you attacks from President Obama Media Clinton Sanders this mo\n",
            "=========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zOECmbWUXdzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'America'\n",
        "for i in range(10):\n",
        "    _ = generate(model, 200, sample_tweet_start)\n",
        "    print('\\n=========================================\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nFTqZ5BlXdzz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1533
        },
        "outputId": "6e75d957-f71d-4dab-9eee-2d011b62adba"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'China'\n",
        "for i in range(10):\n",
        "    _ = generate(model, 200, sample_tweet_start)\n",
        "    print('\\n=========================================\\n')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chinastenfer hit will devated\n",
            "#MakeAmerica_ Thad former he most just were http:/2F016 TRUMP Dicemene Mirdley #BigLead https: CNN Zecal Ragins: https:/5t0 Make Americen 2006 TRUMP2016 KOU ATpringbam Get the\n",
            "=========================================\n",
            "\n",
            "China the likes hell  @CNNSOS08: Debate Jeb ABA OUT cooker  @realDonald8Traumed #MakeAmerAcal Make Ad Nation #MakeAmerMcarson: https:_It\n",
            "#Trump: Team in @megyn 40 in Joe News Trump your thuge will leads Sh\n",
            "=========================================\n",
            "\n",
            "China\n",
            "\n",
            "\"@Rkkndmanoge upman #Backersz\n",
            "\n",
            "I has get women\n",
            "\n",
            ".@FrankAmenoms The @realDin Estable #18 of Carsona: Xm_ http:_ \n",
            "\n",
            "Cwan!\n",
            "\n",
            "RT @TheRFIRSED   http:/2016 #LastUr, Hen illegatienamong illege_ http:/2016 @r\n",
            "=========================================\n",
            "\n",
            "China disgrace:\n",
            "https: https: @FoxNews\n",
            "\n",
            "I will be in he they lead wontera4ze Away #Trump 5 http:/6016: Trump Congres Trump 10.9 http:/hippapier: UNDE Clevel https:\n",
            "_\"\n",
            "\n",
            "\"@heafhenndy #SNL@@CNBC Blacked @foxa\n",
            "=========================================\n",
            "\n",
            "China shown #Trump, @Ridgy http:_  http:/2-16 #SCP @chucklier\n",
            "\n",
            "Just http:/6 This very This 434 Medicst\n",
            "\n",
            "\"@jesfuckes 4 excepeon offices, @realDongly _badica\n",
            "\n",
            "Crooker disastey @wider @inCheck Trump: FBV Cong\n",
            "=========================================\n",
            "\n",
            "China on CNBI #MAGA____/_http:_3 #WEDAND We needs  350,030 person\n",
            "\n",
            "We cluen:\n",
            "#Trump! Got Vidgoy\n",
            "\n",
            "\"@peyplest very will stop #Aderic_\"\n",
            "\n",
            "Join Obama get Trump TRUMP @CBSNew Supmer MakesChe EndersBs vets #Trump\n",
            "=========================================\n",
            "\n",
            "China _n: @realDy http:/2!\n",
            "\n",
            "IT in Agains\n",
            "\n",
            "\"@oneCLY on State-racked: Trump is Rebias\n",
            "\n",
            "\"@dem_cet:\n",
            "https:_6\n",
            "\n",
            "Wow, They State said #DemDebate #1 me. Here\n",
            "\n",
            "Eiadly3 @AnnCoBe @WSJ DH hear Mexically gone Maucial J\n",
            "=========================================\n",
            "\n",
            "China sakings Quinnic:\n",
            "\n",
            "\"@londey #MakeAmerice:\n",
            "#Debate Nevada\n",
            "\n",
            "#MrITAP FOX norm @realDis 19. He will jeb amorone Beach: Ohlam: https: https: knewa: https:_  https: http:_  THANKINH\n",
            "\n",
            "\"@gretated #Trump has a\n",
            "=========================================\n",
            "\n",
            "China3se: Just NYWY #MakeAmerics۪s greaters: we will http:_\n",
            "\n",
            "Another says 60-_\n",
            "\n",
            "A hot debate Off Dens @Timker Demandy\n",
            "\n",
            "\"@sheongmeetic 10 be won, he killed 11_48i62 #PR\n",
            "@Waynes Great #MikeAper Kedbuy highly\n",
            "=========================================\n",
            "\n",
            "China should we seid of leads 4 now, Presanders Needs Trump Washings exocus2000 \"Trump ApproJs #WIPrince 000pinge will #Trump Sec.. http:/2016 http:/https:_\n",
            "\n",
            "Join #VoteTruth if ALLE: RUSS #Make All of TRUM\n",
            "=========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KAYfZKxYXdz4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1499
        },
        "outputId": "db4de9e2-8698-4779-85df-270ac9fc6dac"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'Democratic'\n",
        "for i in range(10):\n",
        "    _ = generate(model, 200, sample_tweet_start)\n",
        "    print('\\n=========================================\\n')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Democratic\n",
            "\n",
            "Crooked Financials just be massive speech when AbL &amp; T.VANG supporters They strong stopfed\n",
            "Beliess BOC will MOVEMENT IN THE AND THUTIO!\n",
            "#MakeAmerica: #SepsJeston, Dogal was subjickers: https://t\n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "\n",
            "Get out in just really success the RYC rest evening story comes Trump Voter, https://t.cohZay or Mr. Interview #Bateres2 @JebBush American Departy #GOPDebates #TrumpLeash #BigLeagytI VOTE #VPDebates\n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "\n",
            "New @GWS @MarkSTrump @Holothelove says and Ire looked Hey suprosting president slould have need to bad over #sed @fightlebDand Trump.8p @RockDFUSA #WHC #TrumpInam &amp; RIcL IN TRUMP\"\n",
            "\n",
            "\"@JoeDICUS &a\n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "\n",
            "RT @TeamTrump: Mikl against they heads for self and they on evening it would do them heard 26\n",
            "\n",
            "Crooked Hillary Clintonsw Get the\n",
            "Dems will remember true--IT, Behn Rue--\n",
            "\n",
            "\"@Jichina_ #MakeAmericaFyree\n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "\n",
            "Why would re and other clars devistuages: https://t.co/XaD I will interviewed Bether! Lutc_\n",
            "\n",
            "I will be &amp; netapeys Reluting Secrate recording and feed of so their Mainhast #MakeAmerica\n",
            "\n",
            "\"@Trumpet\n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "\n",
            "Thank you!\"\n",
            "\n",
            "\"@Dicklint111- #MakeAmerica_ http://t.cohqXlet: https://t.cohvTrumps #MakeAmerica_ https://t.co/fAERY POINS WILL! Goodon tax Partyllics\"  Great\"\n",
            "\n",
            "\"@calmim15:_\n",
            "\n",
            "Just lie: dealing about T\n",
            "=========================================\n",
            "\n",
            "Democratics_ #MAGA_\n",
            "https://t.cohMtJloww1466\n",
            "\n",
            "Thank you apthak 802!\n",
            "#Debates2016 #MakeAmerica\n",
            "@MillariCl Ads on #1 when I OR is gets &amp; watching women oser who need will be many dume &amp; OWNENK IT NOT: htt\n",
            "=========================================\n",
            "\n",
            "Democratics:\n",
            "https://t.cohT\n",
            "\n",
            "RT @Lin_sichom #MakeAmerica_\n",
            "\n",
            "Thank you!\n",
            "They WILL MAKE AMERICA #MADE: https://t.co/AChase Nets!\n",
            "\n",
            "\"@DensvachGoap: get you at - Fox People_ Just create, suw! #Trump2016\"\n",
            "\n",
            "\"@megylebam\n",
            "=========================================\n",
            "\n",
            "Democraticos:_ https://t.co/XRABOUS\n",
            "\n",
            "John here campaign ettlaces wealong is netwryhed TweeTimes Fantas: otherr of woman. @NEORA4\n",
            "\n",
            "\"@laul_gynj13 People Warney: https://t.co/2CIRAT!E Truppork, but jeb being care \n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "\n",
            " https://t.cohAr #LEADERI TRUMP OF 10. Handed Ad Strong! #30pm DRUDGE SPREADIDT BOUG GREAT! Thank you!\"\n",
            "\n",
            "\"@hell_Concon-herela days with @nytimesShow! #MakeAmericaF 179 Manitale Det mean!\n",
            "\n",
            "Chankingis\n",
            "=========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "utZGnEAeXdz-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}