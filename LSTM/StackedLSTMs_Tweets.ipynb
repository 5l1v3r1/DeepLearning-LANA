{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackedLSTMs-Tweets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/LSTM/StackedLSTMs_Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7a_1z1f0Xdyb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Gerando Tweets com Stacked LSTMs \n",
        "\n",
        "Usaremos Tweets do Presidente dos EUA, Donald Trump, para treinar um modelo LSTM de 2 camadas e então ensinar o modelo a gerar tweets automaticamente.\n",
        "\n",
        "O conjunto de dados está disponível no site de compretições em Data Science <a href=\"https://www.kaggle.com/kingburrito666/better-donald-trump-tweets\">Kaggle</a> e foi extraído do Twitter de Donald Trump: https://twitter.com/realDonaldTrump"
      ]
    },
    {
      "metadata": {
        "id": "tYzTD4lcXdye",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Feature Engineering\n",
        "\n",
        "Os dados de texto bruto não podem ser fornecidos diretamente no modelo LSTM. Nós devemos fazer engenharia dos atributos primeiro antes de podermos seguir para a etapa de modelagem."
      ]
    },
    {
      "metadata": {
        "id": "N0KV-RU7Xdyf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YfLVE93SXdyk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Carregando o dataset\n",
        "data = pd.read_csv('tweets.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zp4FUxeRXdyo",
        "colab_type": "code",
        "colab": {},
        "outputId": "fb1905a8-7841-43a3-a3c0-d5e7e19b1848"
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Tweet_Text</th>\n",
              "      <th>Type</th>\n",
              "      <th>Media_Type</th>\n",
              "      <th>Hashtags</th>\n",
              "      <th>Tweet_Id</th>\n",
              "      <th>Tweet_Url</th>\n",
              "      <th>twt_favourites_IS_THIS_LIKE_QUESTION_MARK</th>\n",
              "      <th>Retweets</th>\n",
              "      <th>Unnamed: 10</th>\n",
              "      <th>Unnamed: 11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>15:26:37</td>\n",
              "      <td>Today we express our deepest gratitude to all ...</td>\n",
              "      <td>text</td>\n",
              "      <td>photo</td>\n",
              "      <td>ThankAVet</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>127213</td>\n",
              "      <td>41112</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>13:33:35</td>\n",
              "      <td>Busy day planned in New York. Will soon be mak...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>141527</td>\n",
              "      <td>28654</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>11:14:20</td>\n",
              "      <td>Love the fact that the small groups of protest...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/797...</td>\n",
              "      <td>183729</td>\n",
              "      <td>50039</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>2:19:44</td>\n",
              "      <td>Just had a very open and successful presidenti...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
              "      <td>214001</td>\n",
              "      <td>67010</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>16-11-11</td>\n",
              "      <td>2:10:46</td>\n",
              "      <td>A fantastic day in D.C. Met with President Oba...</td>\n",
              "      <td>text</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.970000e+17</td>\n",
              "      <td>https://twitter.com/realDonaldTrump/status/796...</td>\n",
              "      <td>178499</td>\n",
              "      <td>36688</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Date      Time                                         Tweet_Text  \\\n",
              "0  16-11-11  15:26:37  Today we express our deepest gratitude to all ...   \n",
              "1  16-11-11  13:33:35  Busy day planned in New York. Will soon be mak...   \n",
              "2  16-11-11  11:14:20  Love the fact that the small groups of protest...   \n",
              "3  16-11-11   2:19:44  Just had a very open and successful presidenti...   \n",
              "4  16-11-11   2:10:46  A fantastic day in D.C. Met with President Oba...   \n",
              "\n",
              "   Type Media_Type   Hashtags      Tweet_Id  \\\n",
              "0  text      photo  ThankAVet  7.970000e+17   \n",
              "1  text        NaN        NaN  7.970000e+17   \n",
              "2  text        NaN        NaN  7.970000e+17   \n",
              "3  text        NaN        NaN  7.970000e+17   \n",
              "4  text        NaN        NaN  7.970000e+17   \n",
              "\n",
              "                                           Tweet_Url  \\\n",
              "0  https://twitter.com/realDonaldTrump/status/797...   \n",
              "1  https://twitter.com/realDonaldTrump/status/797...   \n",
              "2  https://twitter.com/realDonaldTrump/status/797...   \n",
              "3  https://twitter.com/realDonaldTrump/status/796...   \n",
              "4  https://twitter.com/realDonaldTrump/status/796...   \n",
              "\n",
              "   twt_favourites_IS_THIS_LIKE_QUESTION_MARK  Retweets  Unnamed: 10  \\\n",
              "0                                     127213     41112          NaN   \n",
              "1                                     141527     28654          NaN   \n",
              "2                                     183729     50039          NaN   \n",
              "3                                     214001     67010          NaN   \n",
              "4                                     178499     36688          NaN   \n",
              "\n",
              "   Unnamed: 11  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "2          NaN  \n",
              "3          NaN  \n",
              "4          NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "PAISsu82Xdyv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tudo o que precisamos é o campo ** Tweet_Text **. Vamos combinar todas as linhas para criar um corpus de texto, concatenando tweets, mas separando-os com duas novas linhas:"
      ]
    },
    {
      "metadata": {
        "id": "3T_lga7IXdyv",
        "colab_type": "code",
        "colab": {},
        "outputId": "aa1fae59-a54d-4886-bf12-7c634443efc0"
      },
      "cell_type": "code",
      "source": [
        "text = '\\n\\n'.join(data['Tweet_Text'].values)\n",
        "print(text[:400])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today we express our deepest gratitude to all those who have served in our armed forces. #ThankAVet https://t.co/wPk7QWpK8Z\n",
            "\n",
            "Busy day planned in New York. Will soon be making some very important decisions on the people who will be running our government!\n",
            "\n",
            "Love the fact that the small groups of protesters last night have passion for our great country. We will all come together and be proud!\n",
            "\n",
            "Just h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eZetk8a8Xdy0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para reduzir o tamanho do nosso espaço de recursos e o tempo de treinamento, removemos caracteres raros:"
      ]
    },
    {
      "metadata": {
        "id": "TEVyMKETXdy2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hDM3j5RLXdy4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cntr = Counter(text)\n",
        "rare = list(np.asarray(list(cntr.keys()))[np.asarray(list(cntr.values())) < 300])\n",
        "for c in rare:\n",
        "    text = re.sub('[' + c + ']', '', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-B4De7VqXdy6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Aqui está como o início do corpus se parece:"
      ]
    },
    {
      "metadata": {
        "id": "B_EIa7hzXdy8",
        "colab_type": "code",
        "colab": {},
        "outputId": "53add0dc-7f13-4d9e-feb5-4e8f88b6f3b9"
      },
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Today we express our deepest gratitude to all those who have served in our armed forces. #ThankAVet https://t.co/wPk7QWpK8Z\n",
            "\n",
            "Busy day planned in New York. Will soon be making some very important decisions on the people who will be running our government!\n",
            "\n",
            "Love the fact that the small groups of protesters last night have passion for our great country. We will all come together and be proud!\n",
            "\n",
            "Just had a very open and successful presidential election. Now professional protesters, incited by the media, are protesting. Very unfair!\n",
            "\n",
            "A fantastic day in D.C. Met with President Obama for first time. Really good meeting, great chemistry. Melania liked Mrs. O a lot!\n",
            "\n",
            "Happy 241st birthday to the U.S. Marine Corps! Thank you for your service!! https://t.co/Lz2dhrXzo4\n",
            "\n",
            "Such a beautiful and important evening! The forgotten man and woman will never be forgotten again. We will all come together as never before\n",
            "\n",
            "Watching the returns at 9:45pm.\n",
            "#ElectionNight #MAGA__ https://t.co/HfuJeRZbod\n",
            "\n",
            "RT @IvankaT\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sGl6pahAXdzA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O corpus tem 857177 caracteres e há 78 caracteres únicos dentro dele:"
      ]
    },
    {
      "metadata": {
        "id": "7iToAcr0XdzB",
        "colab_type": "code",
        "colab": {},
        "outputId": "bc62d42c-d81a-406f-d095-12a5cf04a313"
      },
      "cell_type": "code",
      "source": [
        "print('Total de Caracteres no Corpus: {:,d}'.format(len(text)))\n",
        "chars = sorted(list(set(text)))\n",
        "print('Total de Caracteres Únicos:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total de Caracteres no Corpus: 857,177\n",
            "Total de Caracteres Únicos: 78\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SIMW0kcBXdzF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora, vamos cortar o texto em sequências semi-redundantes de caracteres * maxlen * para que ele possa ser alimentado em um modelo LSTM:"
      ]
    },
    {
      "metadata": {
        "id": "qdPJts2UXdzG",
        "colab_type": "code",
        "colab": {},
        "outputId": "21ccecf9-364e-4917-8d91-51ef211e4e07"
      },
      "cell_type": "code",
      "source": [
        "maxlen = 50\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('Número de Sequências: {:,d}'.format(len(sentences)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Número de Sequências: 285,709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lXME3bcKXdzJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Então, vamos vetorizar as frases:"
      ]
    },
    {
      "metadata": {
        "id": "WupC7Tp7XdzK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YcynuedVXdzM",
        "colab_type": "code",
        "colab": {},
        "outputId": "4ac4176b-5409-49aa-9bd1-d3ae3fe8258b"
      },
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ..., \n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]], dtype=bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "nj-ePwteXdzP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Modelo Generativo"
      ]
    },
    {
      "metadata": {
        "id": "A6m4RsD_XdzR",
        "colab_type": "code",
        "colab": {},
        "outputId": "8fb5c1a4-6ec4-446d-dc8f-57e7931ebfe5"
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import sys\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "BoYuMtY2XdzX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Vamos criar algumas funções reutilizáveis que podem que podem gerar texto para nosso modelo generativo."
      ]
    },
    {
      "metadata": {
        "id": "0KYXEnKmXdzY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cntr = Counter(text)\n",
        "cntr_sum = sum(cntr.values())\n",
        "char_probs = list(map(lambda c: cntr[c] / cntr_sum, chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j6ZjLO4qXdzf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = preds / np.sum(preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BMb34_lsXdzi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate(model, length, seed=''):\n",
        "    \n",
        "    if len(seed) != 0:\n",
        "        sys.stdout.write(seed)\n",
        "    \n",
        "    generated = seed\n",
        "    sentence = seed\n",
        "    \n",
        "    for i in range(length):\n",
        "        x = np.zeros((1, maxlen, len(chars)))\n",
        "\n",
        "        padding = maxlen - len(sentence)\n",
        "        \n",
        "        for i in range(padding):\n",
        "            x[0, i] = char_probs # pad usando os anteriores\n",
        "            \n",
        "        for t, char in enumerate(sentence):\n",
        "            x[0, padding + t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        sentence = sentence[1:] + next_char\n",
        "        generated += next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "        \n",
        "    return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w-Avv-3gXdzm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora, vamos construir o grafo da nossa rede neural. Depois, vamos treinar nosso modelo e exibir algumas amostras em todas as épocas. No final do treinamento, salvamos o modelo para que possamos reutilizá-lo rapidamente no futuro."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "IcymuMQWXdzm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from os.path import isfile\n",
        "from keras.models import load_model\n",
        "\n",
        "MODEL_PATH = 'stacked-lstm-2-layers-128-hidden.h5'\n",
        "\n",
        "if isfile(MODEL_PATH):\n",
        "    model = load_model(MODEL_PATH)\n",
        "else:\n",
        "    N_HIDDEN = 128\n",
        "\n",
        "    # Modelo\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(N_HIDDEN, dropout = 0.1, input_shape = (maxlen, len(chars)), return_sequences = True))\n",
        "    model.add(LSTM(N_HIDDEN, dropout = 0.1))\n",
        "    model.add(Dense(len(chars), activation = 'softmax'))\n",
        "\n",
        "    # Otimizador\n",
        "    optimizer = RMSprop(lr = 0.01)\n",
        "    \n",
        "    # Compilação\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer = optimizer)\n",
        "\n",
        "    # Imprime amostras a cada época\n",
        "    for iteration in range(1, 40):\n",
        "        print('\\n')\n",
        "        print('-' * 50)\n",
        "        print('\\nIteração', iteration)\n",
        "        model.fit(X, y, batch_size=3000, epochs=1)\n",
        "\n",
        "        print('\\n-------------------- Tweet Gerado Pelo Modelo Nesta Iteração ---------------------\\n')\n",
        "\n",
        "        rand = np.random.randint(len(text) - maxlen)\n",
        "        seed = text[rand:rand + maxlen]\n",
        "        generate(model, 400, seed)\n",
        "\n",
        "    model.save(MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YW5Ix_mhXdzp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora vamos experimentar o modelo!\n",
        "\n",
        "Usando a primeira frase deste <a href='https://twitter.com/realDonaldTrump/status/890764622852173826'>tweet</a> como semente, vamos tentar continuar a frase de Trump e ver quais coisas interessantes o nosso modelo pode dizer:"
      ]
    },
    {
      "metadata": {
        "id": "_lPQ9dFdXdzp",
        "colab_type": "code",
        "colab": {},
        "outputId": "c143ee9d-76bc-4c56-e12c-ed7bfd4a12a0"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'Go Republican Senators, Go!'\n",
        "_ = generate(model, 200, sample_tweet_start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go Republican Senators, Go! National in feight better!\n",
            "\n",
            "\"\"@election: @realDonaldTrump what is rient, senution unfilter support are usituliated. http://t.co/uVeXkEax9G\n",
            "\n",
            "RT @LSo: Debate @RealDonaldTrump it wascys got negtrandelic"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "68Oe2d0QXdzs",
        "colab_type": "code",
        "colab": {},
        "outputId": "d09a4894-5092-4369-e65a-ec83be8b4c86"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'immigration'\n",
        "for i in range(10):\n",
        "    _ = generate(model, 200, sample_tweet_start)\n",
        "    print('\\n=========================================\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "immigration They Mr. Weranshoun The Medians I should be ward. http://t.co/UTING:_! Ticketers\"__\n",
            "\n",
            "\"@Separmtlims Republicans #ImWithYou #POTUSS\" ۪p scrunges will findle and Massachusers @realDonaldTrump is. They a\n",
            "=========================================\n",
            "\n",
            "immigration is sntaining Carsention #trumpTannel:\n",
            "https://t.coV34uch #Debates2016 @ChrisWe Bost says Trump 4nether @Chiler2s2015\n",
            "@RuberNBGH TO LOVISDINGA tHATER TRUMP IN TEE care Cruz even 2006 We #Supiccompenne\n",
            "=========================================\n",
            "\n",
            "immigration the mess! This will find supporters! #MakeAmericaGAKE4 @DanScavino\"\n",
            "http://t.co/ eiculing\n",
            "\n",
            "Just release wao Rulie on #Washingtonjoa Usens, #MakeAmericaGreat informerage great known!   https://t.coNQT\n",
            "=========================================\n",
            "\n",
            "immigration: just openly perhams why will dest ROBINGEcTNOUR\n",
            "\n",
            "I will be in the numbers.\n",
            "\n",
            "Thank you for stall Crooked Hillary were allowed Melania_ - 10py have cruzy incredib job @realDonaldTrump Trump way! #Trum\n",
            "=========================================\n",
            "\n",
            "immigration #MakeAmericaG120: @realDonaldTrump: The #VoteTrumpSPRO HIGED\n",
            "https://t.co/aXUGE on #Trump2016\n",
            "\n",
            "RIb @AMPRESIORTORALISTERROUPR DU FOR!\n",
            "\n",
            "\"@spiec_99112  #MakeAmericaGurhttmile\n",
            "\n",
            "Oh asmond very. California\n",
            "=========================================\n",
            "\n",
            "immigrations ISISNS #BEC #Trump2016\n",
            "\n",
            "Mr @inchelentasice? Join me! https://t.co/xSCSEX called disleased anything people by Missin who sick they are sen promings in all statement election, they will alond negative\n",
            "=========================================\n",
            "\n",
            "immigration into delition mistiate people in U.S.A.\n",
            "\n",
            "Hillary Clinton is winning me I execuling selfending @realDonaldTrump A Ted۪t Geta joke anything 600 Pressiciks_W_\n",
            "https://t.coidGCP. One AMERICAR: htths://t.\n",
            "=========================================\n",
            "\n",
            "immigration, endsement\"\n",
            "\n",
            "\"@tretters846 https://t.cohTc wide just out after. 2nd Texas!\n",
            "\n",
            "Hillary Clinton Class Favasign Ted carud HELC Ratings #Debateshttps:_ #INPrimary\n",
            "#Trump2016\n",
            "https://t.couAE   Goofy Extrons\n",
            "=========================================\n",
            "\n",
            "immigration #6p @foxandfriends A3nt President Obama GOP! Watching #SrakaTrumpCarny\n",
            "\n",
            "Wich in New Srame!\n",
            "https://t.coH2866\n",
            "\n",
            "CALNED LAON DONTIRGED So way, more her just is vurly thank you-...  https://t.coHzX not r\n",
            "=========================================\n",
            "\n",
            "immigration\n",
            "\n",
            "Biggd In Ill be dyspled when #ImWithYou\n",
            "Will be intack numbers\" by of your knows like Tweeting such been 3_\n",
            "\n",
            ".@Morning_Joe #MyPrimary #MakeAmericaGurhtmy 30 Rule۪s hells.\"\n",
            "\n",
            "Donald Trump on the natur\n",
            "=========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zOECmbWUXdzv",
        "colab_type": "code",
        "colab": {},
        "outputId": "76e41113-217c-4081-9e58-269bc9cc7666"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'America'\n",
        "for i in range(10):\n",
        "    _ = generate(model, 200, sample_tweet_start)\n",
        "    print('\\n=========================================\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "America Trump:\n",
            "\"I the payls will making slogchy #DrainThe http://tttpripadies if he was fancering\" will voterst Carson, Jurinacive :  Obama Turnout:\n",
            "\n",
            "Thank you. Thank. Many missies: https:// 8d16/NIFL TOOAL \n",
            "=========================================\n",
            "\n",
            "America\n",
            "\n",
            "Hook luty it quehtion Sweeke Ted Cruzicins @nytimes\"\n",
            "\n",
            "\"@menity_ #MakeAmerican Marco RubioS1:\n",
            "#Trump2016: When I extweps #DemDebate Bearmins who very anyover Irencelgen @realDonald Trump will no open\n",
            "=========================================\n",
            "\n",
            "American Be great readled readly #JebBush https://Thcrporian scollins his duning DNC hes insteasled will not.This will be will cribilast Old #MAGA!_ https://t.cv/NT @gratent is a liar if he care Trump starte\n",
            "=========================================\n",
            "\n",
            "America\n",
            "\n",
            " #DrainTheroors #makesee @realDong\n",
            "Bills is, applannel Lynotk2016\n",
            "\n",
            "Ordeq XVCYX ! #Trump2016\n",
            "\n",
            "Great So like it is the Outer @CNN They Alty incompeteD\n",
            "\n",
            "Congraind!\"\n",
            "\n",
            "\"@kegyropwerz Heads a dast? Used ha\n",
            "=========================================\n",
            "\n",
            "America\n",
            "\n",
            "Just interview: Get Trumps #IALILA:\n",
            "https://C6/7/6 Ghean http://t.clussed Mr Trump: Hers fically in a black. I purter did\n",
            "\n",
            "Canaan GOP:\n",
            "https://@realDong #Mke0000 Please Best Carson #MOGA! Join Wayne\n",
            "=========================================\n",
            "\n",
            "American 25\"\n",
            "\n",
            "\"@dradbert with Barmong of \"formack 4 Make AmericaFist Michigan in Washingtoms we is keer goodona: KPI:\n",
            "https://t.tmost or WIB @Ways loves @JolenPock: #ICIOMINY Stacker GOP Debate #Trump2016 @r\n",
            "=========================================\n",
            "\n",
            "American: https://@rusisess news http://t.c/\n",
            "\"@timblearght #VoteTrump #Pollzn Reno_\n",
            "\n",
            "\"@gilkaaon2\n",
            "\n",
            "\"@mikesing #@FoxNewsSo. President New Yorker: @megynked They have having watched #SuperToad\n",
            "\n",
            "\"@Lev_Rubie:\n",
            "htt\n",
            "=========================================\n",
            "\n",
            "America\n",
            "\n",
            "Just rided\n",
            "\n",
            ".@Mike_Penarl_Ou @Mornon40 Great, I am numbers_\n",
            "#MakeAmericaFeybern Your Vets is all! She will voter will fall leaven heally Republicans shouldd Attrost, he approvames Americans:_ https:\n",
            "=========================================\n",
            "\n",
            "American @Senaters: https://90pt 10 yefflas: I۪m signed Pennsylvem201674_N\n",
            "\n",
            "\"@lity104031 \n",
            "Thank you! #Trump2016\n",
            "\n",
            "Morning and MAKE AMERICA UM #MSP follacilyn: Yrueports shill off the only dismubder https://tt\n",
            "=========================================\n",
            "\n",
            "AmericaCure is boarmes 200\n",
            "\n",
            "\"@O4Lammos\n",
            "\n",
            "\"@Lutbaits president #VoteTrump: https:// 36/601 @realDonald Trump: Crohd https://t.cv\n",
            "\n",
            "Jeb Bushlen\n",
            "\n",
            "Hillary @JebBush, #DemDebate\n",
            "\n",
            "If I create agree.\"\n",
            "\n",
            "\"@hetceinned\n",
            "\n",
            "R\n",
            "=========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nFTqZ5BlXdzz",
        "colab_type": "code",
        "colab": {},
        "outputId": "deac7cbf-b416-4b7e-f6a1-22c62d60d3c6"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'China'\n",
        "for i in range(10):\n",
        "    _ = generate(model, 200, sample_tweet_start)\n",
        "    print('\\n=========================================\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "China: http:/021 #Crooked Get will helpechates Trump @onlyZ MOME #RT https:/250 milliss in making @NYDamshorder\n",
            "\n",
            "Gies When ROGTAMINYHY: https:_ https:_\n",
            "\n",
            "Carron 4 Dem flazico4 TMATERIRINAS @realDon. He said\n",
            "=========================================\n",
            "\n",
            "China delement 10P ta5 US @glue_\n",
            "\n",
            "Unsela\"\n",
            "\n",
            "\"@thay one officelost off, Really I begendands. They 11 in joz\n",
            "\n",
            "Why http:/0016 #MAPRICA @Payly They Washers:_ #MAGA__https:\n",
            "\n",
            "Puring Hillaryduch:_ #MakeAme 8 38 da\n",
            "=========================================\n",
            "\n",
            "China Trump Hillary: #MakeAmerics:\n",
            "\n",
            "NIVEME Trump: Opher 11 #IthYor, we can other Is finess\"  Thank\"\n",
            "\n",
            "I will lead 9u, Dont #AZPricary #GOPDebare should Trugp  CLAN Emergemen, helliss #Shown, @megyn Trump Yo\n",
            "=========================================\n",
            "\n",
            "China on The Only #Trump #Crooked  @nbcsh:\n",
            "#Orisbicare? http:/15/https:_.\n",
            "https:_\"\n",
            "\n",
            "Thanks VOTE Posencusion? @thes!\n",
            "\n",
            "\"@Manically Mix Henderson off. the care @Girmy we can stand whilen.\", Ohio is ofd, JOBHI\n",
            "=========================================\n",
            "\n",
            "Chinac 12/3 Enducals 130\n",
            "\n",
            "#MakeAmerics is himses 4nmight not records #BigLeblyymary presides went really voter #Americs the Pail #Inter #DemDebate and I WILL!\n",
            "\n",
            "Thanks https_ https:_  attemen, rhute 60\"\n",
            "\n",
            "\"@\n",
            "=========================================\n",
            "\n",
            "China we will #MakeAments 400 Will She rich repress Like 4 @realDes, You are got the CAC Funnic @realDon 445 yours talk frauders an angradia Gennyn33 People John 2001! #Trump @CNN #DRUDGE_R\n",
            "\n",
            ".@Seuchared\n",
            "\n",
            "C\n",
            "=========================================\n",
            "\n",
            "Chinacter Chicago #FOXAIn Insseight anter Mr @TheRUUL!\n",
            "\n",
            "Incovest way not is win the his behandy, Democrasking a failed #MayTrump\"\n",
            "\n",
            "\"@Senate #MakeAmertanichne Americaziuz\n",
            "\n",
            "\"@jumpispide of Chanton GO NOW ANS\n",
            "=========================================\n",
            "\n",
            "China cannothing join https:_ #MakeAmerical Vettray on @oreiled running_ http:/https:\n",
            "#America_ #Obama\n",
            "\n",
            "Just a viced #IAYRY: CalDary_Ih #RT @Maria Bobbdisage if Press Great http:/https:_. We are spleamus:\n",
            "\n",
            "=========================================\n",
            "\n",
            "China News!\n",
            "\n",
            "A their @Carolision 30 #DemDebates Like Hillion2\n",
            " .@Billome Me Club4m\n",
            "\n",
            ".@shimments so washing The MedieS58: Graud @FoxNe: Please #Inward thank yith disgonson Liks Policy see you needs @realDon\n",
            "=========================================\n",
            "\n",
            "China should Nexwers:\n",
            "https:_ http:/2016 #Leak_ FACTEOU was parm orfer\"\n",
            "\n",
            "\"@Ded_h 116\n",
            "\n",
            "\"@realDonald @realDon 49.7, will bruok:\n",
            "https:_\n",
            "\n",
            "It alreated\"\n",
            "\n",
            " @Reps_\n",
            "\n",
            "MAKE 2016\"\n",
            "\n",
            "\"@Ableght\n",
            "\n",
            "Looking @Balbakes Out fr\n",
            "=========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KAYfZKxYXdz4",
        "colab_type": "code",
        "colab": {},
        "outputId": "99ed7cdd-f357-45ac-c792-58aa58b05496"
      },
      "cell_type": "code",
      "source": [
        "sample_tweet_start = 'Democratic'\n",
        "for i in range(10):\n",
        "    _ = generate(model, 200, sample_tweet_start)\n",
        "    print('\\n=========================================\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Democratic\n",
            "\n",
            "I hoped a join me today Gomgents with @Savun_Luol:\n",
            "#Trump2016 @ChrisChemOch: Im #INPoinits\n",
            "\n",
            "The biggds.  NOT POLL\n",
            "#ENCrugs__ JOEN TEARSROMDSS HELL TRUMP is a propest all after or #NikeUnePPROVA #Rig\n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "\n",
            "Thanks. Not an and emmils:\n",
            "\n",
            "Thank you cannot leave 4000 hell /parth up by ScareUSA BFFATING GUNDER POLL! Scare, Days Changes http://t.cohTdail Hance Prazears Alama at 4pm! #TrumpTraMWer1\n",
            "\n",
            "\"@JomTush:\n",
            "=========================================\n",
            "\n",
            "Democraticon: AL Mack  32 Looking People crieded I can she watching went Barnon Marcorsin #IowaCaucus #CrookedHillary is he benothing #SNL #Waptings #VoteTrump\"  Truegsher, you feak POTUS YOU \"WESS... MAKE AMER\n",
            "=========================================\n",
            "\n",
            "Democratic: #greatAsurc2 is plaznific\n",
            "\n",
            "I۪d endended just release the endsamencied Obama cant want to President Rubio\n",
            "#Debate\"\n",
            "\n",
            "\"@JheWoFee6 lEED AARIVE @davilkimorcation: Obama Team #DranDayTrump #Trump2016\n",
            "\n",
            "We \n",
            "=========================================\n",
            "\n",
            "Democratics۪: Trump\"\n",
            "\n",
            "Great. We are I spent people media ems  POTUS R! https://t.cPMWSING USFAhTORA\n",
            "\n",
            "THENS TO VEDEY SHE WEAR TRUMP SUSIN! https://t.co/aVOLA\n",
            "https://t.cohkfake http://t.coLaT Aperican Des Bernie\n",
            "=========================================\n",
            "\n",
            "Democratics weaks I heard Obama says I weak ON! #WasHington #ImIrity\n",
            "https://t.cPi/5b it choked me has 100 bush 34 Time!\n",
            "\n",
            "\"@huldiggyrromi: http://t.coNfXdi: Leader Jeb Bush: @realDonald TrumpUS MAKE AMERICA NER\n",
            "=========================================\n",
            "\n",
            "Democratico_\n",
            "\n",
            "\"@TIDA watching signt\" Carson - I am I see\n",
            "hillifices:\n",
            "\n",
            "\"@tcarluvesed YOU! Finder, deals were Generali5s SADOEINGN. #DRUDGEATOEE Puringslenably\n",
            "\n",
            "Dadical evening. And I do wenl, take!\" I am another\n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "\n",
            "What a Jeambcobuma6_ #SNLOMA\n",
            "https://t.coHLating #WH sent OR  #as very speece http://t.cohPTRISH\n",
            "\n",
            "\"@BrrorsecoBuly\n",
            " Sonative Rubio!\n",
            "\n",
            "Hopork. ..\n",
            "\n",
            "RT @treitchenk. He only very many new A provecul chris\n",
            "=========================================\n",
            "\n",
            "Democratic:\n",
            "https://t.cPSS super Vegan stracted 14/8a/htBusive: https://t.cohrucks\"\n",
            "Nust politicians he should agree of theor offerdate Vene Covers\" Congress on years in the WisconSill Deal\n",
            "\"Puppergon All Meian\n",
            "=========================================\n",
            "\n",
            "Democratic\n",
            "Many past night. Will kell outen why sersone will lead apges a starting yesterday refort Everyone headtin we WOLL LEATINGT NEVAMIENT US YORS CONNER LOVE TRUPP? BIR.\n",
            "\n",
            "What a queated Damnas who were re\n",
            "=========================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "utZGnEAeXdz-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}