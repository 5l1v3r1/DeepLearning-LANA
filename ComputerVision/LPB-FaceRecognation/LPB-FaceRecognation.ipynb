{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LPB-FaceRecognation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Arquivo está dividido em vários pedaços. Fazer o download do arquivo .tar.gz e executar o passos:\n",
    "\n",
    "Juntar novamente o arquivo: cat caltech_faces-* > caltech_faces2.zip\n",
    "\n",
    "Descompactar unzip caltectec_faces.zip\n",
    "\n",
    "Executar o Jupyter Notebook (arquivo .ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo foi criado como os seguintes comandos:\n",
    "\n",
    "Compactar um diretório/folder tar -czvf caltec_faces.tar.gz caltec_faces\n",
    "\n",
    "Separar o arquivo em pedaços de 20MB: split -b 20000000 caltech_faces.zip caltech_faces-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando o dataset...\n",
      "Treinando o Reconhecedor de Faces...\n",
      "Fazendo previsões...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         5\n",
      "           3       1.00      1.00      1.00         5\n",
      "           4       1.00      1.00      1.00         4\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00         3\n",
      "           8       1.00      1.00      1.00         5\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       1.00      1.00      1.00         9\n",
      "          11       1.00      1.00      1.00         5\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        63\n",
      "   macro avg       1.00      1.00      1.00        63\n",
      "weighted avg       1.00      1.00      1.00        63\n",
      "\n",
      "Previsão: ['person_014'], Atual: person_014, Confidence: 176.86\n",
      "Previsão: ['person_014'], Atual: person_014, Confidence: 173.16\n",
      "Previsão: ['person_006'], Atual: person_006, Confidence: 178.32\n",
      "Previsão: ['person_009'], Atual: person_009, Confidence: 168.78\n",
      "Previsão: ['person_016'], Atual: person_016, Confidence: 174.27\n",
      "Previsão: ['person_005'], Atual: person_005, Confidence: 195.71\n",
      "Previsão: ['person_025'], Atual: person_025, Confidence: 177.49\n",
      "Previsão: ['person_009'], Atual: person_009, Confidence: 168.78\n",
      "Previsão: ['person_009'], Atual: person_009, Confidence: 168.78\n",
      "Previsão: ['person_006'], Atual: person_006, Confidence: 179.26\n"
     ]
    }
   ],
   "source": [
    "# Reconhecimento Facial com LBP\n",
    "# python cap05-12-lbp_face_recognition.py --dataset caltech_faces\n",
    "\n",
    "# Dataset: http://www.vision.caltech.edu/html-files/archive.html\n",
    "# Como o dataset é muito grande, ele está disponível no super servidor da DSA, o Titan, no diretório:\n",
    "# /media/datasets/ComputerVision/Cap05/02-FaceRecognition/02-LBP\n",
    "\n",
    "# O dataset CALTECH Faces é um conjunto de dados de referência popular para algoritmos de reconhecimento facial. \n",
    "# No geral, o conjunto de dados é composto por 450 imagens de aproximadamente 27 pessoas únicas. \n",
    "# Cada foto foi capturada em várias condições de iluminação, cenas de fundo e expressões faciais.\n",
    "\n",
    "# O objetivo geral aqui é aplicar os LBPs para o algoritmo de reconhecimento facial para identificar cada uma das faces\n",
    "# no conjunto de dados CALTECH Faces.\n",
    "\n",
    "# Imports\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "from datasets import load_caltech_faces\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#\n",
    "database = 'caltech_faces'\n",
    "sample_size = 10\n",
    "\n",
    "# Carregando o dataset\n",
    "print(\"Carregando o dataset...\") # dataset de 27 pessoas unicas - cada 1 pessoa é uma classe\n",
    "(training, testing, names) = load_caltech_faces(database, min_faces=21, test_size=0.25)\n",
    "\n",
    "# Codifica os rótulos, transformando-os de strings em números inteiros, uma vez que o OpenCV não gosta de strings como dados de treinamento\n",
    "le = LabelEncoder()\n",
    "le.fit_transform(training.target)\n",
    "\n",
    "# Treinamento do reconhecedor de faces do padrão binário local\n",
    "print(\"Treinando o Reconhecedor de Faces...\")\n",
    "\n",
    "# Parâmetros do LBPHFaceRecognizer_create()\n",
    "\n",
    "# radius - Um raio maior aumenta a abrangência mas pode perder bordas finas (pontos mais distantes). Quanto maior o raio mais padrões podem ser codificados, mas aumenta o esforço computacional.\n",
    "\n",
    "# neighbors - Número de pontos na amostra para construir um padrão local. Quanto maior o número de vizinhos maior é o esforço computacional.\n",
    "\n",
    "# grid_x - Número de células na horizontal. Quanto mais células maior é a dimensionalidade do vetor de características (histogramas).\n",
    "\n",
    "# grid_y - Número de células na vertical. Se a grade aumentar serão usados menso pixels em cada histograma (mais esparsos).\n",
    "\n",
    "# threshold - Limite de confiança.\n",
    "\n",
    "# Cria o classificador\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create(radius=2, neighbors=16, grid_x=8, grid_y=8)\n",
    "\n",
    "# Treinamento\n",
    "recognizer.train(training.data, le.transform(training.target))\n",
    "\n",
    "# Inicializando a lista de previsões e score de confiança\n",
    "print(\"Fazendo previsões...\")\n",
    "predictions = []\n",
    "confidence = []\n",
    "\n",
    "# Loop pelos dados de teste\n",
    "for i in range(0, len(testing.data)):\n",
    "    # Classifica o rosto e atualiza a lista de previsões e score de confiança\n",
    "    (prediction, conf) = recognizer.predict(testing.data[i])\n",
    "    predictions.append(prediction)\n",
    "    confidence.append(conf)\n",
    "    print(i)\n",
    "\n",
    "# Mostra o relatório de classificação\n",
    "print(classification_report(le.transform(testing.target), predictions) )#, target_names=names))\n",
    "\n",
    "# Loop pelo número desejado de amostras\n",
    "for i in np.random.randint(0, high=len(testing.data), size=(sample_size)):\n",
    "    # Redimensionamento do rosto para torná-lo mais visível, então exibe o rosto e a previsão\n",
    "    print(\"Previsão: {}, Atual: {}, Confidence: {:.2f}\".format(le.inverse_transform([predictions[i]]),\n",
    "                                                               testing.target[i], confidence[i]))\n",
    "    face = testing.data[i]\n",
    "    face = imutils.resize(face, width=face.shape[1] * 2, inter=cv2.INTER_CUBIC)\n",
    "    cv2.imshow(\"Face\", face)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 1, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['person_001', 'person_004', 'person_005', 'person_006',\n",
       "       'person_009', 'person_014', 'person_015', 'person_016',\n",
       "       'person_020', 'person_023', 'person_025', 'person_026'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  3, 11])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.transform(training.target)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'person_001',\n",
       " 'person_004',\n",
       " 'person_005',\n",
       " 'person_006',\n",
       " 'person_009',\n",
       " 'person_014',\n",
       " 'person_015',\n",
       " 'person_016',\n",
       " 'person_020',\n",
       " 'person_023',\n",
       " 'person_025',\n",
       " 'person_026'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(testing.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person_023']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(le.inverse_transform([9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person_023'] person_023 172.65546433677352\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(le.inverse_transform([predictions[i]]), testing.target[i], confidence[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
