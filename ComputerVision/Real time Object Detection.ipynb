{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Arquivo está dividido em vários pedaços. \n",
    "Fazer o download do arquivo .tar.gz e executar o passos: \n",
    "\n",
    "Juntar novamente o arquivo \n",
    "cat RealTimeObjectDetection-* > RealTimeObjectDetection.tar.gz \n",
    "\n",
    "Descompactar \n",
    "tar xvzf RealTimeObjectDetection.tar.gz\n",
    "\n",
    "Executar o Jupyter Notebook (arquivo .ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "============================================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo foi criado como os seguintes comandos: \n",
    "\n",
    "Compactar um diretório/folder \n",
    "tar -czvf RealTimeObjectDetection.tar.gz RealTimeObjectDetection\n",
    "\n",
    "Separar o arquivo em pedaços de 20MB \n",
    "split -b 20000000 RealTimeObjectDetection.tar.gz RealTimeObjectDetection-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimiralencar/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n",
      "[DEBUG/MainProcess] created semlock with handle 61\n",
      "[DEBUG/MainProcess] created semlock with handle 62\n",
      "[DEBUG/MainProcess] created semlock with handle 63\n",
      "[DEBUG/MainProcess] Queue._after_fork()\n",
      "[DEBUG/MainProcess] created semlock with handle 66\n",
      "[DEBUG/MainProcess] created semlock with handle 67\n",
      "[DEBUG/MainProcess] created semlock with handle 68\n",
      "[DEBUG/MainProcess] Queue._after_fork()\n",
      "[DEBUG/MainProcess] created semlock with handle 71\n",
      "[DEBUG/MainProcess] created semlock with handle 72\n",
      "[DEBUG/MainProcess] created semlock with handle 75\n",
      "[DEBUG/MainProcess] created semlock with handle 76\n",
      "[DEBUG/MainProcess] added worker\n",
      "[DEBUG/MainProcess] added worker\n",
      "[DEBUG/ForkPoolWorker-1] Queue._after_fork()\n",
      "[DEBUG/ForkPoolWorker-1] Queue._after_fork()\n",
      "[DEBUG/ForkPoolWorker-2] Queue._after_fork()\n",
      "[INFO/ForkPoolWorker-1] child process calling self.run()\n",
      "[DEBUG/ForkPoolWorker-2] Queue._after_fork()\n",
      "[INFO/ForkPoolWorker-2] child process calling self.run()\n",
      "[DEBUG/MainProcess] Queue._start_thread()\n",
      "[DEBUG/MainProcess] doing self._thread.start()\n",
      "[DEBUG/MainProcess] starting thread to feed data to pipe\n",
      "[DEBUG/MainProcess] ... done self._thread.start()\n",
      "[DEBUG/ForkPoolWorker-2] Queue._start_thread()\n",
      "[DEBUG/ForkPoolWorker-2] doing self._thread.start()\n",
      "[DEBUG/ForkPoolWorker-2] starting thread to feed data to pipe\n",
      "[DEBUG/ForkPoolWorker-2] ... done self._thread.start()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tempo: 9.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG/ForkPoolWorker-1] Queue._start_thread()\n",
      "[DEBUG/ForkPoolWorker-1] doing self._thread.start()\n",
      "[DEBUG/ForkPoolWorker-1] starting thread to feed data to pipe\n",
      "[DEBUG/ForkPoolWorker-1] ... done self._thread.start()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tempo: 4.41\n",
      "[INFO] Tempo: 0.21\n",
      "[INFO] Tempo: 0.20\n",
      "[INFO] Tempo: 0.23\n",
      "[INFO] Tempo: 0.28\n",
      "[INFO] Tempo: 0.26\n",
      "[INFO] Tempo: 0.31\n",
      "[INFO] Tempo: 0.26\n",
      "[INFO] Tempo: 0.20\n",
      "[INFO] Tempo: 0.26\n",
      "[INFO] Tempo: 0.26\n",
      "[INFO] Tempo: 0.25\n",
      "[INFO] Tempo: 0.22\n",
      "[INFO] Tempo: 0.21\n",
      "[INFO] Tempo: 0.27\n",
      "[INFO] Tempo: 0.26\n",
      "[INFO] Tempo: 0.27\n",
      "[INFO] Tempo: 0.26\n",
      "[INFO] Tempo: 0.24\n",
      "[INFO] Tempo: 0.19\n",
      "[INFO] Tempo: 0.21\n",
      "[INFO] Tempo: 0.22\n",
      "[INFO] Tempo: 0.27\n",
      "[INFO] Tempo: 0.23\n",
      "[INFO] Tempo: 0.28\n",
      "[INFO] Tempo: 0.25\n",
      "[INFO] Tempo: 0.23\n",
      "[INFO] Tempo: 0.24\n",
      "[INFO] Tempo: 0.23\n",
      "[INFO] Tempo: 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG/MainProcess] terminating pool\n",
      "[Level 5/MainProcess] finalizer calling <bound method Pool._terminate_pool of <class 'multiprocessing.pool.Pool'>> with args (<_queue.SimpleQueue object at 0xb20437548>, <multiprocessing.queues.SimpleQueue object at 0xb20570b70>, <multiprocessing.queues.SimpleQueue object at 0xb20570fd0>, [<ForkProcess(ForkPoolWorker-1, started daemon)>, <ForkProcess(ForkPoolWorker-2, started daemon)>], <Thread(Thread-4, started daemon 123145528209408)>, <Thread(Thread-5, started daemon 123145533464576)>, <Thread(Thread-6, started daemon 123145538719744)>, {}) and kwargs {}\n",
      "[DEBUG/MainProcess] finalizing pool\n",
      "[DEBUG/MainProcess] helping task handler/workers to finish\n",
      "[DEBUG/MainProcess] removing tasks from inqueue until task handler finished\n",
      "[DEBUG/MainProcess] result handler found thread._state=TERMINATE\n",
      "[DEBUG/MainProcess] joining worker handler\n",
      "[DEBUG/MainProcess] ensuring that outqueue is not full\n",
      "[DEBUG/MainProcess] result handler exiting: len(cache)=0, thread._state=2\n",
      "[DEBUG/MainProcess] worker handler exiting\n",
      "[DEBUG/MainProcess] task handler got sentinel\n",
      "[DEBUG/MainProcess] terminating workers\n",
      "[DEBUG/MainProcess] task handler sending sentinel to result handler\n",
      "[DEBUG/MainProcess] joining task handler\n",
      "[DEBUG/MainProcess] task handler sending sentinel to workers\n",
      "[DEBUG/MainProcess] task handler exiting\n",
      "[DEBUG/MainProcess] joining result handler\n",
      "[DEBUG/MainProcess] joining pool workers\n",
      "[DEBUG/MainProcess] cleaning up worker 51199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Tempo: 0.23\n",
      "[INFO] Tempo Total: 21.86\n",
      "[INFO] FPS - Frames Por Segundos (aproximado): 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[DEBUG/MainProcess] cleaning up worker 51200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils.app_utils import FPS, WebcamVideoStream\n",
    "from multiprocessing import Queue, Pool\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "CWD_PATH = os.getcwd()\n",
    "\n",
    "# Este é o modelo real que é usado para a detecção de objetos.\n",
    "MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "PATH_TO_CKPT = os.path.join(CWD_PATH, 'object_detection', MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "\n",
    "# Lista das strings que são usadas para adicionar o rótulo correto para cada caixa.\n",
    "PATH_TO_LABELS = os.path.join(CWD_PATH, 'object_detection', 'data', 'mscoco_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 90\n",
    "\n",
    "# Carregando mapa de labels\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, \n",
    "                                                            use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def detect_objects(image_np, sess, detection_graph):\n",
    "    # Expande as dimensões uma vez que o modelo espera que as imagens tenham shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Cada caixa representa uma parte da imagem onde um objeto específico foi detectado.\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "    # Cada score representa o nível de confiança para cada um dos objetos. \n",
    "    # O score é mostrado na imagem do resultado, juntamente com o rótulo da classe.\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "    # Detecção\n",
    "    (boxes, scores, classes, num_detections) = sess.run([boxes, scores, classes, num_detections], \n",
    "                                                        feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "    # Visualização dos resultados de uma detecção.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        np.squeeze(boxes),\n",
    "        np.squeeze(classes).astype(np.int32),\n",
    "        np.squeeze(scores),\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    return image_np\n",
    "\n",
    "\n",
    "def worker(input_q, output_q):\n",
    "    # Carrega o modelo TensorFlow na memória.\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "        sess = tf.Session(graph=detection_graph)\n",
    "\n",
    "    fps = FPS().start()\n",
    "    while True:\n",
    "        fps.update()\n",
    "        frame = input_q.get()\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        output_q.put(detect_objects(frame_rgb, sess, detection_graph))\n",
    "\n",
    "    fps.stop()\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"   \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-src', '--source', dest='video_source', type=int, default=0,\n",
    "                        help='Device index of the camera.')\n",
    "    parser.add_argument('-wd', '--width', dest='width', type=int, default=480, \n",
    "                        help='Width of the frames in the video stream.')\n",
    "    parser.add_argument('-ht', '--height', dest='height', type=int, default=360, \n",
    "                        help='Height of the frames in the video stream.')\n",
    "    parser.add_argument('-num-w', '--num-workers', dest='num_workers', type=int, default=2, \n",
    "                        help='Number of workers.')\n",
    "    parser.add_argument('-q-size', '--queue-size', dest='queue_size', type=int, default=5, help='Size of the queue.')\n",
    "    args = parser.parse_args()\n",
    "    \"\"\"\n",
    "\n",
    "    logger = multiprocessing.log_to_stderr()\n",
    "    logger.setLevel(multiprocessing.SUBDEBUG)\n",
    "\n",
    "    input_q = Queue(maxsize=5)\n",
    "    output_q = Queue(maxsize=5)\n",
    "    pool = Pool(2, worker, (input_q, output_q))\n",
    "\n",
    "    video_capture = WebcamVideoStream(src=0, width=480, height=360).start()\n",
    "    fps = FPS().start()\n",
    "\n",
    "    while True:  \n",
    "        frame = video_capture.read()\n",
    "        input_q.put(frame)\n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        output_rgb = cv2.cvtColor(output_q.get(), cv2.COLOR_RGB2BGR)\n",
    "        cv2.imshow('Video', output_rgb)\n",
    "        fps.update()\n",
    "\n",
    "        print('[INFO] Tempo: {:.2f}'.format(time.time() - t))\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    fps.stop()\n",
    "    print('[INFO] Tempo Total: {:.2f}'.format(fps.elapsed()))\n",
    "    print('[INFO] FPS - Frames Por Segundos (aproximado): {:.2f}'.format(fps.fps()))\n",
    "\n",
    "    pool.terminate()\n",
    "    video_capture.stop()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
