{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniVGGNet-04.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/ComputerVision/DeepLearning/MiniVGGNet_04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "YPNO9z-h-COD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# LeNet - Rede Neural Convolucional - Classificação de Imagens - Cifar10"
      ]
    },
    {
      "metadata": {
        "id": "sTYUmKxN99FR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Leitura de dados"
      ]
    },
    {
      "metadata": {
        "id": "DH4GmQ5H8i_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "88ff78b3-6cc7-4725-d54d-01ab8dea89f5"
      },
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/ComputerVision/DeepLearning/convnet.py\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-19 01:54:15--  https://raw.githubusercontent.com/vladimiralencar/DeepLearning-LANA/master/ComputerVision/DeepLearning/convnet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6344 (6.2K) [text/plain]\n",
            "Saving to: ‘convnet.py’\n",
            "\n",
            "\rconvnet.py            0%[                    ]       0  --.-KB/s               \rconvnet.py          100%[===================>]   6.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-04-19 01:54:15 (146 MB/s) - ‘convnet.py’ saved [6344/6344]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GU029zWmfdIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm  images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XTLGo2r1dBbY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "042fcd20-b8ee-43d1-894f-36d63a7960c8"
      },
      "cell_type": "code",
      "source": [
        "!curl -L -o imagens.zip https://github.com/vladimiralencar/DeepLearning-LANA/raw/master/ComputerVision/DeepLearning/imagens.zip?raw=true\n",
        "!unzip imagens.zip \n",
        "!rm imagens/.DS_Store "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   180  100   180    0     0    782      0 --:--:-- --:--:-- --:--:--   782\n",
            "\r100  503k  100  503k    0     0  1389k      0 --:--:-- --:--:-- --:--:-- 1389k\n",
            "Archive:  imagens.zip\n",
            "replace imagens/image8.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: imagens/image8.jpg      \n",
            "  inflating: imagens/image9.jpg      \n",
            "  inflating: imagens/image10.jpg     \n",
            "  inflating: imagens/image7.jpg      \n",
            "  inflating: imagens/image6.jpg      \n",
            "  inflating: imagens/image4.jpg      \n",
            "  inflating: imagens/image5.jpg      \n",
            "  inflating: imagens/image1.jpg      \n",
            "  inflating: imagens/image2.jpg      \n",
            "  inflating: imagens/image3.jpg      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PPx1qryyhLjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2ff1de9b-d192-4dca-ec6a-8a8f76e3901f"
      },
      "cell_type": "code",
      "source": [
        "!rm imagens/.DS_Store \n",
        "!ls -ila imagens"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'imagens/.DS_Store': No such file or directory\n",
            "total 556\n",
            " 5637305 drwxr-xr-x 2 root root   4096 Apr 19 02:55 .\n",
            "23199751 drwxr-xr-x 1 root root   4096 Apr 19 02:50 ..\n",
            " 5637314 -rw-r--r-- 1 root root 155744 Apr 20  2018 image10.jpg\n",
            " 5637324 -rw-r--r-- 1 root root  17248 Apr 20  2018 image1.jpg\n",
            " 5637326 -rw-r--r-- 1 root root  11641 Apr 20  2018 image2.jpg\n",
            " 5637328 -rw-r--r-- 1 root root   8750 Apr 20  2018 image3.jpg\n",
            " 5637320 -rw-r--r-- 1 root root  34622 Apr 20  2018 image4.jpg\n",
            " 5637322 -rw-r--r-- 1 root root  41637 Apr 20  2018 image5.jpg\n",
            " 5637318 -rw-r--r-- 1 root root  29093 Apr 20  2018 image6.jpg\n",
            " 5637316 -rw-r--r-- 1 root root  80785 Apr 20  2018 image7.jpg\n",
            " 5637306 -rw-r--r-- 1 root root  83248 Apr 20  2018 image8.jpg\n",
            " 5637312 -rw-r--r-- 1 root root  70520 Apr 20  2018 image9.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FEgdtdvhknno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "43fa383f-4f63-4ccc-d767-1f5e6e0812da"
      },
      "cell_type": "code",
      "source": [
        "!ls -ila "
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 35228\n",
            "23199751 drwxr-xr-x 1 root root     4096 Apr 19 02:50 .\n",
            " 5373954 drwxr-xr-x 1 root root     4096 Apr 19 01:53 ..\n",
            "23199752 drwxr-xr-x 1 root root     4096 Apr  4 20:19 .config\n",
            " 5637282 -rw-r--r-- 1 root root     6344 Apr 19 01:54 convnet.py\n",
            " 5637305 drwxr-xr-x 2 root root     4096 Apr 19 02:55 imagens\n",
            " 5637301 -rw-r--r-- 1 root root   515236 Apr 19 02:54 imagens.zip\n",
            " 5637302 -rw-r--r-- 1 root root    59261 Apr 19 02:37 imagens.zip.1\n",
            " 5637303 -rw-r--r-- 1 root root    59261 Apr 19 02:37 imagens.zip.2\n",
            " 5637304 -rw-r--r-- 1 root root   515236 Apr 19 02:53 images.zip\n",
            " 5637307 drwxrwxr-x 3 root root     4096 Apr 19 02:47 __MACOSX\n",
            " 5637299 -rw-r--r-- 1 root root 17430184 Apr 19 02:24 modelo.hdf5\n",
            " 5637300 -rw-r--r-- 1 root root 17430184 Apr 19 02:33 modeloVGGNet.hdf5\n",
            " 5637285 drwxr-xr-x 2 root root     4096 Apr 19 01:54 __pycache__\n",
            " 9306120 drwxr-xr-x 1 root root     4096 Apr  4 20:20 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3oTti_3Ob4_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "64132361-7ef3-44e8-bde3-802bee6cbeff"
      },
      "cell_type": "code",
      "source": [
        "# Testando o Modelo Pré-Treinado\n",
        "\n",
        "# Execute: python cap09-07-test-convnet.py --model modelo/modelo_minivggnet.hdf5 --test-images imagens\n",
        "\n",
        "# Imports\n",
        "import cv2\n",
        "import imutils\n",
        "import argparse\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "from keras.datasets import cifar10\n",
        "from imutils import paths\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Hiperparametros\n",
        "modelo_path='modeloVGGNet.hdf5'\n",
        "test_images='imagens'\n",
        "batch_size32=32\n",
        "\n",
        "# Lista com os labels no CIFAR-10 # 10 classes\n",
        "gtLabels = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "# Carregando o modelo\n",
        "print(\"\\nCarregando o modelo (arquitetura e pesos)...\")\n",
        "model = load_model(modelo_path)\n",
        "\n",
        "# Testando o modelo em novas imagens\n",
        "print(\"\\nTestando o modelo em novas imagens\")\n",
        "\n",
        "# Loop pelas imagens de teste\n",
        "for imagePath in paths.list_images(test_images):\n",
        "  #print(imagepath)\n",
        "\t# Carrega a imagem, redimensiona para uma resolução fixa de 32 x 32 pixels (ignorando a proporção) e, em seguida, \n",
        "\t# converte a imagem em ordem RGB para torná-la compatível com a nossa rede\n",
        "\tprint(\"Classificando {}\".format(imagePath[imagePath.rfind(\"/\") + 1:]))\n",
        "\timage = cv2.imread(imagePath)\n",
        "\tkerasImage = cv2.resize(image, (32,32))\n",
        "\tkerasImage = cv2.cvtColor(kerasImage, cv2.COLOR_BGR2RGB)\n",
        "\tkerasImage = np.array(kerasImage, dtype=\"float\") / 255.0\n",
        "\n",
        "\t# Adiciona uma dimensão extra à imagem para que possamos passá-la pela rede e, em seguida,\n",
        "\t# fazemos uma previsão na imagem (normalmente faríamos previsões em uma matriz * de imagens, uma a uma)\n",
        "\tkerasImage = kerasImage[np.newaxis, ...]\n",
        "\tprobs = model.predict(kerasImage, batch_size=batch_size32)\n",
        "  print(probs)\n",
        "  \n",
        "\tprediction = probs.argmax(axis=1)[0]\n",
        "\n",
        "  print(prediction)\n",
        "\t# Desenha a previsão na imagem de teste \n",
        "\t#cv2.putText(image, gtLabels[prediction], (10, 35), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 3)\n",
        "\t#cv2.imshow(\"Imagem\", image)\n",
        "\t#cv2.waitKey(0)\n",
        "\n",
        "  plt.figure(figsize=(12,8))\n",
        "  plt.title(gtLabels[prediction])\n",
        "  plt.imshow(image)\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-7d89613da498>\"\u001b[0;36m, line \u001b[0;32m41\u001b[0m\n\u001b[0;31m    print(probs)\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "QVbNs_GNb5k5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "8e4c0066-b410-416b-c0d4-7b8b7280f5d8"
      },
      "cell_type": "code",
      "source": [
        "[x for x in paths.list_images(test_images) ]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imagens/image2.jpg',\n",
              " 'imagens/image3.jpg',\n",
              " 'imagens/image9.jpg',\n",
              " 'imagens/image7.jpg',\n",
              " 'imagens/image4.jpg',\n",
              " 'imagens/image1.jpg',\n",
              " 'imagens/image6.jpg',\n",
              " 'imagens/image10.jpg',\n",
              " 'imagens/image5.jpg',\n",
              " 'imagens/image8.jpg']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "Wex5eSmib5iI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "291db689-fdd5-4317-87b2-970c84629e83"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convnet.py  modelo.hdf5  modeloVGGNet.hdf5  __pycache__  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Fd-9CBurb5d_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp modelo.hdf5 modeloVGGNet.hdf5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UCAwf0EQTJ-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "89c5452a-6222-4367-8d61-6e64abb2afbc"
      },
      "cell_type": "code",
      "source": [
        "# Rede Neural Convolucional Para Classificação de Imagens\n",
        "\n",
        "\n",
        "# import the necessary packages\n",
        "from convnet import ConvNetFactory\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "# hiperparametros\n",
        "network='minivggnet'\n",
        "model_path='modelo.hdf5'\n",
        "epochs=20\n",
        "dropout=1\n",
        "activation=\"tanh\"\n",
        "batch_size=32\n",
        "verbose=1\n",
        "\n",
        "# Carrega os dados de treinamento e teste e, em seguida, dimensiona no intervalo [0, 1]\n",
        "print(\"\\nCarregando os dados de treino...\")\n",
        "((trainData, trainLabels), (testData, testLabels)) = cifar10.load_data()\n",
        "trainData = trainData.astype(\"float\") / 255.0\n",
        "testData = testData.astype(\"float\") / 255.0\n",
        "\n",
        "# Transforma os rótulos de treinamento e teste em vetores no intervalo [0, numClasses]\n",
        "# Isso gera um vetor para cada rótulo, onde o índice do rótulo é definido como `1` e todas as outras entradas para `0`\n",
        "# No caso do CIFAR-10, existem 10 rótulos de classe\n",
        "trainLabels = np_utils.to_categorical(trainLabels, 10)\n",
        "testLabels = np_utils.to_categorical(testLabels, 10)\n",
        "\n",
        "# Coleta os argumentos\n",
        "kargs = {\"dropout\": dropout > 0, \"activation\": activation}\n",
        "\n",
        "# Treina o modelo usando SGD\n",
        "print(\"Compilando o modelo...\")\n",
        "model = ConvNetFactory.build(network, 3, 32, 32, 10, **kargs)\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
        "\n",
        "# Inicia o treinamento\n",
        "print(\"Iniciando o treinamento...\\n\")\n",
        "model.fit(trainData, trainLabels, batch_size=batch_size, epochs=epochs, verbose=verbose)\n",
        "\n",
        "# Mostra a acurácia nos dados de teste\n",
        "(loss, accuracy) = model.evaluate(testData, testLabels, batch_size=batch_size, verbose=verbose)\n",
        "print(\"Acurácia: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Salva o modelo \n",
        "print(\"\\nSalvando o modelo...\")\n",
        "model.save(model_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Carregando os dados de treino...\n",
            "Compilando o modelo...\n",
            "Iniciando o treinamento...\n",
            "\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 16s 314us/step - loss: 1.8898 - acc: 0.4139\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 15s 309us/step - loss: 1.2038 - acc: 0.5848\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.9978 - acc: 0.6543\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 16s 321us/step - loss: 0.8859 - acc: 0.6906\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 16s 313us/step - loss: 0.8080 - acc: 0.7175\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 15s 310us/step - loss: 0.7495 - acc: 0.7370\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 16s 314us/step - loss: 0.7099 - acc: 0.7515\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 15s 309us/step - loss: 0.6670 - acc: 0.7643\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.6390 - acc: 0.7750\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.6098 - acc: 0.7867\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.5763 - acc: 0.7972\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 16s 310us/step - loss: 0.5564 - acc: 0.8056\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 16s 315us/step - loss: 0.5311 - acc: 0.8128\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.5162 - acc: 0.8172\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.4955 - acc: 0.8255\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.4796 - acc: 0.8307\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.4660 - acc: 0.8346\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 16s 321us/step - loss: 0.4479 - acc: 0.8429\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 16s 325us/step - loss: 0.4392 - acc: 0.8447\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.4181 - acc: 0.8516\n",
            "10000/10000 [==============================] - 1s 107us/step\n",
            "Acurácia: 80.85%\n",
            "\n",
            "Salvando o modelo...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ykott3isAwKz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Faz download do arquivo de pesos do Modelo"
      ]
    },
    {
      "metadata": {
        "id": "EH5Z9oYe_hYL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files \n",
        "model_path='modeloVGGNet.hdf5'\n",
        "files.download(model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}