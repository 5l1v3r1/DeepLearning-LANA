{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectando Faces em Vídeos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para detectar faces em arquivos de vídeo, exeucte: python cap05-06-detect_faces_video.py --video videos/video1.mp4\n",
    "# Para detectar faces em ao vivo em sua webcam, exeucte: python cap05-06-detect_faces_video.py \n",
    "\n",
    "# Imports\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "video = 'videos/video1.mp4'\n",
    "# Criando o classificador\n",
    "detector = cv2.CascadeClassifier(\"cascades/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Se um caminho de vídeo não foi fornecido, usamos a referência para a webcam\n",
    "if len(video) == 0: \n",
    "    camera = cv2.VideoCapture(0) # Caso você tenha mais de uma webcam, altere o valor que indica sua webcam: 1, 2, etc...\n",
    "\n",
    "# Caso contrário, usamos a referência ao arquivo de vídeo\n",
    "else:\n",
    "    camera = cv2.VideoCapture(video)\n",
    "\n",
    "# Navegamos pelos frames do vídeo enquanto não for pressionada a tecla \"q\" no seu teclado\n",
    "while True:\n",
    "    # Obtém o frame corrente\n",
    "    (grabbed, frame) = camera.read()\n",
    "\n",
    "    # Se estivermos vendo um vídeo e não pegarmos um frame, chegamos ao final do vídeo\n",
    "    if len(video) > 0 and not grabbed:\n",
    "        break\n",
    "\n",
    "    # Resize do frame, conversão para grayscale e detecção de faces no frame\n",
    "    frame = imutils.resize(frame, width=570)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faceRects = detector.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5, minSize=(30, 30), flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "    # Loop pelas faces e desenho dos retângulos\n",
    "    for (x, y, w, h) in faceRects:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Mostra o frame na nossa tela\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Se a tecla 'q' for pressionada, interrompe o loop e para a execução do script\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Limpa a câmera e fecha a janela\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
