{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cmemory.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning_LANA/blob/master/CUDA/cmemory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "euNcdzooIzhF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Utilizando constant memory parasomarr em GPU"
      ]
    },
    {
      "metadata": {
        "id": "UvgWDR_dJEBO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\\#include <cuda_profiler_api.h>\n",
        "\n",
        "\\#include <stdio.h>\n",
        "\n",
        "\\#include <iostream>\n",
        "  \n",
        "\\#include <vector>\n",
        "  \n",
        "\\#include <algorithm>\n",
        "  \n",
        "\\#include <numeric>\n",
        "  \n",
        "\n",
        "\\#define AxCheckError(err) CheckError(err,__FUNCTION__, __LINE__)\n",
        "  \n",
        "\\#define AxCheckErrorMsg(err, msg) CheckErrorMsg(err, msg, __FUNCTION__, __LINE__)\n",
        "  \n",
        "\n",
        "void GenerateTestData(int const N, float* const input, float* const filtered, \n",
        "                      float* const ref);\n",
        "void CompareData(int const N, float const* const a, float const* const b);\n",
        "\n",
        "void CheckError(cudaError_t const err, char const* const fun, const int line);\n",
        "void CheckErrorMsg(cudaError_t const err, char const* const msg, char const* const fun, int const line);\n",
        "\n",
        "\\#define BLOCK_SIZE  512\n",
        "  \n",
        "\n",
        "\n",
        "float const FILTER_COEFFS[21] = {0.005f,0.01f, 0.02f, 0.03f, 0.04f, \n",
        "                                 0.05f, 0.06f, 0.07f, 0.25f, 0.75f, \n",
        "                                 1.0f,  0.75f, 0.25f, 0.07f, 0.06f, \n",
        "                                 0.05f, 0.04f, 0.03f, 0.02f, 0.01f, 0.005f};\n",
        "  \n",
        "\n",
        "// Armazenado na Constant Memory\n",
        "__device__ __constant__ float FilterCoeffs[21] =  {0.005f,0.01f, 0.02f, 0.03f, 0.04f, \n",
        "                                                   0.05f, 0.06f, 0.07f, 0.25f, 0.75f, \n",
        "                                                   1.0f,  0.75f, 0.25f, 0.07f, 0.06f, \n",
        "                                                   0.05f, 0.04f, 0.03f, 0.02f, 0.01f, 0.005f};\n",
        "  \n",
        "\n",
        "\n",
        "// Usa apenas a Global Memory\n",
        "__global__ void GlobalFilter(float* const input, float* const filtered, int const N)\n",
        "{\n",
        "  \n",
        "   \n",
        "    int gIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "    if (10 < gIdx && gIdx < N - 10)\n",
        "    {\n",
        "        float sum;\n",
        "        sum = input[gIdx - 10] * FilterCoeffs[ 0] +\n",
        "              input[gIdx -  9] * FilterCoeffs[ 1] + \n",
        "              input[gIdx -  8] * FilterCoeffs[ 2] + \n",
        "              input[gIdx -  7] * FilterCoeffs[ 3] +\n",
        "              input[gIdx -  6] * FilterCoeffs[ 4] +\n",
        "              input[gIdx -  5] * FilterCoeffs[ 5] + \n",
        "              input[gIdx -  4] * FilterCoeffs[ 6] + \n",
        "              input[gIdx -  3] * FilterCoeffs[ 7] +\n",
        "              input[gIdx -  2] * FilterCoeffs[ 8] + \n",
        "              input[gIdx -  1] * FilterCoeffs[ 9] + \n",
        "              input[gIdx     ] * FilterCoeffs[10] + \n",
        "              input[gIdx +  1] * FilterCoeffs[11] + \n",
        "              input[gIdx +  2] * FilterCoeffs[12] +\n",
        "              input[gIdx +  3] * FilterCoeffs[13] +\n",
        "              input[gIdx +  4] * FilterCoeffs[14] +\n",
        "              input[gIdx +  5] * FilterCoeffs[15] +\n",
        "              input[gIdx +  6] * FilterCoeffs[16] +\n",
        "              input[gIdx +  7] * FilterCoeffs[17] +\n",
        "              input[gIdx +  8] * FilterCoeffs[18] +\n",
        "              input[gIdx +  9] * FilterCoeffs[19] +\n",
        "              input[gIdx + 10] * FilterCoeffs[20];\n",
        "\n",
        "        filtered[gIdx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Usa a Shared Memory\n",
        "  \n",
        "__global__ void SharedFilter(float* const input, float* const filtered, int const N)\n",
        "{\n",
        "  \n",
        "    __shared__ float inputS[BLOCK_SIZE+20];\n",
        "    int sIdx = threadIdx.x;\n",
        "    long long gIdx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    \n",
        "\t// Dez valores extras no índice\n",
        "    int sIdxShift = sIdx + 10;\n",
        "\n",
        "    // Todas as threads fazem a leitura de um elemento na Global Memory e armazenam na Shared Memory.\n",
        "    if (gIdx < N)\n",
        "    {\n",
        "        inputS[sIdxShift] = input[gIdx];\n",
        "    }\n",
        "\n",
        "    // As primeiras 10 threads no bloco armazenam os 10 valores extras nos 10 primeiros elementos da Shared Memory\n",
        "    if(sIdx < 10 && blockIdx.x != 0)\n",
        "    {\n",
        "        inputS[sIdx] = input[gIdx - 10];\n",
        "    }\n",
        "\n",
        "    // As últimas 10 threads armazenam os 10 valores extras na Shared Memory \n",
        "    if(sIdxShift >= blockDim.x && blockIdx.x < gridDim.x - 1)\n",
        "    {\n",
        "        inputS[sIdxShift + 10] = input[gIdx + 10];\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "    \n",
        "    float sum;\n",
        "    sum = inputS[sIdxShift - 10] * FilterCoeffs[ 0] +\n",
        "          inputS[sIdxShift -  9] * FilterCoeffs[ 1] + \n",
        "          inputS[sIdxShift -  8] * FilterCoeffs[ 2] + \n",
        "          inputS[sIdxShift -  7] * FilterCoeffs[ 3] +\n",
        "          inputS[sIdxShift -  6] * FilterCoeffs[ 4] +\n",
        "          inputS[sIdxShift -  5] * FilterCoeffs[ 5] + \n",
        "          inputS[sIdxShift -  4] * FilterCoeffs[ 6] + \n",
        "          inputS[sIdxShift -  3] * FilterCoeffs[ 7] +\n",
        "          inputS[sIdxShift -  2] * FilterCoeffs[ 8] + \n",
        "          inputS[sIdxShift -  1] * FilterCoeffs[ 9] + \n",
        "          inputS[sIdxShift     ] * FilterCoeffs[10] + \n",
        "          inputS[sIdxShift +  1] * FilterCoeffs[11] + \n",
        "          inputS[sIdxShift +  2] * FilterCoeffs[12] +\n",
        "          inputS[sIdxShift +  3] * FilterCoeffs[13] +\n",
        "          inputS[sIdxShift +  4] * FilterCoeffs[14] +\n",
        "          inputS[sIdxShift +  5] * FilterCoeffs[15] +\n",
        "          inputS[sIdxShift +  6] * FilterCoeffs[16] +\n",
        "          inputS[sIdxShift +  7] * FilterCoeffs[17] +\n",
        "          inputS[sIdxShift +  8] * FilterCoeffs[18] +\n",
        "          inputS[sIdxShift +  9] * FilterCoeffs[19] +\n",
        "          inputS[sIdxShift + 10] * FilterCoeffs[20];\n",
        "\n",
        "    filtered[gIdx] = sum;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "                                                        \n",
        "    float *inputH, *filteredH, *refH;\n",
        "    float *inputD, *filteredD;\n",
        "    cudaError_t e = cudaSuccess;\n",
        "    dim3 gridSize, gridSize2;\n",
        "    dim3 blockSize;\n",
        "\n",
        "    int const N = 16*1024*1024;\n",
        "    int const N_BYTES = N * sizeof(float);\n",
        "\n",
        "    inputH =    (float*)malloc(N_BYTES);\n",
        "    filteredH = (float*)malloc(N_BYTES);\n",
        "    refH =      (float*)malloc(N_BYTES);\n",
        "\n",
        "    GenerateTestData(N, inputH, filteredH, refH);\n",
        "\n",
        "    e = cudaMalloc((void**)&inputD, N_BYTES);\n",
        "    AxCheckError(e);\n",
        "    e = cudaMalloc((void**)&filteredD, N_BYTES);\n",
        "    AxCheckError(e);\n",
        "\n",
        "    e = cudaMemcpy(inputD, inputH, N_BYTES, cudaMemcpyHostToDevice);\n",
        "    AxCheckError(e);\n",
        "\n",
        "    gridSize.x = ((N + BLOCK_SIZE - 1) / BLOCK_SIZE); \n",
        "    blockSize.x = BLOCK_SIZE; \n",
        "\n",
        "    int const TRIALS = 5;\n",
        "    std::vector<float> sharedTimes;\n",
        "    std::vector<float> globalTimes;\n",
        "    cudaEvent_t start, stop;\n",
        "\n",
        "    e = cudaEventCreate(&start);\n",
        "    AxCheckError(e);\n",
        "    e = cudaEventCreate(&stop);\n",
        "    AxCheckError(e);\n",
        "\n",
        "    e = cudaProfilerStart();\n",
        "\n",
        "    for(int i = 0; i < TRIALS; i++)\n",
        "    {\n",
        "        e = cudaEventRecord(start, 0);\n",
        "        SharedFilter<<<gridSize, blockSize>>>(inputD, filteredD, N);\n",
        "        e = cudaEventRecord(stop, 0);\n",
        "        AxCheckError(cudaDeviceSynchronize());\n",
        "        AxCheckError(cudaGetLastError());\n",
        "\n",
        "        float elapsed;\n",
        "        e = cudaEventElapsedTime(&elapsed, start, stop);\n",
        "        sharedTimes.push_back(elapsed);\n",
        "\n",
        "        e = cudaEventRecord(start, 0);\n",
        "        GlobalFilter<<<gridSize, blockSize>>>(inputD, filteredD, N);\n",
        "        e = cudaEventRecord(stop, 0);\n",
        "        AxCheckError(cudaDeviceSynchronize());\n",
        "        AxCheckError(cudaGetLastError());\n",
        "\n",
        "        e = cudaEventElapsedTime(&elapsed, start, stop);\n",
        "        globalTimes.push_back(elapsed);\n",
        "    }\n",
        "\n",
        "    e = cudaProfilerStop();\n",
        "\n",
        "    float averageTime = std::accumulate(globalTimes.begin(), globalTimes.end(), 0.0f)/globalTimes.size();\n",
        "    std::cout << \"Global Memory time (ms): \" << averageTime << std::endl;\n",
        "    averageTime = std::accumulate(sharedTimes.begin(), sharedTimes.end(), 0.0f)/sharedTimes.size();\n",
        "    std::cout << \"Shared Memory time (ms): \" << averageTime << std::endl;\n",
        "\n",
        "    /* Executando o kernel */\n",
        "    SharedFilter<<<gridSize, blockSize>>>(inputD, filteredD, N);\n",
        "    AxCheckError(cudaDeviceSynchronize());\n",
        "    AxCheckError(cudaGetLastError());\n",
        "\n",
        "    /* Não geramos zeros para os 10 primeiros / últimos 10 elementos no kernel. Na verdade, geramos valores usando\n",
        "        Shared Memory não inicializada como entradas, logo elas estão incorretas. Portanto, não os copiamos e confiamos\n",
        "        no fato de que o filtro H foi previamente ajustado para zero. */\n",
        "    e = cudaMemcpy(filteredH + 10, filteredD + 10, N_BYTES - 20 * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    AxCheckError(e);\n",
        "\n",
        "    std::cout << \"Validando o output do SharedFilter...\" << std::endl;\n",
        "    CompareData(N, filteredH, refH);\n",
        "\n",
        "    /* Executando o kernel */\n",
        "    GlobalFilter<<<gridSize, blockSize>>>(inputD, filteredD, N);\n",
        "    AxCheckError(cudaDeviceSynchronize());\n",
        "    AxCheckError(cudaGetLastError());\n",
        "\n",
        "    /* Nós não geramos saída para os 10 primeiros / últimos 10 elementos no kernel. Portanto, não os copiamos e confiamos\n",
        "     no fato de que o filtroH foi previamente ajustado para zero. */\n",
        "    e = cudaMemcpy(filteredH + 10, filteredD + 10, N_BYTES - 20 * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    AxCheckError(e);\n",
        "\n",
        "    std::cout << \"Validando o output do GlobalFilter...\" << std::endl;\n",
        "    CompareData(N, filteredH, refH);\n",
        "\n",
        "    cudaFree(inputD); cudaFree(filteredD);\n",
        "    free(inputH); free(filteredH); free(refH);\n",
        "\n",
        "    AxCheckError(cudaDeviceReset());\n",
        "\n",
        "\tgetchar();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "void GenerateTestData(int const N, float* const input, float* const filtered, float* const ref)\n",
        "{\n",
        "    int i;\n",
        "\n",
        "    for(i = 0; i < N; i++)\n",
        "    {\n",
        "                     \n",
        "        //input[i] = ((float)rand())/RAND_MAX;\n",
        "        input[i] = i;\n",
        "        filtered[i] = 0.0f;\n",
        "    }\n",
        "\n",
        "    memset(ref, 0, N*sizeof(float) );\n",
        "\n",
        "    /* Não podemos calcular um filtro de 21 pontos nas bordas da nossa matriz.\n",
        "        Se todos os 21 pontos não estiverem disponíveis, o resultado esperado é zero! */\n",
        "    for(i = 10; i < N-10; i++)\n",
        "    {   \n",
        "  \n",
        "        ref[i] = (input[i-10]*FILTER_COEFFS[ 0] +\n",
        "                  input[i- 9]*FILTER_COEFFS[ 1] +\n",
        "                  input[i- 8]*FILTER_COEFFS[ 2] +\n",
        "                  input[i- 7]*FILTER_COEFFS[ 3] +\n",
        "                  input[i- 6]*FILTER_COEFFS[ 4] +\n",
        "                  input[i- 5]*FILTER_COEFFS[ 5] +\n",
        "                  input[i- 4]*FILTER_COEFFS[ 6] +\n",
        "                  input[i- 3]*FILTER_COEFFS[ 7] +\n",
        "                  input[i- 2]*FILTER_COEFFS[ 8] +\n",
        "                  input[i- 1]*FILTER_COEFFS[ 9] + \n",
        "                  input[i   ]*FILTER_COEFFS[10] + \n",
        "                  input[i+ 1]*FILTER_COEFFS[11] + \n",
        "                  input[i+ 2]*FILTER_COEFFS[12] + \n",
        "                  input[i+ 3]*FILTER_COEFFS[13] + \n",
        "                  input[i+ 4]*FILTER_COEFFS[14] + \n",
        "                  input[i+ 5]*FILTER_COEFFS[15] + \n",
        "                  input[i+ 6]*FILTER_COEFFS[16] + \n",
        "                  input[i+ 7]*FILTER_COEFFS[17] + \n",
        "                  input[i+ 8]*FILTER_COEFFS[18] + \n",
        "                  input[i+ 9]*FILTER_COEFFS[19] + \n",
        "                  input[i+10]*FILTER_COEFFS[20]);\n",
        "    }\n",
        "}\n",
        "\n",
        "int UlpDifference(float a, float b)\n",
        "{\n",
        "  \n",
        "    int iA, iB;\n",
        "    iA = *((int*)(&a));\n",
        "    iB = *((int*)(&b));\n",
        "    return abs(iA - iB);\n",
        "}\n",
        "\n",
        "void CompareData(int const N, float const* const a, float const* const b)\n",
        "{\n",
        "  \n",
        "    int i;\n",
        "    int different = 0;\n",
        "\n",
        "    for(i = 0; i < N; i++)\n",
        "    {\n",
        "        different = (UlpDifference(a[i],b[i]) > 5);\n",
        "        if(different)\n",
        "        {\n",
        "            std::cout << \"Mismatch: \" << a[i] << \" \" << b[i] << std::endl;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if(different)\n",
        "    {\n",
        "        printf(\"Arrays do not match @%d.\\n\", i);\n",
        "    }\n",
        "    else\n",
        "    {\n",
        "        printf(\"Arrays match.\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "void CheckError(cudaError_t const err, char const* const fun, const int line)\n",
        "{\n",
        "    if (err)\n",
        "    {\n",
        "        printf(\"CUDA Error Code[%d]: %s %s():%d\\n\",err,cudaGetErrorString(err),fun,line);\n",
        "        exit(1);\n",
        "    }\n",
        "}\n",
        "\n",
        "void CheckErrorMsg(cudaError_t const err, char const* const msg, char const* const fun, int const line)\n",
        "{\n",
        "    if (err)\n",
        "    {\n",
        "        printf(\"CUDA Error Code[%d]: %s %s() %d\\n%s\\n\",err,cudaGetErrorString(err),fun,line,msg);\n",
        "        exit(1);\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "metadata": {
        "id": "6lBZzhIYIvtX",
        "colab_type": "code",
        "outputId": "874365ec-69aa-4e70-9960-b72ba3ca4246",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7ddb73c7-70a0-4cd7-bbb7-bbc2a46637f5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7ddb73c7-70a0-4cd7-bbb7-bbc2a46637f5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving cmemory.cu to cmemory.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cacR6PpzlFZo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## compilando o código CUDA"
      ]
    },
    {
      "metadata": {
        "id": "QRUzuzwVJeY_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!nvcc cmemory.cu -o cmemory"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OgxXhyc-lJmi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Executando o código CUDA na GPU"
      ]
    },
    {
      "metadata": {
        "id": "njzigHX4k9bq",
        "colab_type": "code",
        "outputId": "c883d03b-2cbe-441c-988e-2ba15f7e1b4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!./cmemory"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Global Memory time (ms): 7.51076\n",
            "Shared Memory time (ms): 2.49276\n",
            "Validando o output do SharedFilter...\n",
            "Arrays match.\n",
            "Validando o output do GlobalFilter...\n",
            "Arrays match.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}