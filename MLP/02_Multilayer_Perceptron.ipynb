{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-Multilayer-Perceptron.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/MLP/02_Multilayer_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Oo7-U_u2Lt7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Multilayer Perceptron"
      ]
    },
    {
      "metadata": {
        "id": "zkisLiDZLt7g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Implementação com TensorFlow "
      ]
    },
    {
      "metadata": {
        "id": "iCKxLa93Lt7h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "metadata": {
        "id": "RW7KpP4qLx-p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Leitura  dos dados"
      ]
    },
    {
      "metadata": {
        "id": "Y3WYbbypLw56",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "54e4611c-b05e-417d-9dfa-e4640fa00943"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d6dcd654-a84d-4ae3-9f92-56b6afe585aa\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d6dcd654-a84d-4ae3-9f92-56b6afe585aa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving t10k-images-idx3-ubyte.gz to t10k-images-idx3-ubyte (1).gz\n",
            "Saving t10k-labels-idx1-ubyte.gz to t10k-labels-idx1-ubyte (1).gz\n",
            "Saving train-images-idx3-ubyte.gz to train-images-idx3-ubyte (1).gz\n",
            "Saving train-labels-idx1-ubyte.gz to train-labels-idx1-ubyte (1).gz\n",
            "Saving Arquitetura-MNIST.png to Arquitetura-MNIST (1).png\n",
            "Saving mnist-sample.png to mnist-sample (1).png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hj60C2WJOzEf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# listar os arquivos da pasta corrente\n",
        "#import os\n",
        "#items = os.listdir('/content')\n",
        "#[print(item) for item in items ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T6HP1jAvLt7h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compreendendo o Dataset\n",
        "\n",
        "MNIST é um dataset que contém 70.000 imagens rotuladas de dígitos escritos à mão, conforme imagem abaixo.\n",
        "\n",
        "![MNIST Data Sample](https://github.com/vladimiralencar/DeepLearning-LANA/blob/master/images/mnist-sample.png?raw=true  \"MNIST Data Sample\")\n",
        "\n",
        "Nós vamos treinar um classificador linear em uma parte desse conjunto de dados e depois testar o classificador contra outra parte do conjunto de dados para avaliar a performance do nosso modelo. Para isso usaremos um modelo Multilayer Perceptron."
      ]
    },
    {
      "metadata": {
        "id": "kxPPGEYELt7j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##########################\n",
        "### Importando os Módulos\n",
        "##########################\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0)\n",
        "plt.rcParams['image.cmap'] = 'Greys'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0MHIBc7Lt7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "29384d3d-057f-420e-d7cd-cca8cba8bba9"
      },
      "cell_type": "code",
      "source": [
        "##########################\n",
        "### DATASET\n",
        "##########################\n",
        "#file = \"/media/datasets/DeepLearningI/Cap04/MNIST\"\n",
        "mnist = input_data.read_data_sets(\"MNIST\", one_hot = True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-821e4fc78579>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_NDAUFk3Lt7s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Esse procedimento já divide o conjunto de dados em três partes:\n",
        "\n",
        "* Dataset de treino (55000 exemplos) usado para treinar o modelo\n",
        "* Dataset de validação (5000 exemplos) usado para otimizar os hiperparâmetros \n",
        "* Dataset de test (10000 exemplos) usado para avaliar a precisão do modelo treinado\n",
        "\n",
        "As imagens estão em escala de cinza e cada uma tem dimensão de 28 pixels de largura por 28 pixels de altura sendo armazenada em uma matriz de comprimento 784.\n",
        "\n",
        "Os rótulos (labels) são um vetor * one hot * de comprimento 10, o que significa que é um vetor preenchido com zeros, exceto no local que corresponde ao rótulo a que se refere. Por exemplo. Uma imagem com label `3` será representada como `(0, 0, 0, 1, 0, 0, 0, 0, 0, 0)`.\n"
      ]
    },
    {
      "metadata": {
        "id": "mmUs7fP7Lt7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d4ac3454-4efb-4c17-fd24-e7d911313508"
      },
      "cell_type": "code",
      "source": [
        "print (mnist.train.images.shape)\n",
        "print (mnist.train.labels.shape) "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55000, 784)\n",
            "(55000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mBGGSbP8Lt7w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2197fda9-d296-48fd-aca1-37846f5b62a5"
      },
      "cell_type": "code",
      "source": [
        "print (mnist.validation.images.shape)\n",
        "print (mnist.validation.labels.shape) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 784)\n",
            "(5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4KUwf_YJLt70",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eb18fd87-d6b1-4f0e-b99c-f27f71ea7478"
      },
      "cell_type": "code",
      "source": [
        "print (mnist.test.images.shape)\n",
        "print (mnist.test.labels.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 784)\n",
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J3dm_67pLt74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "e51615d4-d140-4044-f58a-378c547d5bbd"
      },
      "cell_type": "code",
      "source": [
        "##########################\n",
        "### Visualizando os Dados\n",
        "##########################\n",
        "example_image = mnist.train.images[1]\n",
        "example_image_reshaped = example_image.reshape((28, 28)) \n",
        "example_label = mnist.train.labels[1]\n",
        "\n",
        "print (example_label)\n",
        "plt.imshow(example_image_reshaped)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd251570668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAVdJID/BzkaX0WzFRABAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Aj40IstBLt7-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uTEyFASjLt8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06c35912-4df8-4e5d-dfcd-b6f7c97b9dc6"
      },
      "cell_type": "code",
      "source": [
        "np.count_nonzero(example_image)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "172"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "UVxap16ZLt8F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1413
        },
        "outputId": "8ea12388-9846-4ffa-e3a6-78d7b5740e42"
      },
      "cell_type": "code",
      "source": [
        "a = example_image\n",
        "unique, counts = np.unique(a, return_counts=True)\n",
        "df = pd.DataFrame({'value': unique, 'ocur':counts, })\n",
        "df.sort_values('ocur', ascending=False)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ocur</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>612</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>31</td>\n",
              "      <td>0.992157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>16</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>14</td>\n",
              "      <td>0.996078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>11</td>\n",
              "      <td>0.796079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>7</td>\n",
              "      <td>0.592157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>0.078431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>6</td>\n",
              "      <td>0.913726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>5</td>\n",
              "      <td>0.321569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>5</td>\n",
              "      <td>0.835294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>5</td>\n",
              "      <td>0.160784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>4</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.082353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>4</td>\n",
              "      <td>0.243137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>4</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3</td>\n",
              "      <td>0.596078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>0.121569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>3</td>\n",
              "      <td>0.717647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>0.156863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3</td>\n",
              "      <td>0.196078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2</td>\n",
              "      <td>0.878431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2</td>\n",
              "      <td>0.556863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2</td>\n",
              "      <td>0.482353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2</td>\n",
              "      <td>0.674510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2</td>\n",
              "      <td>0.952941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2</td>\n",
              "      <td>0.752941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>0.239216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>0.360784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2</td>\n",
              "      <td>0.839216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2</td>\n",
              "      <td>0.874510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>0.509804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0.117647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1</td>\n",
              "      <td>0.956863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1</td>\n",
              "      <td>0.909804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>0.831373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>0.517647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>0.435294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0.439216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>0.678431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>0.443137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>0.639216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.043137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>0.670588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ocur     value\n",
              "0    612  0.000000\n",
              "41    31  0.992157\n",
              "40    16  0.988235\n",
              "42    14  0.996078\n",
              "30    11  0.796079\n",
              "22     7  0.592157\n",
              "2      7  0.078431\n",
              "37     6  0.913726\n",
              "12     5  0.321569\n",
              "32     5  0.835294\n",
              "7      5  0.160784\n",
              "43     4  1.000000\n",
              "3      4  0.082353\n",
              "11     4  0.243137\n",
              "14     4  0.400000\n",
              "23     3  0.596078\n",
              "5      3  0.121569\n",
              "28     3  0.717647\n",
              "6      3  0.156863\n",
              "8      3  0.196078\n",
              "35     2  0.878431\n",
              "21     2  0.556863\n",
              "18     2  0.482353\n",
              "26     2  0.674510\n",
              "38     2  0.952941\n",
              "29     2  0.752941\n",
              "10     2  0.239216\n",
              "13     2  0.360784\n",
              "33     2  0.839216\n",
              "34     2  0.874510\n",
              "19     1  0.509804\n",
              "9      1  0.200000\n",
              "4      1  0.117647\n",
              "39     1  0.956863\n",
              "36     1  0.909804\n",
              "31     1  0.831373\n",
              "20     1  0.517647\n",
              "15     1  0.435294\n",
              "16     1  0.439216\n",
              "27     1  0.678431\n",
              "17     1  0.443137\n",
              "24     1  0.639216\n",
              "1      1  0.043137\n",
              "25     1  0.670588"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "XcV4aSkLLt8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce653056-2fcb-43b2-8fba-bf38882b73bf"
      },
      "cell_type": "code",
      "source": [
        "df.ocur.sum()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "8tITcGzILt8N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Arquitetura da Rede\n",
        "\n",
        "Agora que compreendemos melhor o conjunto de dados com o qual estamos trabalhando, vamos passar para os bits de aprendizado da máquina."
      ]
    },
    {
      "metadata": {
        "id": "gHhzpJ_ELt8Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Neural network 1 hidden layer](https://github.com/vladimiralencar/DeepLearning-LANA/blob/master/images/Arquitetura-MNIST.png?raw=true \"Neural network with 1 hidden layer\")"
      ]
    },
    {
      "metadata": {
        "id": "JCqslXCuLt8R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##########################\n",
        "### Configurações\n",
        "##########################\n",
        "\n",
        "# Hiperparâmetros\n",
        "learning_rate = 0.1 # tamanho da passada\n",
        "training_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "# Arquitetura\n",
        "n_hidden_1 = 128\n",
        "n_hidden_2 = 256\n",
        "n_input = 784\n",
        "n_classes = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cR8r5KspLt8U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Definindo o Grafo Computacional"
      ]
    },
    {
      "metadata": {
        "id": "0YT5MeWPLt8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primeiro, configuramos alguns espaços reservados (placeholders) para armazenar lotes desses dados de treinamento para quando treinarmos nosso modelo. A razão pela qual trabalhamos em lotes é que é mais fácil carregar na memória do que usar todo o conjunto. E é essa noção de trabalhar com lotes (aleatórios) de entrada ao invés de todo o conjunto que nos move do domínio de * Gradient Descent * que vimos anteriormente, para * Stochastic Gradient Descent * que temos aqui. Depois criamos as camadas, a função de perda e como vamos calcular as previsões."
      ]
    },
    {
      "metadata": {
        "id": "zV7eVWyELt8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Definiremos a inicialização de pesos e bias da seguinte forma:\n",
        "\n",
        "````\n",
        "W1 = tf.Variable(tf.zeros([784, 100]))\n",
        "b1 = tf.Variable(tf.zeros([100]))\n",
        "W2 = tf.Variable(tf.zeros([100, 10]))\n",
        "b2 = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "````\n",
        "\n",
        "Definimos também a nossa função de perda para medir a performance do modelo em imagens com rótulos conhecidos. Usamos a forma específica chamada de[cross entropy loss]"
      ]
    },
    {
      "metadata": {
        "id": "3I46nAACLt8X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##########################\n",
        "### Definição do Grafo no TensorFlow\n",
        "##########################\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "\n",
        "    # Input data\n",
        "    tf_x = tf.placeholder(tf.float32, [None, n_input], name = 'features')\n",
        "    tf_y = tf.placeholder(tf.float32, [None, n_classes], name = 'targets')\n",
        "\n",
        "    # Parâmetros do Modelo\n",
        "    weights = {\n",
        "        'w1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1], stddev = 0.1)),\n",
        "        'w2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2], stddev = 0.1)),\n",
        "        'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes], stddev = 0.1))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.zeros([n_hidden_1])),\n",
        "        'b2': tf.Variable(tf.zeros([n_hidden_2])),\n",
        "        'out': tf.Variable(tf.zeros([n_classes]))\n",
        "    }\n",
        "\n",
        "    # Multilayer perceptron\n",
        "    layer_1 = tf.add(tf.matmul(tf_x, weights['w1']), biases['b1'])\n",
        "    layer_1 = tf.nn.relu(layer_1)\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
        "    layer_2 = tf.nn.relu(layer_2)\n",
        "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
        "\n",
        "    # Loss e optimizer\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits = out_layer, labels = tf_y)\n",
        "    cost = tf.reduce_mean(loss, name = 'cost')\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
        "    train = optimizer.minimize(cost, name = 'train')\n",
        "\n",
        "    # Previsões\n",
        "    correct_prediction = tf.equal(tf.argmax(tf_y, 1), tf.argmax(out_layer, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = 'accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HY-lft1sLt8b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Treinando o modelo\n",
        "\n",
        "De acordo com o funcionamento do TensorFlow, nós realmente não executamos nenhum dos códigos acima no sentido clássico. Tudo o que fizemos foi definir o que é chamado de grafo computacional.\n",
        "\n",
        "Agora, vamos em frente e inicializamos uma sessão para realmente treinar o modelo e avaliar seu desempenho."
      ]
    },
    {
      "metadata": {
        "id": "g1Sj5443Lt8c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0c0ae941-a003-4dfd-b138-f9bd58911a8a"
      },
      "cell_type": "code",
      "source": [
        "##########################\n",
        "### Treinamento e Avaliação\n",
        "##########################\n",
        "\n",
        "with tf.Session(graph = g) as sess:\n",
        "    \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0.\n",
        "        total_batch = mnist.train.num_examples // batch_size\n",
        "\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "            _, c = sess.run(['train', 'cost:0'], feed_dict = {'features:0': batch_x, \n",
        "                                                              'targets:0': batch_y})\n",
        "            avg_cost += c\n",
        "        \n",
        "        train_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.train.images,\n",
        "                                                        'targets:0': mnist.train.labels})\n",
        "        \n",
        "        valid_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.validation.images, \n",
        "                                                        'targets:0': mnist.validation.labels})  \n",
        "        \n",
        "        print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / (i + 1)), end=\"\")\n",
        "        print(\" | Acurácia em Treino/Validação: %.3f/%.3f\" % (train_acc, valid_acc))\n",
        "        \n",
        "    test_acc = sess.run(accuracy, feed_dict = {'features:0': mnist.test.images,\n",
        "                                               'targets:0': mnist.test.labels})\n",
        "    \n",
        "    print('Acurácia em Teste: %.3f' % test_acc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001 | AvgCost: 0.346 | Acurácia em Treino/Validação: 0.947/0.950\n",
            "Epoch: 002 | AvgCost: 0.155 | Acurácia em Treino/Validação: 0.966/0.967\n",
            "Epoch: 003 | AvgCost: 0.112 | Acurácia em Treino/Validação: 0.974/0.970\n",
            "Epoch: 004 | AvgCost: 0.087 | Acurácia em Treino/Validação: 0.980/0.975\n",
            "Epoch: 005 | AvgCost: 0.071 | Acurácia em Treino/Validação: 0.983/0.974\n",
            "Epoch: 006 | AvgCost: 0.059 | Acurácia em Treino/Validação: 0.984/0.975\n",
            "Epoch: 007 | AvgCost: 0.049 | Acurácia em Treino/Validação: 0.987/0.978\n",
            "Epoch: 008 | AvgCost: 0.041 | Acurácia em Treino/Validação: 0.991/0.977\n",
            "Epoch: 009 | AvgCost: 0.035 | Acurácia em Treino/Validação: 0.992/0.978\n",
            "Epoch: 010 | AvgCost: 0.030 | Acurácia em Treino/Validação: 0.993/0.977\n",
            "Acurácia em Teste: 0.977\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}