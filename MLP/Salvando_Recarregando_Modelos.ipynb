{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Salvando-Recarregando-Modelos.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/MLP/Salvando_Recarregando_Modelos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6YberZ9GckE1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Salvando e Carregando Modelos Treinados"
      ]
    },
    {
      "metadata": {
        "id": "nk5HwmY9ewn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "19eaf6e4-8007-43a1-9111-f5b284e6c6e0"
      },
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jan 17 15:43:34 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   57C    P0    58W / 149W |   1303MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V2r1V5VEckE2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Definindo um Grafo Multilayer Perceptron "
      ]
    },
    {
      "metadata": {
        "id": "e_YQwU8dckE3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "##########################\n",
        "### Definindo o Modelo\n",
        "##########################\n",
        "\n",
        "# Função que define uma camada\n",
        "def fc_layer(input_tensor, \n",
        "             n_output_units, \n",
        "             name, \n",
        "             activation_fn = None, \n",
        "             seed = None, \n",
        "             weight_params = None, \n",
        "             bias_params = None):\n",
        "\n",
        "    with tf.variable_scope(name):\n",
        "\n",
        "        if weight_params is not None:\n",
        "            weights = tf.constant(weight_params, name = 'weights', dtype = tf.float32)\n",
        "        else:\n",
        "            weights = tf.Variable(tf.truncated_normal(\n",
        "                shape=[input_tensor.get_shape().as_list()[-1], n_output_units],\n",
        "                    mean = 0.0,\n",
        "                    stddev = 0.1,\n",
        "                    dtype = tf.float32,\n",
        "                    seed = seed),\n",
        "                name = 'weights',)\n",
        "\n",
        "        if bias_params is not None:\n",
        "            biases = tf.constant(bias_params, name = 'biases', dtype=tf.float32)\n",
        "\n",
        "        else:\n",
        "            biases = tf.Variable(tf.zeros(shape = [n_output_units]),\n",
        "                                 name = 'biases', \n",
        "                                 dtype = tf.float32)\n",
        "\n",
        "        act = tf.matmul(input_tensor, weights) + biases\n",
        "\n",
        "        if activation_fn is not None:\n",
        "            act = activation_fn(act)\n",
        "\n",
        "    return act\n",
        "\n",
        "# Função que define o grafo\n",
        "def mlp_graph(n_input = 784, \n",
        "              n_classes = 10, \n",
        "              n_hidden_1 = 128, \n",
        "              n_hidden_2 = 256,\n",
        "              learning_rate = 0.1,\n",
        "              fixed_params = None):\n",
        "    \n",
        "    # Carregando pesos e bias de arquivos NumPy\n",
        "    if not fixed_params:\n",
        "        var_names = ['fc1/weights:0', 'fc1/biases:0',\n",
        "                     'fc2/weights:0', 'fc2/biases:0',\n",
        "                     'logits/weights:0', 'logits/biases:0',]\n",
        "        \n",
        "        fixed_params = {v: None for v in var_names}\n",
        "        found_params = False\n",
        "    else:\n",
        "        found_params = True\n",
        "    \n",
        "    # Input data\n",
        "    tf_x = tf.placeholder(tf.float32, [None, n_input], name = 'features')\n",
        "    tf_y = tf.placeholder(tf.int32, [None], name = 'targets')\n",
        "    tf_y_onehot = tf.one_hot(tf_y, depth = n_classes, name = 'onehot_targets')\n",
        "\n",
        "    # Multilayer perceptron\n",
        "    fc1 = fc_layer(input_tensor = tf_x, \n",
        "                   n_output_units = n_hidden_1, \n",
        "                   name = 'fc1',\n",
        "                   weight_params = fixed_params['fc1/weights:0'], \n",
        "                   bias_params = fixed_params['fc1/biases:0'],\n",
        "                   activation_fn = tf.nn.relu)\n",
        "\n",
        "    fc2 = fc_layer(input_tensor = fc1, \n",
        "                   n_output_units = n_hidden_2, \n",
        "                   name = 'fc2',\n",
        "                   weight_params = fixed_params['fc2/weights:0'], \n",
        "                   bias_params = fixed_params['fc2/biases:0'],\n",
        "                   activation_fn = tf.nn.relu)\n",
        "    \n",
        "    logits = fc_layer(input_tensor = fc2, \n",
        "                      n_output_units = n_classes, \n",
        "                      name = 'logits',\n",
        "                      weight_params = fixed_params['logits/weights:0'], \n",
        "                      bias_params = fixed_params['logits/biases:0'],\n",
        "                      activation_fn = tf.nn.relu)\n",
        "    \n",
        "    # Loss e optimizer\n",
        "    ### Somente necessário se nenhum parâmetro existente for encontrado\n",
        "    ### e um grafo treinável deve ser inicializado\n",
        "    if not found_params:\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "            logits=logits, labels=tf_y_onehot)\n",
        "        cost = tf.reduce_mean(loss, name='cost')\n",
        "        optimizer = tf.train.GradientDescentOptimizer(\n",
        "            learning_rate=learning_rate)\n",
        "        train = optimizer.minimize(cost, name='train')\n",
        "\n",
        "    # Previsões\n",
        "    probabilities = tf.nn.softmax(logits, name = 'probabilities')\n",
        "    labels = tf.cast(tf.argmax(logits, 1), tf.int32, name = 'labels')\n",
        "    \n",
        "    correct_prediction = tf.equal(labels, tf_y, name='correct_predictions')\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name = 'accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cvJRxQveckFD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Treinando e Salvando o Modelo Multilayer Perceptron"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "KkoHs-EFckFE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "afba6d5f-7db5-4dca-c0a2-e404f0c37623"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "##########################\n",
        "### Configurações\n",
        "##########################\n",
        "\n",
        "# Hiperparâmetros\n",
        "learning_rate = 0.1\n",
        "training_epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "##########################\n",
        "### Definição do Grafo\n",
        "##########################\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "    mlp_graph()\n",
        "\n",
        "##########################\n",
        "### DATASET\n",
        "##########################\n",
        "file = '.'\n",
        "mnist = input_data.read_data_sets(file, one_hot = False)\n",
        "\n",
        "############################\n",
        "### Treinamento e Avaliação\n",
        "############################\n",
        "\n",
        "with tf.Session(graph = g) as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    saver0 = tf.train.Saver()\n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0.\n",
        "        total_batch = mnist.train.num_examples // batch_size\n",
        "\n",
        "        for i in range(total_batch):\n",
        "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "            _, c = sess.run(['train', 'cost:0'], feed_dict = {'features:0': batch_x,\n",
        "                                                            'targets:0': batch_y})\n",
        "            avg_cost += c\n",
        "        \n",
        "        train_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.train.images,\n",
        "                                                        'targets:0': mnist.train.labels})\n",
        "        \n",
        "        valid_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.validation.images,\n",
        "                                                        'targets:0': mnist.validation.labels})  \n",
        "        \n",
        "        print(\"Epoch: %03d | AvgCost: %.3f\" % (epoch + 1, avg_cost / (i + 1)), end=\"\")\n",
        "        print(\" | Acurácia em Treino/Validação: %.3f/%.3f\" % (train_acc, valid_acc))\n",
        "        \n",
        "    test_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.test.images,\n",
        "                                                   'targets:0': mnist.test.labels})\n",
        "    print('Acurácia em Teste: %.3f' % test_acc)\n",
        "    \n",
        "    ##################################\n",
        "    ### Salvando o Modelo Treinado ###\n",
        "    ##################################\n",
        "    saver0.save(sess, save_path = './mlp')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-526c34543389>:24: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./train-labels-idx1-ubyte.gz\n",
            "Extracting ./t10k-images-idx3-ubyte.gz\n",
            "Extracting ./t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "Epoch: 001 | AvgCost: 0.576 | Acurácia em Treino/Validação: 0.855/0.846\n",
            "Epoch: 002 | AvgCost: 0.385 | Acurácia em Treino/Validação: 0.870/0.858\n",
            "Epoch: 003 | AvgCost: 0.340 | Acurácia em Treino/Validação: 0.867/0.856\n",
            "Epoch: 004 | AvgCost: 0.238 | Acurácia em Treino/Validação: 0.970/0.964\n",
            "Epoch: 005 | AvgCost: 0.085 | Acurácia em Treino/Validação: 0.978/0.972\n",
            "Epoch: 006 | AvgCost: 0.068 | Acurácia em Treino/Validação: 0.985/0.974\n",
            "Epoch: 007 | AvgCost: 0.057 | Acurácia em Treino/Validação: 0.986/0.971\n",
            "Epoch: 008 | AvgCost: 0.047 | Acurácia em Treino/Validação: 0.989/0.978\n",
            "Epoch: 009 | AvgCost: 0.040 | Acurácia em Treino/Validação: 0.992/0.979\n",
            "Epoch: 010 | AvgCost: 0.033 | Acurácia em Treino/Validação: 0.992/0.977\n",
            "Acurácia em Teste: 0.976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TFNPMBg1ckFJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Recarregando o Modelo de Arquivos Meta e Checkpoint "
      ]
    },
    {
      "metadata": {
        "id": "QEBBMSFJf6Ub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e785b38b-1478-4c50-f0e3-83cee82b3914"
      },
      "cell_type": "code",
      "source": [
        "!ls -ilah mlp.meta"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15861705 -rw-r--r-- 1 root root 36K Jan 17 15:48 mlp.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pUCFgEqZckFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3a3e4177-52b3-4520-b4b2-cda656b3622b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "file = '.'\n",
        "mnist = input_data.read_data_sets(file, one_hot = False)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    saver1 = tf.train.import_meta_graph('./mlp.meta')\n",
        "    saver1.restore(sess, save_path = './mlp')\n",
        "    \n",
        "    test_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.test.images,\n",
        "                                                   'targets:0': mnist.test.labels})\n",
        "    print('Acurácia em Teste: %.3f' % test_acc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./train-images-idx3-ubyte.gz\n",
            "Extracting ./train-labels-idx1-ubyte.gz\n",
            "Extracting ./t10k-images-idx3-ubyte.gz\n",
            "Extracting ./t10k-labels-idx1-ubyte.gz\n",
            "INFO:tensorflow:Restoring parameters from ./mlp\n",
            "Acurácia em Teste: 0.976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "__2AaLWwckFR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Trabalhando com Arquivos NumPy e Criando Grafos Não-Treinados"
      ]
    },
    {
      "metadata": {
        "id": "TK7sCvJ7ckFS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exportando os Parâmetros do Modelo Para Arquivos NumPy NPZ "
      ]
    },
    {
      "metadata": {
        "id": "voDrveVNckFU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "34ef27b3-d250-4291-81b8-29d25485286a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.reset_default_graph()\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    saver1 = tf.train.import_meta_graph('./mlp.meta')\n",
        "    saver1.restore(sess, save_path='./mlp')\n",
        "    \n",
        "    var_names = [v.name for v in \n",
        "                 tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)]\n",
        "    \n",
        "    params = {}\n",
        "    print('Variáveis encontradas:')\n",
        "    for v in var_names:\n",
        "        print(v)\n",
        "        \n",
        "        ary = sess.run(v)\n",
        "        params[v] = ary\n",
        "        \n",
        "    np.savez('mlp', **params)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./mlp\n",
            "Variáveis encontradas:\n",
            "fc1/weights:0\n",
            "fc1/biases:0\n",
            "fc2/weights:0\n",
            "fc2/biases:0\n",
            "logits/weights:0\n",
            "logits/biases:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RrhTTOHtckFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Carregando Arquivos NumPy .npz em `mlp_graph`"
      ]
    },
    {
      "metadata": {
        "id": "4jY-wGkGckFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c052c7c3-ca23-495f-cc8a-33a408d80ed0"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "###########################\n",
        "### Carregando Dados e Parâmetros\n",
        "###########################\n",
        "\n",
        "file = '.'\n",
        "mnist = input_data.read_data_sets(file, one_hot=False)\n",
        "param_dict = np.load('mlp.npz')\n",
        "\n",
        "##########################\n",
        "### Definição do Grafo\n",
        "##########################\n",
        "\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "    \n",
        "    mlp_graph(fixed_params = param_dict)\n",
        "\n",
        "with tf.Session(graph=g) as sess:\n",
        "    \n",
        "    test_acc = sess.run('accuracy:0', feed_dict = {'features:0': mnist.test.images,'targets:0': mnist.test.labels})\n",
        "    print('Acurácia em Teste: %.3f' % test_acc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./train-images-idx3-ubyte.gz\n",
            "Extracting ./train-labels-idx1-ubyte.gz\n",
            "Extracting ./t10k-images-idx3-ubyte.gz\n",
            "Extracting ./t10k-labels-idx1-ubyte.gz\n",
            "Acurácia em Teste: 0.976\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}