{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN-Keras-Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vladimiralencar/DeepLearning-LANA/blob/master/DNN/DNN_Keras_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gUQpcPfkZQgy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Networks com TensorFlow \n",
        "## Classificação\n",
        "\n",
        "![TensorFlow](http://localhost:8888/notebooks/Dropbox/BigDataAnalytics/DeepLearning/DSA/FIA/deepLearning_I/cap06-DeepNeuralNetwork/Exercicio8/images/tensorflow.png \"TensorFlow\")\n",
        "\n",
        "TensorFlow é uma biblioteca de software de código aberto para aprendizagem de máquinas em vários tipos de tarefas de compreensão de percepção e linguagem. Atualmente, ele é usado tanto para pesquisa quanto para produção por diferentes equipes em muitos produtos comerciais do Google, como reconhecimento de fala, Gmail, Google Photos e pesquisas, muitas das quais anteriormente utilizaram seu antecessor DistBelief. O TensorFlow foi originalmente desenvolvido pela equipe do Google Brain para fins de pesquisa e produção do Google e posteriormente lançado sob a licença de código aberto Apache 2.0 em 9 de novembro de 2015.\n",
        "\n",
        "* [TensorFlow Homepage](https://www.tensorflow.org/)\n",
        "* [TensorFlow GitHib](https://github.com/tensorflow/tensorflow)\n",
        "* [TensorFlow Google Groups Support](https://groups.google.com/forum/#!forum/tensorflow)\n",
        "* [TensorFlow Google Groups Developer Discussion](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss)\n",
        "* [TensorFlow FAQ](https://www.tensorflow.org/resources/faq)\n"
      ]
    },
    {
      "metadata": {
        "id": "ugiqhHZRZQg3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f33aee7-a58c-4086-d2be-ce118c181d7b"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Versão do TensorFlow: {}\".format(tf.__version__))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Versão do TensorFlow: 1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "akRMOfU4ZQhB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Usando TensorFlow\n",
        "\n",
        "TensorFlow é uma API de matemática de baixo nível, semelhante ao [Numpy] (http://www.numpy.org/). No entanto, ao contrário de Numpy, TensorFlow é construído para aprendizagem profunda. O TensorFlow funciona permitindo que você defina grafos de computação com o Python. O TensorFlow compila esses grafos de computação em um código C ++ / [CUDA] (https://developer.nvidia.com/cuda-zone) altamente eficiente."
      ]
    },
    {
      "metadata": {
        "id": "TN-3CKnDZQhC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Neste exercício, seu trabalho é criar as camadas da rede neural, necessárias para construir o modelo de classificação, usando TensorFlow e Keras. Usaremos o dataset iris.csv e nosso objetivo é prever a categoria (ou classe) a qual pertencem as plantas. "
      ]
    },
    {
      "metadata": {
        "id": "LoLuP8DUZQhE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Funções de Transformação (função de apoio para construção do modelo)"
      ]
    },
    {
      "metadata": {
        "id": "9yrCAJraZQhG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Encode dos valores de texto (i.e. [1],[2],[3] para vermelho, verde e azul).\n",
        "from sklearn import preprocessing\n",
        "def encode_text_index(df, name):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    df[name] = le.fit_transform(df[name])\n",
        "    return le.classes_\n",
        "\n",
        "# Função para preencher os valores NA\n",
        "def missing_median(df, name):\n",
        "    med = df[name].median()\n",
        "    df[name] = df[name].fillna(med)\n",
        "    \n",
        "# Converte um dataframe do Pandas para inputs x,y que TensorFlow precisa\n",
        "def to_xy(df, target):\n",
        "    result = []\n",
        "    for x in df.columns:\n",
        "        if x != target:\n",
        "            result.append(x)\n",
        "    \n",
        "    # Descubrindo o tipo da coluna de destino.  \n",
        "    target_type = df[target].dtypes\n",
        "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
        "    \n",
        "    # Codificação. TensorFlow gosta de 32 bits.\n",
        "    if target_type in (np.int64, np.int32):\n",
        "        # Classification\n",
        "        dummies = pd.get_dummies(df[target])\n",
        "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
        "    else:\n",
        "        # Regression\n",
        "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P3B4_I7maCgn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Carregando os dados"
      ]
    },
    {
      "metadata": {
        "id": "BG6GU3PrZ1Vi",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "66695e00-e418-4a4e-fee7-bd7b5a5ab555"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir data\n",
        "!cp *.csv data"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a089e0d-73c4-4e43-8180-a06296f6da61\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9a089e0d-73c4-4e43-8180-a06296f6da61\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving iris.csv to iris.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VPh8B7ZOaP0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb6b4542-59de-4b1f-8705-1018071f5929"
      },
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iris.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VTClKAWOZQhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6abec2fc-7c3d-46be-b590-74bb84bbd84f"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "path = \"./data\"\n",
        "\n",
        "# Carrega o dataset\n",
        "filename_read = os.path.join(path,\"iris.csv\")\n",
        "\n",
        "# Preenche com o valor NA quando não houver dados na coluna\n",
        "df = pd.read_csv(filename_read, na_values = ['NA','?'])\n",
        "\n",
        "# Encode das classes\n",
        "species = encode_text_index(df,\"species\")\n",
        "\n",
        "# Converte para o formato x,y requerido pelo TensorFlow\n",
        "x,y = to_xy(df,\"species\")\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "sGTo_PTyaXDZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7f8a1431-c12f-4eaf-f485-357740c5034b"
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_l</th>\n",
              "      <th>sepal_w</th>\n",
              "      <th>petal_l</th>\n",
              "      <th>petal_w</th>\n",
              "      <th>species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal_l  sepal_w  petal_l  petal_w  species\n",
              "0      5.1      3.5      1.4      0.2        0\n",
              "1      4.9      3.0      1.4      0.2        0\n",
              "2      4.7      3.2      1.3      0.2        0\n",
              "3      4.6      3.1      1.5      0.2        0\n",
              "4      5.0      3.6      1.4      0.2        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "ywVG652daoZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca8e6d70-3807-47c5-cf43-456aa01d93d4"
      },
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "jRrE8AsKa0sb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "306a6072-eee3-43ca-83c8-640b4b089e45"
      },
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "ds3l7-KqaV8g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "839e1098-74de-46b0-b5cd-be1655de3afc"
      },
      "cell_type": "code",
      "source": [
        "# Cria a rede neural\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim = x.shape[1], kernel_initializer = 'normal', activation = 'relu'))\n",
        "model.add(Dense(1, kernel_initializer = 'normal'))\n",
        "model.add(Dense(y.shape[1], activation = 'softmax' ))\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 10)                50        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 11        \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 3)                 6         \n",
            "=================================================================\n",
            "Total params: 67\n",
            "Trainable params: 67\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y69S2ffAaYyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3434
        },
        "outputId": "1ce69b2e-8d92-486d-e24b-fc8dbffa74c0"
      },
      "cell_type": "code",
      "source": [
        "# treina o modelo\n",
        "model.fit(x, y, verbose = 2, epochs = 100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " - 2s - loss: 1.0998\n",
            "Epoch 2/100\n",
            " - 0s - loss: 1.0994\n",
            "Epoch 3/100\n",
            " - 0s - loss: 1.0994\n",
            "Epoch 4/100\n",
            " - 0s - loss: 1.0989\n",
            "Epoch 5/100\n",
            " - 0s - loss: 1.0986\n",
            "Epoch 6/100\n",
            " - 0s - loss: 1.0985\n",
            "Epoch 7/100\n",
            " - 0s - loss: 1.0984\n",
            "Epoch 8/100\n",
            " - 0s - loss: 1.0982\n",
            "Epoch 9/100\n",
            " - 0s - loss: 1.0984\n",
            "Epoch 10/100\n",
            " - 0s - loss: 1.0980\n",
            "Epoch 11/100\n",
            " - 0s - loss: 1.0980\n",
            "Epoch 12/100\n",
            " - 0s - loss: 1.0979\n",
            "Epoch 13/100\n",
            " - 0s - loss: 1.0979\n",
            "Epoch 14/100\n",
            " - 0s - loss: 1.0976\n",
            "Epoch 15/100\n",
            " - 0s - loss: 1.0975\n",
            "Epoch 16/100\n",
            " - 0s - loss: 1.0974\n",
            "Epoch 17/100\n",
            " - 0s - loss: 1.0973\n",
            "Epoch 18/100\n",
            " - 0s - loss: 1.0971\n",
            "Epoch 19/100\n",
            " - 0s - loss: 1.0970\n",
            "Epoch 20/100\n",
            " - 0s - loss: 1.0969\n",
            "Epoch 21/100\n",
            " - 0s - loss: 1.0967\n",
            "Epoch 22/100\n",
            " - 0s - loss: 1.0965\n",
            "Epoch 23/100\n",
            " - 0s - loss: 1.0963\n",
            "Epoch 24/100\n",
            " - 0s - loss: 1.0960\n",
            "Epoch 25/100\n",
            " - 0s - loss: 1.0957\n",
            "Epoch 26/100\n",
            " - 0s - loss: 1.0956\n",
            "Epoch 27/100\n",
            " - 0s - loss: 1.0951\n",
            "Epoch 28/100\n",
            " - 0s - loss: 1.0948\n",
            "Epoch 29/100\n",
            " - 0s - loss: 1.0942\n",
            "Epoch 30/100\n",
            " - 0s - loss: 1.0937\n",
            "Epoch 31/100\n",
            " - 0s - loss: 1.0933\n",
            "Epoch 32/100\n",
            " - 0s - loss: 1.0925\n",
            "Epoch 33/100\n",
            " - 0s - loss: 1.0918\n",
            "Epoch 34/100\n",
            " - 0s - loss: 1.0911\n",
            "Epoch 35/100\n",
            " - 0s - loss: 1.0902\n",
            "Epoch 36/100\n",
            " - 0s - loss: 1.0895\n",
            "Epoch 37/100\n",
            " - 0s - loss: 1.0881\n",
            "Epoch 38/100\n",
            " - 0s - loss: 1.0874\n",
            "Epoch 39/100\n",
            " - 0s - loss: 1.0852\n",
            "Epoch 40/100\n",
            " - 0s - loss: 1.0837\n",
            "Epoch 41/100\n",
            " - 0s - loss: 1.0823\n",
            "Epoch 42/100\n",
            " - 0s - loss: 1.0802\n",
            "Epoch 43/100\n",
            " - 0s - loss: 1.0780\n",
            "Epoch 44/100\n",
            " - 0s - loss: 1.0756\n",
            "Epoch 45/100\n",
            " - 0s - loss: 1.0730\n",
            "Epoch 46/100\n",
            " - 0s - loss: 1.0698\n",
            "Epoch 47/100\n",
            " - 0s - loss: 1.0663\n",
            "Epoch 48/100\n",
            " - 0s - loss: 1.0626\n",
            "Epoch 49/100\n",
            " - 0s - loss: 1.0581\n",
            "Epoch 50/100\n",
            " - 0s - loss: 1.0529\n",
            "Epoch 51/100\n",
            " - 0s - loss: 1.0485\n",
            "Epoch 52/100\n",
            " - 0s - loss: 1.0430\n",
            "Epoch 53/100\n",
            " - 0s - loss: 1.0378\n",
            "Epoch 54/100\n",
            " - 0s - loss: 1.0310\n",
            "Epoch 55/100\n",
            " - 0s - loss: 1.0251\n",
            "Epoch 56/100\n",
            " - 0s - loss: 1.0183\n",
            "Epoch 57/100\n",
            " - 0s - loss: 1.0108\n",
            "Epoch 58/100\n",
            " - 0s - loss: 1.0040\n",
            "Epoch 59/100\n",
            " - 0s - loss: 0.9958\n",
            "Epoch 60/100\n",
            " - 0s - loss: 0.9880\n",
            "Epoch 61/100\n",
            " - 0s - loss: 0.9798\n",
            "Epoch 62/100\n",
            " - 0s - loss: 0.9715\n",
            "Epoch 63/100\n",
            " - 0s - loss: 0.9643\n",
            "Epoch 64/100\n",
            " - 0s - loss: 0.9546\n",
            "Epoch 65/100\n",
            " - 0s - loss: 0.9453\n",
            "Epoch 66/100\n",
            " - 0s - loss: 0.9370\n",
            "Epoch 67/100\n",
            " - 0s - loss: 0.9288\n",
            "Epoch 68/100\n",
            " - 0s - loss: 0.9205\n",
            "Epoch 69/100\n",
            " - 0s - loss: 0.9113\n",
            "Epoch 70/100\n",
            " - 0s - loss: 0.9019\n",
            "Epoch 71/100\n",
            " - 0s - loss: 0.8934\n",
            "Epoch 72/100\n",
            " - 0s - loss: 0.8852\n",
            "Epoch 73/100\n",
            " - 0s - loss: 0.8772\n",
            "Epoch 74/100\n",
            " - 0s - loss: 0.8679\n",
            "Epoch 75/100\n",
            " - 0s - loss: 0.8593\n",
            "Epoch 76/100\n",
            " - 0s - loss: 0.8512\n",
            "Epoch 77/100\n",
            " - 0s - loss: 0.8429\n",
            "Epoch 78/100\n",
            " - 0s - loss: 0.8354\n",
            "Epoch 79/100\n",
            " - 0s - loss: 0.8278\n",
            "Epoch 80/100\n",
            " - 0s - loss: 0.8187\n",
            "Epoch 81/100\n",
            " - 0s - loss: 0.8115\n",
            "Epoch 82/100\n",
            " - 0s - loss: 0.8018\n",
            "Epoch 83/100\n",
            " - 0s - loss: 0.7914\n",
            "Epoch 84/100\n",
            " - 0s - loss: 0.7789\n",
            "Epoch 85/100\n",
            " - 0s - loss: 0.7683\n",
            "Epoch 86/100\n",
            " - 0s - loss: 0.7602\n",
            "Epoch 87/100\n",
            " - 0s - loss: 0.7533\n",
            "Epoch 88/100\n",
            " - 0s - loss: 0.7455\n",
            "Epoch 89/100\n",
            " - 0s - loss: 0.7379\n",
            "Epoch 90/100\n",
            " - 0s - loss: 0.7306\n",
            "Epoch 91/100\n",
            " - 0s - loss: 0.7238\n",
            "Epoch 92/100\n",
            " - 0s - loss: 0.7172\n",
            "Epoch 93/100\n",
            " - 0s - loss: 0.7107\n",
            "Epoch 94/100\n",
            " - 0s - loss: 0.7044\n",
            "Epoch 95/100\n",
            " - 0s - loss: 0.6981\n",
            "Epoch 96/100\n",
            " - 0s - loss: 0.6921\n",
            "Epoch 97/100\n",
            " - 0s - loss: 0.6864\n",
            "Epoch 98/100\n",
            " - 0s - loss: 0.6805\n",
            "Epoch 99/100\n",
            " - 0s - loss: 0.6749\n",
            "Epoch 100/100\n",
            " - 0s - loss: 0.6694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe15cd04c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "nsPv8baQZQhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "516ba103-403c-4cd4-ee9a-9d2775e41c61"
      },
      "cell_type": "code",
      "source": [
        "# Classes encontradas\n",
        "print(species)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_JepF0o0ZQhe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Desliga a opção de notação científica para imprimir os resultados.\n",
        "np.set_printoptions(suppress = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5d1y8HnZQhY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Agora que você tem uma rede neural treinada, vamos usá-la. O código a seguir usa nossa rede neural. Exatamente como antes, vamos gerar prédições. Observe que 3 valores voltam para cada uma das 150 flores da íris. Havia 3 tipos de íris (Iris-setosa, Iris-versicolor e Iris-virginica)."
      ]
    },
    {
      "metadata": {
        "id": "O8e5PfbIZQhZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "308c232e-b39a-4dac-a78a-2360dffc6e9f"
      },
      "cell_type": "code",
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "pred = model.predict(x)\n",
        "print(\"Shape: {}\".format(pred.shape))\n",
        "print(pred[:10])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (150, 3)\n",
            "[[0.87465876 0.02141222 0.10392903]\n",
            " [0.8187447  0.03762416 0.14363109]\n",
            " [0.8493396  0.02836394 0.12229647]\n",
            " [0.8117921  0.03985329 0.1483546 ]\n",
            " [0.88179755 0.01957599 0.09862647]\n",
            " [0.87492263 0.02134334 0.10373402]\n",
            " [0.85051    0.02802798 0.12146204]\n",
            " [0.8536035  0.02714668 0.11924984]\n",
            " [0.79491717 0.04544919 0.15963362]\n",
            " [0.8261748  0.03529222 0.13853298]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YCxLAdY-ZQhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "228fb22d-beec-434d-c313-323608764c2a"
      },
      "cell_type": "code",
      "source": [
        "y[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "QYz9MCwsZQhn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6e8d046a-7ece-480c-d306-86883d47fa1e"
      },
      "cell_type": "code",
      "source": [
        "# Normalmente, a coluna (pred) com maior previsão é considerada a predição da rede neural. \n",
        "# A função argmax encontra o índice da previsão máxima para cada linha.\n",
        "predict_classes = np.argmax(pred,axis=1)\n",
        "expected_classes = np.argmax(y,axis=1)\n",
        "print(\"Valores Previstos: {}\".format(predict_classes))\n",
        "print(\"Valores Esperados: {}\".format(expected_classes))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valores Previstos: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1]\n",
            "Valores Esperados: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O8ubaSq8ZQht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee8062cd-01eb-4312-eab0-7e09e204b3a0"
      },
      "cell_type": "code",
      "source": [
        "print(species)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gZjaItoZZQhx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e13416fa-ec39-408c-f606-9558b9f81fc9"
      },
      "cell_type": "code",
      "source": [
        "# É muito fácil transformar esses índices de volta em espécies de íris. \n",
        "# Nós apenas usamos a lista de espécies que criamos anteriormente.\n",
        "print(species[predict_classes[1:10]])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
            " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xQLEw2gTZQh4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b67985d3-efc4-4aa6-f1f6-20c1f45e5ebc"
      },
      "cell_type": "code",
      "source": [
        "# A precisão pode ser uma métrica de erro mais fácil de entender. \n",
        "# É essencialmente uma pontuação de teste. Para todas as previsões da íris, que porcentagem estava correta? \n",
        "# A desvantagem é que não considera a confiança na rede neural em cada previsão.\n",
        "from sklearn.metrics import accuracy_score\n",
        "correct = accuracy_score(expected_classes, predict_classes)\n",
        "print(\"Acurácia: {}\".format(correct))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia: 0.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NrdhSyV3ZQh-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "O código abaixo executa duas previsões ad hoc. A primeira previsão é simplesmente uma única flor de íris. O segundo prediz duas flores de íris. Observe que o argmax na segunda predição requer ** eixo = 1 ** <br > Uma vez que temos um array 2D agora, devemos especificar qual eixo levar o argmax. O valor ** axis = 1 ** especifica que queremos o índice de coluna max para cada linha."
      ]
    },
    {
      "metadata": {
        "id": "Vmb1fJmOZQiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7a3ccd5e-430e-4563-adee-774ad273775e"
      },
      "cell_type": "code",
      "source": [
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "print(species)\n",
        "\n",
        "# Previsão ad-hoc\n",
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0]], dtype=float)\n",
        "pred = model.predict(sample_flower)\n",
        "print(pred)\n",
        "pred = np.argmax(pred)\n",
        "print(\"Prevendo que {} é: {}\".format(sample_flower,species[pred]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
            "[[0.15543687 0.47747836 0.3670848 ]]\n",
            "Prevendo que [[5. 3. 4. 2.]] é: Iris-versicolor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "foG60kkccHdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "97559a14-6f1f-454a-f23e-80c5ab96cc33"
      },
      "cell_type": "code",
      "source": [
        "# predict two sample flowers\n",
        "sample_flower = np.array( [[5.0,3.0,4.0,2.0],[5.2,3.5,1.5,0.8]], dtype=float)\n",
        "pred = model.predict(sample_flower)\n",
        "print(pred)\n",
        "pred = np.argmax(pred,axis=1)\n",
        "print(\"Prevendo que {} é: {}\".format(sample_flower,species[pred]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.15543687 0.47747836 0.3670848 ]\n",
            " [0.82423264 0.03589669 0.13987058]]\n",
            "Prevendo que [[5.  3.  4.  2. ]\n",
            " [5.2 3.5 1.5 0.8]] é: ['Iris-versicolor' 'Iris-setosa']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}